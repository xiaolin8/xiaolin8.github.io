<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[MySQL-Explain]]></title>
    <url>%2F2019%2F09%2F14%2FMySQL-Explain%2F</url>
    <content type="text"><![CDATA[The ref column shows which columns or constants are compared to the index named in the key column to select rows from the table. The type column of EXPLAIN output describes how tables are joined. The following list describes the join types, ordered from the best type to the worst: system The table has only one row (= system table). This is a special case of the const join type. const The table has at most one matching row, which is read at the start of the query. Because there is only one row, values from the column in this row can be regarded as constants by the rest of the optimizer. const tables are very fast because they are read only once. const is used when you compare all parts of a PRIMARY KEY or UNIQUE index to constant values. In the following queries, tbl_name can be used as a const table: 1234SELECT * FROM tbl_name WHERE primary_key=1;SELECT * FROM tbl_name WHERE primary_key_part1=1 AND primary_key_part2=2; eq_ref One row is read from this table for each combination of rows from the previous tables. Other than the system and const types, this is the best possible join type. It is used when all parts of an index are used by the join and the index is a PRIMARY KEY or UNIQUE NOT NULL index. eq_ref can be used for indexed columns that are compared using the = operator. The comparison value can be a constant or an expression that uses columns from tables that are read before this table. In the following examples, MySQL can use an eq_ref join to process ref_table: 123456SELECT * FROM ref_table,other_table WHERE ref_table.key_column=other_table.column;SELECT * FROM ref_table,other_table WHERE ref_table.key_column_part1=other_table.column AND ref_table.key_column_part2=1; ref All rows with matching index values are read from this table for each combination of rows from the previous tables. ref is used if the join uses only a leftmost prefix of the key or if the key is not a PRIMARY KEY or UNIQUE index (in other words, if the join cannot select a single row based on the key value). If the key that is used matches only a few rows, this is a good join type. ref can be used for indexed columns that are compared using the = or &lt;=&gt; operator. In the following examples, MySQL can use a ref join to process ref_table: 12345678SELECT * FROM ref_table WHERE key_column=expr;SELECT * FROM ref_table,other_table WHERE ref_table.key_column=other_table.column;SELECT * FROM ref_table,other_table WHERE ref_table.key_column_part1=other_table.column AND ref_table.key_column_part2=1; fulltext The join is performed using a FULLTEXT index. range Only rows that are in a given range are retrieved, using an index to select the rows. The key column in the output row indicates which index is used. The key_len contains the longest key part that was used. The ref column is NULL for this type. range can be used when a key column is compared to a constant using any of the =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, LIKE, or IN() operators: 1234567891011SELECT * FROM tbl_name WHERE key_column = 10;SELECT * FROM tbl_name WHERE key_column BETWEEN 10 and 20;SELECT * FROM tbl_name WHERE key_column IN (10,20,30);SELECT * FROM tbl_name WHERE key_part1 = 10 AND key_part2 IN (10,20,30); index The index join type is the same as ALL, except that the index tree is scanned. This occurs two ways: If the index is a covering index for the queries and can be used to satisfy all data required from the table, only the index tree is scanned. In this case, the Extra column says Using index. An index-only scan usually is faster than ALL because the size of the index usually is smaller than the table data. A full table scan is performed using reads from the index to look up data rows in index order. Uses index does not appear in the Extra column. MySQL can use this join type when the query uses only columns that are part of a single index. ALL A full table scan is done for each combination of rows from the previous tables. This is normally not good if the table is the first table not marked const, and usually very bad in all other cases. Normally, you can avoid ALL by adding indexes that enable row retrieval from the table based on constant values or column values from earlier tables. EXPLAIN Extra InformationThe Extra column of EXPLAIN output contains additional information about how MySQL resolves the query. The following list explains the values that can appear in this column. Each item also indicates for JSON-formatted output which property displays the Extra value. For some of these, there is a specific property. The others display as the text of the message property. const row not found For a query such as SELECT … FROM tbl_name, the table was empty. Distinct MySQL is looking for distinct values, so it stops searching for more rows for the current row combination after it has found the first matching row. Impossible HAVING The HAVING clause is always false and cannot select any rows. Impossible WHERE The WHERE clause is always false and cannot select any rows. Impossible WHERE noticed after reading const tables MySQL has read all const (and system) tables and notice that the WHERE clause is always false. no matching row in const table For a query with a join, there was an empty table or a table with no rows satisfying a unique index condition. Not exists MySQL was able to do a LEFT JOIN optimization on the query and does not examine more rows in this table for the previous row combination after it finds one row that matches the LEFT JOIN criteria. Here is an example of the type of query that can be optimized this way: 12SELECT * FROM t1 LEFT JOIN t2 ON t1.id=t2.id WHERE t2.id IS NULL; Assume that t2.id is defined as NOT NULL. In this case, MySQL scans t1 and looks up the rows in t2 using the values of t1.id. If MySQL finds a matching row in t2, it knows that t2.id can never be NULL, and does not scan through the rest of the rows in t2 that have the same id value. In other words, for each row in t1, MySQL needs to do only a single lookup in t2, regardless of how many rows actually match in t2. Using filesort MySQL must do an extra pass to find out how to retrieve the rows in sorted order. The sort is done by going through all rows according to the join type and storing the sort key and pointer to the row for all rows that match the WHERE clause. The keys then are sorted and the rows are retrieved in sorted order. Using index The column information is retrieved from the table using only information in the index tree without having to do an additional seek to read the actual row. This strategy can be used when the query uses only columns that are part of a single index. For InnoDB tables that have a user-defined clustered index, that index can be used even when Using index is absent from the Extra column. This is the case if type is index and key is PRIMARY. Using index condition Tables are read by accessing index tuples and testing them first to determine whether to read full table rows. In this way, index information is used to defer (“push down”) reading full table rows unless it is necessary. Using join buffer (Block Nested Loop), Using join buffer Tables from earlier joins are read in portions into the join buffer, and then their rows are used from the buffer to perform the join with the current table. (Block Nested Loop) indicates use of the Block Nested-Loop algorithm and (Batched Key Access) indicates use of the Batched Key Access algorithm. That is, the keys from the table on the preceding line of the EXPLAIN output will be buffered, and the matching rows will be fetched in batches from the table represented by the line in which Using join buffer appears. Using MRR Tables are read using the Multi-Range Read optimization strategy. Using temporary To resolve the query, MySQL needs to create a temporary table to hold the result. This typically happens if the query contains GROUP BY and ORDER BY clauses that list columns differently. Using where A WHERE clause is used to restrict which rows to match against the next table or send to the client. Unless you specifically intend to fetch or examine all rows from the table, you may have something wrong in your query if the Extra value is not Using where and the table join type is ALL or index. Using where with pushed condition id: SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符. select_type: SELECT 查询的类型. table: 查询的是哪个表 partitions: 匹配的分区 type: join 类型 possible_keys: 此次查询中可能选用的索引 key: 此次查询中确切使用到的索引. ref: 哪个字段或常数与 key 一起被使用 rows: 显示此查询一共扫描了多少行. 这个是一个估计值. filtered: 表示此查询条件所过滤的数据的百分比 extra: 额外的信息 SIMPLE, 表示此查询不包含 UNION 查询或子查询 PRIMARY, 表示此查询是最外层的查询 UNION, 表示此查询是 UNION 的第二或随后的查询 DEPENDENT UNION, UNION 中的第二个或后面的查询语句, 取决于外面的查询 UNION RESULT, UNION 的结果 SUBQUERY, 子查询中的第一个 SELECT DEPENDENT SUBQUERY: 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果. system: 表中只有一条数据. 这个类型是特殊的 const 类型. const: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可. eq_ref: 此类型通常出现在多表的 join 查询, 表示对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询的比较操作通常是 =, 查询效率较高. ref: 此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了 最左前缀 规则索引的查询. range: 表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN() 操作中. index: 表示全索引扫描(full index scan), 和 ALL 类型类似, 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据.index 类型通常出现在: 所要查询的数据直接在索引树中就可以获取到, 而不需要扫描数据. 当是这种情况时, Extra 字段 会显示 Using index. ALL: 表示全表扫描, 这个类型的查询是性能最差的查询之一. 通常来说, 我们的查询不应该出现 ALL 类型的查询, 因为这样的查询在数据量大的情况下, 对数据库的性能是巨大的灾难. 如一个查询是 ALL 类型查询, 那么一般来说可以对相应的字段添加索引来避免. 1ALL &lt; index &lt; range ~ index_merge &lt; ref &lt; eq_ref &lt; const &lt; system Using filesort 当 Extra 中有 Using filesort 时, 表示 MySQL 需额外的排序操作, 不能通过索引顺序达到排序效果. 一般有 Using filesort, 都建议优化去掉, 因为这样的查询 CPU 资源消耗大. Using index“覆盖索引扫描”, 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 往往说明性能不错 Using temporary查询有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 查询效率不高, 建议优化.]]></content>
  </entry>
  <entry>
    <title><![CDATA[分布式锁总结]]></title>
    <url>%2F2019%2F07%2F14%2Fdistributed-lock%2F</url>
    <content type="text"><![CDATA[zookeeper可靠性比redis强太多，只是效率低了点，如果并发量不是特别大，追求可靠性，首选zookeeper。为了效率，则首选redis实现。 使用场景 不同的业务服务器，不同的进程 需要怎样的锁 可重入锁（可以多次加锁）可避免死锁（Thread+引用计数，避免了频繁的加锁解锁，又避免了死锁）同一个class中的synchronized方法可互相调用而不会发生死锁 ReentrantLock和synchronized都是可重入锁（前提是同一个对象） 不可重入锁（自旋锁） 阻塞锁（根据业务需要）可以让线程进入阻塞状态等待唤醒，而不是快速失败返回 公平锁（根据业务需要）加锁时是否根据优先级排队 失效时间（没有失效时间的锁一旦解锁失败，线程们就再也无法获取到锁了） 我加的锁只能由我来释放，或者锁超时自动释放（这时我的业务处理也要停下来） Redlock算法set(key, value, nx=True, ex=xxx) 背景：简单的sentinel集群中，如果master挂了，slave来不及同步数据（主从异步复制）就被选为新的master，那么如果有请求过来申请锁就会直接批准了，那么可以就同一把锁被两个客户端同时持有了 获取当前时间（单位是毫秒）。 轮流用相同的key和随机值在N个节点上请求锁，在这一步里，客户端在每个master上请求锁时，会有一个和总的锁释放时间相比小的多的超时时间。比如如果锁自动释放时间是10秒钟，那每个节点锁请求的超时时间可能是5-50毫秒的范围，这个可以防止一个客户端在某个宕掉的master节点上阻塞过长时间，如果一个master节点不可用了，我们应该尽快尝试下一个master节点。 客户端计算第二步中获取锁所花的时间，只有当客户端在大多数master节点上成功获取了锁（在这里是3个），而且总共消耗的时间不超过锁释放时间，这个锁就认为是获取成功了。 如果锁获取成功了，那现在锁自动释放时间就是最初的锁释放时间减去之前获取锁所消耗的时间。 如果锁获取失败了，不管是因为获取成功的锁不超过一半（N/2+1)还是因为总消耗时间超过了锁释放时间，客户端都会到每个master节点上释放锁，即便是那些他认为没有获取成功的锁。 N个独立的节点，加锁时至少要获取到超过一半的锁时才能算是加锁成功，获取锁超时时间&lt;&lt;锁自动释放时间，锁持有时间（业务执行时间）=锁自动释放时间-获取锁超时时间，redlock在业务方获取到锁时会返回客户端能够占用的时间，业务若是执行超时，需要在锁块过期时进行续租 redis的官方分布式锁redisson就是用的续租的方法 基于redis的分布式锁一直没有解决的问题：如果业务处理超时了，锁自动释放的问题 节点崩溃重启，会出现多个客户端持有锁假设一共有5个Redis节点：A, B, C, D, E。设想发生了如下的事件序列：(1)客户端1成功锁住了A, B, C，获取锁成功（但D和E没有锁住）。(2)节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了。(3)节点C重启后，客户端2锁住了C, D, E，获取锁成功。这样，客户端1和客户端2同时获得了锁（针对同一资源）。 延迟重启等待的时间大于锁的有效时间。采用这种方式，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。 时间跳跃问题(1)假设一共有5个Redis节点：A, B, C, D, E。设想发生了如下的事件序列：(2)客户端1从Redis节点A, B, C成功获取了锁（多数节点）。由于网络问题，与D和E通信失败。(3)节点C上的时钟发生了向前跳跃，导致它上面维护的锁快速过期。客户端2从Redis节点C, D, E成功获取了同一个资源的锁（多数节点）。客户端1和客户端2现在都认为自己持有了锁。 超时导致锁失效问题RedLock算法并没有解决，操作共享资源超时，导致锁失效的问题。 基于Zookeeper实现分布式锁 临时有序节点 在节点上绑定监听器，一旦节点有变化，ZK会通知客户端，客户端检查自己创建的节点是不是所有节点序号中最小的 可重入：客户端在创建节点时把当前IP和ThreadId写到节点中，下次要获取锁的时候直接判断是不是一样 公平锁：ZK的临时节点有序，每次锁被释放时，ZK可以通知最小节点来获取锁，保证了公平 过期时间：如果创建/lock节点的客户端挂了，那么相应的node会被自动删除 ZK弱一致性（每次同步写刚好超过一半的节点） 性能不高：每次都需要动态创建、删除临时节点，而且只能通过leader服务器 参考： https://www.cnblogs.com/rjzheng/p/9310976.html https://redis.io/topics/distlock]]></content>
      <tags>
        <tag>distributed, lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot2-upgrade]]></title>
    <url>%2F2019%2F07%2F13%2Fspringboot2-upgrade%2F</url>
    <content type="text"><![CDATA[SpringBoot2 解决了 ”too many open fd“问题 性能更好：默认 HikariCP 连接池 支持 Spring5 （支持WebFlux） 更强大的Actuator监控组件，SpringBoot2采用micrometer做Metrics统计，性能更强，统计指标项更合理，且支持无缝对接Promethus监控 属性配置方面也更加强大了 SpringBoot2.0新特性：WebMvcConfigurer SpringBoot2 升级的坑 一大堆 Maven 依赖冲突需要解决，有些依赖还不好解决，记得有一个 Velocity 渲染的组件，在 SpringBoot2 中直接被移除了，添加依赖还会冲突，最后没办法上网查了半天解决方案才解决 序列化问题：主要是Date类型，原版本序列化话为long型时间戳，薪版本将会序列化为一个utc时间字符串。为了保持接口兼容、以及对其他解析程序的便捷，我们简单修改一下配置即可：spring.jackson.time-zone=GMT+08:00spring.jackson.serialization.write-dates-as-timestamps=true 数据源 默认 HikariCP 连接池 访问报错，HikariPool-1 - jdbcUrl is required with driverClassName 当然既然是使用了读写分离的数据库，光做这些是不够的，需要进行手动配置 12345678@Bean// 设置为首选的数据源@Primary// 读取配置@ConfigurationProperties(prefix="spring.datasource.readwrite")public DataSource dataSource() &#123; return DataSourceBuilder.create().build();&#125; 底层 tomcat 安全机制变更，导致有个别的get请求无法访问，最终通过安全放行策略解决 Redis - Jedis –&gt; lettuce Lettuce 是 一种可伸缩，线程安全，完全非阻塞的Redis客户端，多个线程可以共享一个RedisConnection,它利用Netty NIO 框架来高效地管理多个连接，从而提供了异步和同步数据访问方式，用于构建非阻塞的反应性应用程序 支持micrometer metrics，对接Promethus补全监控能力 SpringBoot2适配pageHelper Spring 官方迁移文档 最佳实践注解 or XML？spring boot官方是主张完全用注解替代XML的。那么实际生产环境下，我们该用注解还是该用XML，哪里用注解，哪里用XML？ 遇到依赖注入的类时，被依赖的对象应该使用XML配置。这样，当需要修改实现类的时候，能够不修改代码、不重新打包完成更换。 对于生产环境，一般来说很少直接线上切换不同的实现类，换也是线下随着某一个版本的发布，完成替换。]]></content>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高强度学习]]></title>
    <url>%2F2019%2F07%2F11%2Fintensive-learning%2F</url>
    <content type="text"><![CDATA[1. 强大的学习动力2. 不要太计较学习效率该快的时候，就要拼命地快；不该快的时候，就慢慢地“滋养”知识 3. 严格作息4. 犯困了，就睡觉；不犯困，就坚持学习5. 高强运动和“润泽”你运动强度越大、而休息得越好，那么，你的身体越好，你的“狠劲”、“自信心”越强。 最好的休息，是让你重燃生活的热情 我们的疲惫主要来自对现有的一成不变的生活的厌倦。 但可惜，我们缺乏对“休息”的想象力。我们能想出来的休息方法不是痴睡就是傻玩。 基本思路是以“做”来解决“累”，用积极休息取代消极放纵 旅行，而不是换个地方消遣。去一个地方对那个地方本身心存好奇，对自己这趟行程心存美意，感受自己经验范围以外的人生样貌。而不是坐了5小时飞机，只是换个地方打麻将，换个地方游泳，换个地方打球…… 从这个周末起学习一项新的技艺，比如弹电子琴，打鼓……每周末练习1小时以上。 去社交。不要以为它总是令人疲惫的。虽然和看书比起来，它稍有点令人紧张，但也能让你更兴奋，更有认同感。你必须每周有两三天是和工作圈子和亲戚外的人 打交道。它让你在朝九晚五的机械运行中不至失去活泼的天性。女性朋友们尤为需要走出去和朋友聚会，这些时刻你不再是满脸写着“效率”的中性人，而是一个裙裾飞扬的魅力焦点。 做点困难的事，如果你是精神超级紧张的人。心理学家发现解除神经紧张的方法，是去处理需要神经紧张才能解决的问题。 如去一个复杂的机械工厂从学徒干起，或者做一道超级复杂的数学题。 番茄工作法切换任务，交替地学习或者工作午睡适当体育锻炼保证晚上睡眠质量]]></content>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[整洁代码随想]]></title>
    <url>%2F2019%2F06%2F06%2Fclean-code%2F</url>
    <content type="text"><![CDATA[感想代码大部分时候是用来维护的，一定要清晰好看自描述的代码胜过文档和注释比较适合写注释的两种场景： public interface，向别人明确发布你功能的语义，输入输出，且不需要关注实现。 功能容易有歧义的点，或者涉及比较深层专业知识的时候。比如，如果你写一个客户端，各种config参数的含义等。 设计模式只是手段，代码清晰才是目的一些所谓“高手”的代码都比较抽象，各种工厂、各种继承。想找到一个实现总是要山路十八弯，一个工程里大部分的类是抽象类或者接口，找不到一两句实现的代码，整个读起代码来很不顺畅 当你的系统内大部分抽象只有一个实现的时候，要好好思考一下，是不是设计有点过度了，清晰永远是第一准则。 code review用git的pull request机制来做code review 重点应该review什么？ 凡是能通过机器检查出来的事情，无需通过人。比如换行、注释、方法长度、代码重复等。除了基本功能需求的逻辑合理没有bug外，我们更应该关注代码的设计与风格。比如，一段功能是不是应该属于一个类、是不是有很多相似的功能可以抽取出来复用、代码太过冗长难懂等等。 勤于重构 掌握一些常见的“无痛”重构技巧 小步快跑，不要企图一口吃成个胖子 建立自动化测试机制 熟练掌握IDE的自动重构功能 静态检查可以与发布系统做集成，强制把主要问题修复掉才可以上线 通用技巧单一职责优先定义整体框架我写代码的时候，比较喜欢先去定义整体的框架，就是写很多空实现，来把整体的业务流程穿起来。良好的方法签名，用入参和出参来控制流程。这样能够避免陷入业务细节无法自拔。在脑海中先定义清楚流程的几个阶段，并为每个阶段找到合适的方法／类归属。 清晰的命名避免过长参数避免过长方法和类 横向拆分 根据业务，把建立／更新／修改／通知等逻辑拆到不同的类里去 纵向拆分 把数据库操作/MQ操作/Cache操作/对象校验等，拆到不同的对象里去，让主流程尽量简单可控，让同一个类，表达尽量同一个维度的东西。 让相同长度的代码段表示相同粒度的逻辑面向对象设计技巧贫血与领域驱动大部分公司采用的三层/四层贫血模型，已经让我们的编码习惯，变成了面向DAO而不是面向对象。 缺少了必要的模型抽象和设计环节，使得代码冗长，复用程度比较差。每次撸代码的时候，从mapper撸起，好像已经成为不成文的规范。 一个好的系统，一定离不开一套好的模型定义。梳理清楚系统中的核心模型，清楚的定义每个方法的类归属，无论对于代码的可读性、可交流性，还是和产品的沟通，都是有莫大好处的。 为每个方法找到合适的类归属，数据和行为尽量要在一起如果一个类的所有方法，都是在操作另一个类的对象。这时候就要仔细想一想类的设计是否合理了。理论上讲，面向对象的设计，主张数据和行为在一起。这样，对象之间的结构才是清晰的，也能减少很多不必要的参数传递。 但是，如果操作一个对象数据的所有方法都建立在对象内部，可能使对象承载了很多并不属于它本身职能的方法。 例如，我定义一个类，叫做person，。这个类有很多行为，比如：吃饭、睡觉、上厕所、生孩子；也有很多字段，比如：姓名、年龄、性格。 很明显，字段从更大程度上来讲，是定义和描述我这个人的，但很多行为和我的字段并不相关。上厕所的时候是不会关心我是几岁的。如果把所有关于人的行为全部在person内部承载，这个类一定会膨胀的不行。 这时候就体现了service方法的价值，如果一个行为，无法明确属于哪个领域对象，牵强地融入领域对象里，会显得很不自然。这时候，无状态的service可以发挥出它的作用。但一定要把握好这个度，回归本质，我们要把属于每个模型的行为合理的去划定归属。 警惕staticstatic方法，本质上来讲是面向过程的，无法清晰地反馈对象之间的关系。虽然有一些代码实例（自己实现单例或者Spring托管等）的无状态方法可以用static来表示，但这种抽象是浅层次的。说白了，如果我们所有调用static的地方，都写上import static，那么所有的功能就由类自己在承载了。 而单例的膨胀，很大程度上也是贫血模型带来的副作用。如果对象本身有血有肉，就不需要这么多无状态方法。 static真正适用的场景：工具方法，而不是业务方法。 巧用method objectmethod object是大型重构的常用技巧。当一段逻辑特别复杂的代码，充斥着各种参数传递和是非因果判断的时候，我首先想到的重构手段是提取method object。所谓method object，是一个有数据有行为的对象。依赖的数据会成为这个对象的变量，所有的行为会成为这个对象的内部方法。利用成员变量代替参数传递，会让代码简洁清爽很多。并且，把一段过程式的代码转换成对象代码，为很多面向对象编程才可以使用的继承／封装／多态等提供了基础。 面向接口编程正确使用继承和组合protected abstract 这种是最值得使用继承的，父类保留扩展点，子类扩展 继承更多的是为扩展提供便利，为复用而存在的方法最好使用组合的方式 代码复用技巧模板方法这是我用得最多的设计模式了。每当有两个行为类似但又不完全相同的代码段时，我总是会想到模板方法。提取公共流程和可复用的方法到父类，保留不同的地方作为abstract方法，由不同的子类去实现。 最后，把不属于流程的、但可复用的方法，判断是不是属于基类的领域职责，再使用继承或者组合的方法，为这些方法找到合适的安家之处。 extract method责任链经常看到这样的代码，一连串类似的行为，只是数据或者行为不一样。如一堆校验器，如果成功怎么样、失败怎么样；或者一堆对象构建器，各去构造一部分数据。碰到这种场景，我总是喜欢定义一个通用接口，入参是完整的要校验／构造的参数， 出参是成功/失败的标示或者是void。然后有很多实现器分别实现这个接口，再用一个集合把这堆行为串起来。最后，遍历这个集合，串行或者并行的执行每一部分的逻辑。 这样做的好处是： ① 很多通用的代码可以在责任链原子对象的基类里实现； ② 代码清晰，开闭原则，每当有新的行为产生的时候，只需要定义行的实现类并添加到集合里即可； ③ 为并行提供了基础。 为集合显式定义它的行为例如一个Map，它可能表示一个配制、一个缓存等等。如果所有的操作都是直接操作Map，那么它的行为就没有任何语义。第一，读起来就必须要深入细节；第二，如果想从获取配置读取缓存的地方加个通用的逻辑，例如打个log什么的，你可以想象是多么的崩溃。 个人提倡的做法是，对于有明确语义的集合的一些操作，尤其是全局的集合或者被经常使用的集合，做一些封装和抽象，如把Map封装成一个Cache类或者一个config类，再提供GetFromCache这样的方法。]]></content>
      <tags>
        <tag>design, clean code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo 异步调用]]></title>
    <url>%2F2019%2F05%2F29%2Fdubbo-asynchronous-call%2F</url>
    <content type="text"><![CDATA[Dubbo 默认采用单一长连接，底层实现是 Netty 的 NIO 异步通讯机制；基于这种机制，Dubbo 实现了以下几种调用方式： 同步调用 异步调用 参数回调 事件通知 同步调用同步调用是一种阻塞式的调用方式，即 Consumer 端代码一直阻塞等待，直到 Provider 端返回为止； Consumer 业务线程调用远程接口，向 Provider 发送请求，同时当前线程处于阻塞状态； Provider 接到 Consumer 的请求后，开始处理请求，将结果返回给 Consumer； Consumer 收到结果后，当前线程继续往后执行。 这里有 2 个问题： Consumer 业务线程是怎么进入阻塞状态的？ Consumer 收到结果后，如何唤醒业务线程往后执行的？ 其实，Dubbo 的底层 IO 操作都是异步的。Consumer 端发起调用后，得到一个 Future 对象。对于同步调用，业务线程通过Future#get(timeout)，阻塞等待 Provider 端将结果返回；timeout则是 Consumer 端定义的超时时间。当结果返回后，会设置到此 Future，并唤醒阻塞的业务线程；当超时时间到结果还未返回时，业务线程将会异常返回。 异步调用基于 Dubbo 底层的异步 NIO 实现异步调用，对于 Provider 响应时间较长的场景是必须的，它能有效利用 Consumer 端的资源，相对于 Consumer 端使用多线程来说开销较小。 异步调用，对于 Provider 端不需要做特别的配置。下面的例子中，Provider 端接口定义如下： 123&lt;dubbo:reference id="asyncService" interface="com.alibaba.dubbo.samples.async.api.AsyncService"&gt; &lt;dubbo:method name="goodbye" async="true"/&gt;&lt;/dubbo:reference&gt; 需要异步调用的方法，均需要使用 \dubbo:method/标签进行描述。 Consumer 端发起调用12345AsyncService service = ...;String result = service.goodbye("samples");// 这里的返回值为空，请不要使用Future&lt;String&gt; future = RpcContext.getContext().getFuture();... // 业务线程可以开始做其他事情result = future.get(); // 阻塞需要获取异步结果时，也可以使用 get(timeout, unit) 设置超时时间 Dubbo Consumer 端发起调用后，同时通过RpcContext.getContext().getFuture()获取跟返回结果关联的Future对象，然后就可以开始处理其他任务；当需要这次异步调用的结果时，可以在任意时刻通过future.get(timeout)来获取。 一些特殊场景下，为了尽快调用返回，可以设置是否等待消息发出： sent=”true” 等待消息发出，消息发送失败将抛出异常； sent=”false” 不等待消息发出，将消息放入 IO 队列，即刻返回。 默认为false。配置方式如下： 1&lt;dubbo:method name="goodbye" async="true" sent="true" /&gt; 如果你只是想异步，完全忽略返回值，可以配置 return=”false”，以减少 Future 对象的创建和管理成本： 1&lt;dubbo:method name="goodbye" async="true" return="false"/&gt; 此时，RpcContext.getContext().getFuture()将返回null。 整个异步调用的时序图如下： 参数回调参数回调有点类似于本地 Callback 机制，但 Callback 并不是 Dubbo 内部的类或接口，而是由 Provider 端自定义的；Dubbo 将基于长连接生成反向代理，从而实现从 Provider 端调用 Consumer 端的逻辑。 Provider 端定义 Service 和 Callback1234567public interface CallbackService &#123; void addListener(String key, CallbackListener listener);&#125;public interface CallbackListener &#123; void changed(String msg);&#125; Provider 端 Service 实现123456789101112131415161718192021222324252627282930313233343536public class CallbackServiceImpl implements CallbackService &#123; private final Map&lt;String, CallbackListener&gt; listeners = new ConcurrentHashMap&lt;String, CallbackListener&gt;(); public CallbackServiceImpl() &#123; Thread t = new Thread(new Runnable() &#123; public void run() &#123; while (true) &#123; try &#123; for (Map.Entry&lt;String, CallbackListener&gt; entry : listeners.entrySet()) &#123; try &#123; entry.getValue().changed(getChanged(entry.getKey())); &#125; catch (Throwable t) &#123; listeners.remove(entry.getKey()); &#125; &#125; Thread.sleep(5000); // timely trigger change event &#125; catch (Throwable t) &#123; t.printStackTrace(); &#125; &#125; &#125; &#125;); t.setDaemon(true); t.start(); &#125; public void addListener(String key, CallbackListener listener) &#123; listeners.put(key, listener); listener.changed(getChanged(key)); // send notification for change &#125; private String getChanged(String key) &#123; return "Changed: " + new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()); &#125;&#125; Provider 端暴露服务12345678&lt;bean id="callbackService" class="com.alibaba.dubbo.samples.callback.impl.CallbackServiceImpl"/&gt;&lt;dubbo:service interface="com.alibaba.dubbo.samples.callback.api.CallbackService" ref="callbackService" connections="1" callbacks="1000"&gt; &lt;dubbo:method name="addListener"&gt; &lt;dubbo:argument index="1" callback="true"/&gt; &lt;!--&lt;dubbo:argument type="com.demo.CallbackListener" callback="true" /&gt;--&gt; &lt;/dubbo:method&gt;&lt;/dubbo:service&gt; 这里，Provider 需要在方法中声明哪个参数是 Callback 参数。 Consumer 端实现 Callback 接口123456CallbackService callbackService = ...;callbackService.addListener("foo.bar", new CallbackListener() &#123; public void changed(String msg) &#123; System.out.println("callback1:" + msg); &#125;&#125;); Callback 接口的实现类在 Consumer 端，当方法发生调用时，Consumer 端会自动 export 一个 Callback 服务。而 Provider 端在处理调用时，判断如果参数是 Callback，则生成了一个 proxy，因此服务实现类里在调用 Callback 方法的时候，会被传递到 Consumer 端执行 Callback 实现类的代码。 上述示例代码位于：https://github.com/dubbo/dubbo-samples/tree/master/dubbo-samples-callback 这种调用方式有点像消息的发布和订阅，但又有区别。比如当 Consumer 端 完成了Callback 服务的 export 后，如果后续重启了，这时 Provider 端就会调不通；同时 Provider 端如何清理掉这个 proxy 也是一个问题。 事件通知事件通知允许 Consumer 端在调用之前、调用之后或出现异常时，触发 oninvoke、onreturn、onthrow 三个事件。 12345&lt;bean id="demoCallback" class="com.alibaba.dubbo.samples.notify.impl.NotifyImpl" /&gt;&lt;dubbo:reference id="demoService" check="false" interface="com.alibaba.dubbo.samples.notify.api.DemoService" version="1.0.0" group="cn"&gt; &lt;dubbo:method name="sayHello" onreturn="demoCallback.onreturn" onthrow="demoCallback.onthrow"/&gt;&lt;/dubbo:reference&gt; 其中，NotifyImpl 的代码如下： 12345678910111213public class NotifyImpl implements Notify&#123; public Map&lt;Integer, String&gt; ret = new HashMap&lt;Integer, String&gt;(); public void onreturn(String name, int id) &#123; ret.put(id, name); System.out.println("onreturn: " + name); &#125; public void onthrow(Throwable ex, String name, int id) &#123; System.out.println("onthrow: " + name); &#125;&#125; oninvoke 方法参数与调用方法的参数相同； onreturn方法第一个参数为调用方法的返回值，其余为调用方法的参数； onthrow方法第一个参数为调用异常，其余为调用方法的参数。 上述配置中，sayHello方法为同步调用，因此事件通知方法的执行也是同步执行。可以配置 async=true让方法调用为异步，这时事件通知的方法也是异步执行的。特别强调一下，oninvoke方法不管是否异步调用，都是同步执行的。 事件通知的示例代码请参考：https://github.com/dubbo/dubbo-samples/tree/master/dubbo-samples-notify]]></content>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[API接口安全性设计]]></title>
    <url>%2F2019%2F05%2F18%2Fapi-security-specification%2F</url>
    <content type="text"><![CDATA[Token、Timestamp和Sign，保证接口的数据不被篡改和重复调用： Token授权机制：用户使用用户名密码登录后服务器给客户端返回一个Token（通常是UUID），并将Token-UserId以键值对的形式存放在缓存服务器中。服务端接收到请求后进行Token验证，如果Token不存在，说明请求无效。Token是客户端访问服务端的凭证。 时间戳超时机制：用户每次请求都带上当前时间的时间戳timestamp，服务端接收到timestamp后跟当前时间进行比对，如果时间差大于一定时间（比如5分钟），则认为该请求失效。时间戳超时机制是防御DOS攻击的有效手段。 签名机制：将 Token 和 时间戳 加上其他请求参数再用MD5或SHA-1算法（可根据情况加点盐）加密，加密后的数据就是本次请求的签名sign，服务端接收到请求后以同样的算法得到签名，并跟当前的签名进行比对，如果不一样，说明参数被更改过，直接返回错误标识。签名机制保证了请求参数不会被篡改。 拒绝重复调用（非必须）：客户端第一次访问时，将签名sign存放到缓存服务器中，超时时间设定为跟时间戳的超时时间一致，二者时间一致可以保证无论在timestamp限定时间内还是外 URL都只能访问一次。如果有人使用同一个URL再次访问，如果发现缓存服务器中已经存在了本次签名，则拒绝服务。如果在缓存中的签名失效的情况下，有人使用同一个URL再次访问，则会被时间戳超时机制拦截。这就是为什么要求时间戳的超时时间要设定为跟时间戳的超时时间一致。拒绝重复调用机制确保URL被别人截获了也无法使用（如抓取数据）。 1、客户端通过用户名密码登录服务器并获取Token2、客户端生成时间戳timestamp，并将timestamp作为其中一个参数3、客户端将所有的参数，包括Token和timestamp按照自己的算法进行排序加密得到签名sign4、将token、timestamp和sign作为请求时必须携带的参数加在每个请求的URL后边（http://url/request?token=123&amp;timestamp=123&amp;sign=123123123）5、服务端写一个过滤器对token、timestamp和sign进行验证，只有在token有效、timestamp未超时、缓存服务器中不存在sign三种情况同时满足，本次请求才有效]]></content>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[性能优化模式]]></title>
    <url>%2F2019%2F05%2F15%2Fperformance-tuning-pattern%2F</url>
    <content type="text"><![CDATA[在某些情况下，降低响应时间、提高系统吞吐量和提高服务可用性三者相互矛盾，不可兼得。例如：增加缓存可以降低平均响应时间，但是处理线程数量会因为缓存过大而有所限制，从而降低系统吞吐量；为了提高服务可用性，对异常请求重复调用是一个常用的做法，但是这会提高响应时间并降低系统吞吐量。 系统面临如下三个挑战：1. 日益增长的用户数量，2. 日渐复杂的业务，3. 急剧膨胀的数据。 设计原则最小可用原则两个关注点：1. 强调快速接入，快速完成；2. 实现核心功能可用。这是一个被普遍运用的原则，其目标是缩短测试周期，增加试错机会，避免过度设计。为了快速接入就必须最大限度地利用已有的解决方案或系统。从另外一个角度讲，一个解决方案或系统只要能够满足基本需求，就满足最小可用原则的应用需求。过度强调快速接入原则会导致重构风险的增加，原则上讲，基于该原则去设计系统需要为重构做好准备。 经济原则经济原则关注的是成本问题，看起来很像最小可用原则，但是它们之间关注点不同。最小可用原则的目标是通过降低开发周期，快速接入而实现风险可控，而快速接入并不意味着成本降低，有时候为了实现快速接入可能需要付出巨大的成本。软件项目的生命周期包括：预研、设计、开发、测试、运行、维护等阶段。最小可用原则主要运用在预研阶段，而经济原则可以运用在整个软件生命周期里，也可以只关注某一个或者几个阶段。例如：运行时经济原则需要考虑的系统成本包括单次请求的CPU、内存、网络、磁盘消耗等；设计阶段的经济原则要求避免过度设计；开发阶段的经济原则可能关注代码复用，工程师资源复用等。 代码复用原则代码复用原则分为两个层次：第一个层次使用已有的解决方案或调用已存在的共享库（Shared Library），也称为方案复用；第二个层次是直接在现有的代码库中开发，也称之为共用代码库。 方案复用是一个非常实用主义的原则，它的出发点就是最大限度地利用手头已有的解决方案，即使这个方案并不好。方案的形式可以是共享库，也可以是已存在的服务。方案复用的例子参见避免蚊子大炮模式的具体案例。用搜索引擎服务来解决查找附近商家的问题是一个性能很差的方案，但仍被很多工程师使用。方案复用原则的一个显著优点就是提高生产效率，例如：Java之所以能够得到如此广泛应用，原因之一就是有大量可以重复利用的开源库。实际上“Write once, run anywhere”是Java语言最核心的设计理念之一。基于Java语言开发的代码库因此得以在不同硬件平台、不同操作系统上更广泛地使用。 共用代码库要求在同一套代码库中完成所有功能开发。采用这个原则，代码库中的所有功能编译时可见，新功能代码可以无边界的调用老代码。另外，原代码库已存在的各种运行、编译、测试、配置环境可复用。主要有两个方面地好处：1. 充分利用代码库中已有的基础设施，快速接入新业务；2. 直接调用原代码中的基础功能或原語，避免网络或进程间调用开销，性能更佳。共用代码库的例子参见垂直分割模式的具体案例。 从设计的角度上讲，方案复用类似于微服务架构，而共用代码库和Monolithic Architecture很接近。总的来说，微服务倾向于面向接口编程，要求设计出可重用性的组件（Library或Service），通过分层组织各层组件来实现良好的架构。与之相对应，Monolith Architecture则希望尽可能在一套代码库中开发，通过直接调用代码中的基础功能或原語而实现性能的优化和快速迭代。使用Monolith Architecture有很大的争议，被认为不符合“设计模式”的理念。参考文献[4]，Monolithic Design主要的缺点包括：1. 缺乏美感；2. 很难重构；3. 过早优化（参见文献[6]Optimize judiciously）; 4. 不可重用；5. 限制眼界。微服务架构是很多互联网公司的主流架构。Monolithic Architecture也有其忠实的粉丝，例如：Tripadvisor的全球网站就共用一套代码库；基于性能的考虑，Linux最终选择的也是Monolithic kernel的模式。 奥卡姆剃刀原则一般而言，一个系统的代码量会随着其功能增加而变多。系统的健壮性有时候也需要通过编写异常处理代码来实现。异常考虑越周全，异常处理代码量越大。但是随着代码量的增大，引入Bug的概率也就越大，系统也就越不健壮。从另外一个角度来讲，异常流程处理代码也要考虑健壮性问题，这就形成了无限循环。所以在系统设计和代码编写过程中，奥卡姆剃刀原则要求：一个功能模块如非必要，就不要；一段代码如非必写，就不写。 奥卡姆剃刀原则和最小可用原则有所区别。最小可用原则主要运用于产品MVP阶段，本文所指的奥卡姆剃刀原则主要指系统设计和代码编写两个方面，这是完全不同的两个概念。MVP包含系统设计和代码编写，但同时，系统设计和代码编写也可以发生在成熟系统的迭代阶段。 性能恶化模式长请求拥塞反模式（High Latency Invocating AntiPattern）这是一种单次请求时延变长而导致系统性能恶化甚至崩溃的恶化模式。对于多线程服务，大量请求时间变长会使线程堆积、内存使用增加，最终可能会通过如下三种方式之一恶化系统性能： 1. 线程数目变多导致线程之间CPU资源使用冲突，反过来进一步延长了单次请求时间； 2. 线程数量增多以及线程中缓存变大，内存消耗随之剧增，对于基于Java语言的服务而言，又会更频繁地full GC，反过来单次请求时间会变得更长； 3. 内存使用增多，会使操作系统内存不足，必须使用Swap，可能导致服务彻底崩溃。 长请求拥塞反模式所导致的性能恶化现象非常普遍，所以识别该模式非常重要。典型的场景如下：某复杂业务系统依赖于多个服务，其中某个服务的响应时间变长，随之系统整体响应时间变长，进而出现CPU、内存、Swap报警。系统进入长请求拥塞反模式的典型标识包括：被依赖服务可用性变低、响应时间变长、服务的某段计算逻辑时间变长等。 多次请求杠杆反模式（Levered Multilayer Invocating AntiPattern）客户端一次用户点击行为往往会触发多次服务端请求，这是一次请求杠杆；每个服务端请求进而触发多个更底层服务的请求，这是第二次请求杠杆。每一层请求可能导致一次请求杠杆，请求层级越多，杠杆效应就越大。在多次请求杠杆反模式下运行的分布式系统，处于深层次的服务需要处理大量请求，容易会成为系统瓶颈。与此同时，大量请求也会给网络带来巨大压力，特别是对于单次请求数据量很大的情况，网络可能会成为系统彻底崩溃的导火索。典型恶化流程图如下图： 多次请求杠杆所导致的性能恶化现象非常常见，例如：对于美团推荐系统，一个用户列表请求会有多个算法参与，每个算法会召回多个列表单元（商家或者团购），每个列表单元有多种属性和特征，而这些属性和特征数据服务又分布在不同服务和机器上面，所以客户端的一次用户展现可能导致了成千上万的最底层服务调用。对于存在多次请求杠杆反模式的分布式系统，性能恶化与流量之间往往遵循指数曲线关系。这意味着，在平常流量下正常运行服务系统，在流量高峰时通过线性增加机器解决不了可用性问题。所以，识别并避免系统进入多次请求杠杆反模式对于提高系统可用性而言非常关键。 反复缓存反模式（Recurrent Caching AntiPattern）为了降低响应时间，系统往往在本地内存中缓存很多数据。缓存数据越多，命中率就越高，平均响应时间就越快。为了降低平均响应时间，有些开发者会不加限制地缓存各种数据，在正常流量情况下，系统响应时间和吞吐量都有很大改进。但是当流量高峰来临时，系统内存使用开始增多，触发了JVM进行full GC，进而导致大量缓存被释放（因为主流Java内存缓存都采用SoftReference和WeakReference所导致的），而大量请求又使得缓存被迅速填满，这就是反复缓存。反复缓存导致了频繁的full GC，而频繁full GC往往会导致系统性能急剧恶化。典型恶化流程图如下图： 性能优化模式水平分割模式（Horizontal partitioning Pattern）原理和动机一次请求总耗时=解析请求耗时 + ∑(获取数据耗时+处理数据耗时) + 组装返回结果耗时 大部分耗时长的服务主要时间都花在中间两个环节，即获取数据和处理数据环节。对于非计算密集性的系统，主要耗时都用在获取数据上面。获取数据主要有三个来源：本地缓存，远程缓存或者数据库，远程服务。三者之中，进行远程数据库访问或远程服务调用相对耗时较长，特别是对于需要进行多次远程调用的系统，串行调用所带来的累加效应会极大地延长单次请求响应时间，这就增大了系统进入长请求拥塞反模式的概率。如果能够对不同的业务请求并行处理，请求总耗时就会大大降低。 水平分割模式首先将整个请求流程切分为必须相互依赖的多个Stage，而每个Stage包含相互独立的多种业务处理（包括计算和数据获取）。完成切分之后，水平分割模式串行处理多个Stage，但是在Stage内部并行处理。如此，一次请求总耗时等于各个Stage耗时总和，每个Stage所耗时间等于该Stage内部最长的业务处理时间。 水平分割模式有两个关键优化点：减少Stage数量和降低每个Stage耗时。为了减少Stage数量，需要对一个请求中不同业务之间的依赖关系进行深入分析并进行解耦，将能够并行处理的业务尽可能地放在同一个Stage中，最终将流程分解成无法独立运行的多个Stage。降低单个Stage耗时一般有两种思路：1. 在Stage内部再尝试水平分割（即递归水平分割)，2. 对于一些可以放在任意Stage中进行并行处理的流程，将其放在耗时最长的Stage内部进行并行处理，避免耗时较短的Stage被拉长。 水平分割模式不仅可以降低系统平均响应时间，而且可以降低TP95响应时间（这两者有时候相互矛盾，不可兼得）。通过降低平均响应时间和TP95响应时间，水平分割模式往往能够大幅度提高系统吞吐量以及高峰时期系统可用性，并大大降低系统进入长请求拥塞反模式的概率。 具体案例伴随着算法工程师的持续迭代，算法数量越来越多，随之而来的结果就是客户端响应时间越来越长，系统很容易进入长请求拥塞反模式。曾经有一段时间，一旦流量高峰来临，出现整条服务链路的机器CPU、内存报警。在对系统进行分析之后，我们采取了如下三个优化措施，最终使得系统TP95时间降低了一半： 算法之间并行计算； 每个算法内部，多次特征获取进行了并行处理； 在调度线程对工作线程进行调度的时候，耗时最长的线程最先调度，最后处理。 缺点和优点对成熟系统进行水平切割，意味着对原系统的重大重构，工程师必须对业务和系统非常熟悉，所以要谨慎使用。水平切割主要有两方面的难点： 并行计算将原本单一线程的工作分配给多线程处理，提高了系统的复杂度。而多线程所引入的安全问题让系统变得脆弱。与此同时，多线程程序测试很难，因此重构后系统很难与原系统在业务上保持一致。 对于一开始就基于单线程处理模式编写的系统，有些流程在逻辑上能够并行处理，但是在代码层次上由于相互引用已经难以分解。所以并行重构意味着对共用代码进行重复撰写，增大系统的整体代码量，违背奥卡姆剃刀原则。 对于上面提到的第二点，举例如下：A和B是逻辑可以并行处理的两个流程，基于单线程设计的代码，假定处理完A后再处理B。在编写处理B逻辑代码时候，如果B需要的资源已经在处理A的过程中产生，工程师往往会直接使用A所产生的数据，A和B之间因此出现了紧耦合。并行化需要对它们之间的公共代码进行拆解，这往往需要引入新的抽象，更改原数据结构的可见域。 在如下两种情况，水平切割所带来的好处不明显： 一个请求中每个处理流程需要获取和缓存的数据量很大，而不同流程之间存在大量共享的数据，但是请求之间数据共享却很少。在这种情况下，流程处理完之后，数据和缓存都会清空。采用顺序处理模式，数据可以被缓存在线程局部存储（ThreadLocal）中而减少重复获取数据的成本；如果采用水平切割的模式，在一次请求中，不同流程会多次获取并缓存的同一类型数据，对于内存原本就很紧张的系统，可能会导致频繁full GC，进入反复缓存反模式。 某一个处理流程所需时间远远大于其他所有流程所需时间的总和。这种情况下，水平切割不能实质性地降低请求响应时间。 采用水平切割的模式可以降低系统的平均响应时间和TP95响应时间，以及流量高峰时系统崩溃的概率。虽然进行代码重构比较复杂，但是水平切割模式非常容易理解，只要熟悉系统的业务，识别出可以并行处理的流程，就能够进行水平切割。有时候，即使少量的并行化也可以显著提高整体性能。对于新系统而言，如果存在可预见的性能问题，把水平分割模式作为一个重要的设计理念将会大大地提高系统的可用性、降低系统的重构风险。总的来说，虽然存在一些具体实施的难点，水平分割模式是一个非常有效、容易识别和理解的模式。 垂直分割模式（Vertical partitioning Pattern）原理和动机对于移动互联网节奏的公司，新需求往往是一波接一波。基于代码复用原则，工程师们往往会在一个系统实现大量相似却完全不相干的功能。伴随着功能的增强，系统实际上变得越来越脆弱。这种脆弱可能表现在系统响应时间变长、吞吐量降低或者可用性降低。导致系统脆弱原因主要来自两方面的冲突：资源使用冲突和可用性不一致冲突。 资源使用冲突是导致系统脆弱的一个重要原因。不同业务功能并存于同一个运行系统里面意味着资源共享，同时也意味着资源使用冲突。可能产生冲突的资源包括：CPU、内存、网络、I/O等。例如：一种业务功能，无论其调用量多么小，都有一些内存开销。对于存在大量缓存的业务功能，业务功能数量的增加会极大地提高内存消耗，从而增大系统进入反复缓存反模式的概率。对于CPU密集型业务，当产生冲突的时候，响应时间会变慢，从而增大了系统进入长请求拥塞反模式的可能性。 不加区别地将不同可用性要求的业务功能放入一个系统里，会导致系统整体可用性变低。当不同业务功能糅合在同一运行系统里面的时候，在运维和机器层面对不同业务的可用性、可靠性进行调配将会变得很困难。但是，在高峰流量导致系统濒临崩溃的时候，最有效的解决手段往往是运维，而最有效手段的失效也就意味着核心业务的可用性降低。 垂直分割思路就是将系统按照不同的业务功能进行分割，主要有两种分割模式：部署垂直分割和代码垂直分割。部署垂直分割主要是按照可用性要求将系统进行等价分类，不同可用性业务部署在不同机器上，高可用业务单独部署；代码垂直分割就是让不同业务系统不共享代码，彻底解决系统资源使用冲突问题。 具体案例我们的挑战来自于美团推荐系统，美团客户端的多个页面都有推荐列表。虽然不同的推荐产品需求来源不同，但是为了实现快速的接入，基于共用代码库原则，所有的推荐业务共享同一套推荐代码，同一套部署。在一段时间内，我们发现push推荐和首页“猜你喜欢推荐”的资源消耗巨大。特别是在push推荐的高峰时刻，CPU和内存频繁报警，系统不停地full GC，造成美团用户进入客户端时，首页出现大片空白。 在对系统进行分析之后，得出两个结论： 首页“猜你喜欢”对用户体验影响更大，应该给予最高可用性保障，而push推荐给予较低可用性保障； 首页“猜你喜欢”和push推荐都需要很大的本地缓存，有较大的内存使用冲突，并且响应时间都很长，有严重的CPU使用冲突。 因此我们采取了如下措施，一方面，解决了首页“猜你喜欢”的可用性低问题，减少了未来出现可用性问题的概率，最终将其TP95响应时间降低了40%；另一方面也提高了其他推荐产品的服务可用性和高峰吞吐量。 将首页“猜你喜欢”推荐进行单独部署，而将push推荐和其他对系统资源要求不高的推荐部署在另一个集群上面； 对于新承接的推荐业务，新建一套代码，避免影响首页推荐这种最高可用性的业务。 缺点和优点 增加了维护成本。一方面代码库数量增多提高了开发工程师的维护成本，另一方面，部署集群的变多会增加运维工程师的工作量； 代码不共享所导致的重复编码工作。 解决重复编码工作问题的一个思路就是为不同的系统提供共享库（Shared Library），但是这种耦合反过来可能导致部署机器中引入未部署业务的开销。所以在共享库中要减少静态代码的初始化开销，并将类似缓存初始化等工作交给上层系统。总的来说，通过共享库的方式引入的开销可以得到控制。但是对于业务密集型的系统，由于业务往往是高度定制化的，共用一套代码库的好处是开发工程师可以采用Copy-on-write的模式进行开发，需要修改的时候随时拷贝并修改。共享库中应该存放不容易变化的代码，避免使用者频繁升级，所以并不适合这种场景。因此，对于业务密集型的系统，分代码所导致的重复编码量是需要权衡的一个因素。 垂直分割是一个非常简单而又有效的性能优化模式，特别适用于系统已经出现问题而又需要快速解决的场景。部署层次的分割既安全又有效。需要说明的是部署分割和简单意义上的加机器不是一回事，在大部分情况下，即使不增加机器，仅通过部署分割，系统整体吞吐量和可用性都有可能提升。所以就短期而言，这几乎是一个零成本方案。对于代码层次的分割，开发工程师需要在业务承接效率和系统可用性上面做一些折衷考虑。 恒变分离模式（Runtime 3NF Pattern）原理和动机基于性能的设计要求变化的数据和不变的数据分开，这一点和基于面向对象的设计原则相悖。在面向对象的设计中，为了便于对一个对象有整体的把握，紧密相关的数据集合往往被组装进一个类，存储在一个数据库表，即使有部分数据冗余（关于面向对象与性能冲突的讨论网上有很多文章，本文不细讲）。很多系统的主要工作是处理变化的数据，如果变化的数据和不变的数据被紧密组装在一起，系统对变化数据的操作将引入额外的开销。而如果易变数据占总数据比例非常小，这种额外开销将会通过杠杆效应恶化系统性能。分离易变和恒定不变的数据在对象创建、内存管理、网络传输等方面都有助于性能提高。 恒变分离模式的原理非常类似与数据库设计中的第三范式（3NF）：第三范式主要解决的是静态存储中重复存储的问题，而恒变分离模式解决的是系统动态运行时候恒定数据重复创建、传输、存储和处理的问题。按照3NF，如果一个数据表的每一记录都依赖于一些非主属性集合，而这些非主属性集合大量重复出现，那么应该考虑对被依赖的非主属性集合定义一个新的实体（构建一个新的数据表），原数据库的记录依赖于新实体的ID。如此一来数据库重复存储数据量将大大降低。类似的，按照恒变分离模式，对于一个实体，如果系统处理的只是这个实体的少量变化属性，应该将不变的属性定义为一个新实体（运行时的另一个类，数据库中的另一个表），原来实体通过ID来引用新实体，那么原有实体在运行系统中的数据传输、创建、网络开销都会大大降低。 案例分析我们的挑战是提供一个高性能、高一致性要求的团购服务（DealService）。系统存在一些多次请求杠杆反模式问题，客户端一次请求会导致几十次DealService读取请求，每次获取上百个团购详情信息，服务端单机需要支持每秒万次级别的吞吐量。基于需求，系统大体框架设计如下： 每个DealService定期从持久层同步所有发生变化的deal信息，所有的deal信息保存在内存里面。在最初的设计里面，数据库只有一个数据表DealModelTable，程序里面也只有一个实体类DealModel。由于销量、价格、用户评价等信息的频发变化，为了达到高一致性要求，服务系统每分钟需要从数据库同步几万条记录。随着美团团购数量的增多和用户活跃度的增加，系统出现了三个问题： 团购服务网卡频繁报警，由于这是高性能低延时服务，又导致了大量的客户端超时异常； 频繁的full GC，这是由于每条数据库记录更新都会导致运行系统里面老的DealModel实体被销毁，新的DealModels实体被创建； 数据库从库滞后主库，使得服务数据一致性降低，原因是数据库系统写数据量巨大。 在对系统进行分析之后，我们采用了如下措施，大大降低了网络传输的数据量，缓解了主从数据库同步压力，使得客户端的超时异常从高峰时候的9%降低到了小于0.01%（低于万分之一）： 将DealModelTable中的销量、价格、用户评价等常变的信息单独构建一张数据表VariableDealModel； 同时在代码中为销量、价格、用户评价等常变数据创建一个单独的类VariableDealModel； DealService对两张表进行分别同步； 如果DealModelTable的记录产生了更新，运行系统销毁老的DealModel实体并创建新的DealModel实体； 如果只是VariableDealModel的记录产生了更新，只对VariableDealModel的属性进行更改。 缺点和优点 不符合面向对象的设计原则。原本概念上统一的实体被切分成多个实体，会给开发工程师带来一些理解上的困难，因此增加维护成本。进一步而言，这会增加引入额外Bug的概率（实际上面向对象之所以如此受欢迎的一个重要原因就是容易理解）。 增加了类不变量（Class invariant）的维护难度。很多情况下，Class invariant是通过语言所提供的封装（Encapsulation）特性来维护的。当一个类变成多个类，Class invariant可能会被破坏。如果必须维护Class invariant，而这种Class invariant又发生在不同实体之间，那么往往是把不变的属性从不变实体移到易变的实体中去。 一张数据库表变成多张，也会增加维护成本。 在如下两种场景下，恒变分离模式所带来的好处有限： 易变数据导致的操作和传输并不频繁，不是系统主要操作； 易变数据占整体数据的比例很高，杠杆效应不显著，通过恒变分离模式不能根本性地解决系统性能问题。 总的来说，恒变分离模式非常容易理解，其应用往往需要满足两个条件：易变数据占整体数据比例很低（比例越低，杠杆效应越大）和易变数据所导致的操作又是系统的主要操作。在该场景下，如果系统性能已经出现问题，牺牲一些可维护性就显得物有所值。 大部分系统都是由多种类型的数据构成，大多数数据类型的都包含易变、少变和不变的属性。盲目地进行恒变分离会导致系统的复杂度指数级别的增加，系统变得很难维护，所以系统设计者必须在高性能和高维护性之间找到一个平衡点。作者的建议是：对于复杂的业务系统，尽量按照面向对象的原则进行设计，只有在性能出现问题的时候才开始考虑恒变分离模式；而对于高性能，业务简单的基础数据服务，恒变分离模式应该是设计之初的一个重要原则。 数据局部性模式（Locality Pattern）原理和动机数据局部性模式是多次请求杠杆反模式的针对性解决方案。在大数据和强调个性化服务的时代，一个服务消费几十种不同类型数据的现象非常常见，同时每一种类型的数据服务都有可能需要一个大的集群（多台机器）提供服务。这就意味着客户端的一次请求有可能会导致服务端成千上万次调用操作，很容易使系统进入多次请求杠杆反模式。在具体开发过程中，导致数据服务数量暴增的主要原因有两个：1. 缓存滥用以及缺乏规划，2. 数据量太大以至于无法在一台机器上提供全量数据服务。数据局部性模的核心思想是合理组织数据服务，减少服务调用次数。具体而言，可以从服务端和客户端两个方面进行优化。 服务端优化方案的手段是对服务进行重新规划。对于数据量太大以至于无法在一台机器上存储全量数据的场景，建议采用Bigtable或类似的解决方案提供数据服务。典型的Bigtable的实现包括Hbase、Google Cloud Bigtable等。实际上数据局部性是Bigtable的一个重要设计原则，其原理是通过Row key和Column key两个主键来对数据进行索引，并确保同一个Row key索引的所有数据都在一台服务器上面。通过这种数据组织方式，一次网络请求可以获取同一个Row key对应的多个Column key索引的数据。缺乏规划也是造成服务数量剧增的一个重要原因。很多通过统计和挖掘出来的特征数据往往是在漫长的时间里由不同team独立产生的。而对于每种类型数据，在其产生之初，由于不确定其实际效果以及生命周期，基于快速接入原则，服务提供者往往会用手头最容易实施的方案，例如采用Redis Cache（不加选择地使用缓存会导致缓存滥用）。数据服务之间缺乏联动以及缺乏标准接入规划流程就会导致数据服务数量膨胀。数据局部性原则对规划的要求，具体而言是指：1. 数据由尽可能少的服务器来提供，2. 经常被一起使用的数据尽可能放在同一台服务器上。 客户端优化有如下几个手段： 本地缓存，对于一致性要求不高且缓存命中率较高的数据服务，本地缓存可以减少服务端调用次数； 批处理，对于单机或者由等价的机器集群提供的数据服务，尽可能采用批处理方式，将多个请求合成在一个请求中； 客户端Hash，对于需要通过Hash将请求分配到不同数据服务机器的服务，尽量在客户端进行Hash，对于落入同一等价集群的请求采用批处理方式进行调用。 案例分析我们的挑战来自于美团的推荐、个性化列表和个性化搜索服务。这些个性化系统需要获取各种用户、商家和团购信息。信息类型包括基本属性和统计属性。最初，不同属性数据由不同的服务提供，有些是RPC服务，有些是Redis服务，有些是HBase或者数据库，参见下图： 通常而言，客户端每个用户请求都会触发多个算法。一方面，每个算法都会召回几十甚至几百个团购或者商家ID，团购和商家基础属性被均匀地分配到几十台Redis里面（如下图），产生了大量的Redis请求，极端情况下，一次客户端请求所触发的团购基础数据请求就超过了上千次；另一方面，用户特征属性信息有十几种，每种属性也由单独的服务提供，服务端网络调用次数暴增。在一段时间里，很多系统都进入了多次请求杠杆反模式，Redis服务器的网卡经常被打死，多次进行扩容，提高线程池线程数量，丝毫没有改善。 在对系统进行分析之后，按照数据局部性模式的原则，我们采用了如下手段，彻底解决了系统多次请求杠杆反模式的问题： 采用大内存服务器存储所有的团购和商家基础信息，每个算法只要一次网络请求就可以获取所有的信息； 服务端采用多线程方式提供服务，避免了Redis单一线程模式下单个请求慢所带来的连锁效应； 借鉴类似Bigtable的数据组织方式，将用户的多种特征采用两个维度（用户维度和特征类型）进行索引，确保同一用户的信息只存放在一台机器上面，减少网络调用数量。 缺点和优点数据局部性模式并不适用于系统初级阶段。在初级阶段，最小可用原则往往是主要设计原则之一，出于两方面的考虑：一方面，在初级阶段，很难预测所要提供服务的数据是否有效而且能够长期使用，以及未来的调用量；另一方面，在初级阶段，工程师可能无法预测最终的调用模式，而不同的调用模式会导致数据局部性方案的设计不同。对于已经大量使用的数据服务，采用数据局部性模式进行重构必然要改变老的调用模式，这一方面会引入新的Bug，另一方面也意味着巨大的工作量。需要特别强调的是，数据处于系统的最底层，对于结构复杂而又重要的数据，重构所带来可靠性、一致性和工作量都是需要权衡的因素。对于请求量比较小的数据服务，即使一次请求会触发严重的请求杠杆效应，但是如果原始触发请求数量在可预见的时间内没有明显变多的迹象，进行数据服务重构可能得不偿失。 数据局部性模式能够解决多次请求杠杆反模式所导致的问题，但它并非大数据的产物，CPU、编译器的设计理念里早就融入了该模式，所以很容易被工程师理解。虽然过度设计在系统初级阶段是一个要尽量避免的事情，但是理解和掌握数据局部性模式对于设计出一个可扩展、可重用的系统有很大帮助。很多成熟的系统因为多次请求杠杆反模式而导致系统频繁崩溃，理解数据局部性模式的原则有助于提高工程师分析解决问题的能力，而在确认了系统存在请求杠杆问题后，数据局部性原则是一件非常锐利的武器。 避免蚊子大炮模式（Avoiding Over-generalized Solution Pattern）原理和动机“用大炮打蚊子”本来是大材小用的意思，但是细致想一想，用大炮打蚊子，成功率不高。对于开发工程师而言，一方面为了快速承接业务，按照方案复用原则，总是尽可能地利用现有系统，这使得系统功能越来越强大；另一方面，提高系统的通用性或可重用性也是工程师们在设计系统的一个重要目标。随着这两个过程的相互独立演化，采用通用方案解决特定问题的现象随处可见，形象地说，这就像大炮打蚊子。大炮成本很高，蚊子的数量众多，最终的结局往往是蚊子战胜了大炮。 “避免蚊子大炮模式”是经济原则在运行时系统的运用，它要求采用最节省资源（CPU、内存等）的方法来解决所面临的问题，资源浪费会带来未来潜在的风险。工程师接到一个需求的时候，需要思考的不仅仅是如何复用现有的系统，减少开发时间，还需要考虑现有系统为处理每个新需求访问所需运行时成本，以及新需求的预期访问量。否则，不加辨别地利用现有系统，不仅仅增大了重构风险，还有可能交叉影响，对现有系统所支持的服务造成影响。从另外一个角度讲，工程师在构建一个可重用系统的时候，要明确其所不能解决和不建议解决的问题，而对于不建议解决的问题，在文档中标明潜在的风险。 案例分析我们的挑战是为移动用户寻找其所在位置附近的商家信息。美团有非常完善的搜索系统，也有资深的搜索工程师，所以一个系统需要查找附近的商家的时候，往往第一方案就是调用搜索服务。但是在美团，太多的服务有基于LBS的查询需求，导致搜索请求量直线上升，这本来不属于搜索的主营业务，在一段时间里面反倒成了搜索的最多请求来源。而搜索引擎在如何从几十万商家里面找最近的几百商家方面的性能非常差，因此一段时间里，搜索服务频繁报警。不仅仅搜索服务可用性受到了影响，所有依赖于LBS的服务的可用性都大大降低。 在对系统分析之后，我们认为更适合解决最短直线距离的算法应该是k-d tree，在快速实现了基于k-d tree的LBS Search解决方案之后，我们用4台服务器轻松解决了30多台搜索服务器无法解决的问题，平均响应时间从高峰时的100ms降低到300ns，性能取得了几百倍的提高。 缺点和优点避免蚊子大炮模式的问题和数据局部性模式类似，都与最小可用原则相冲突。在系统设计初级阶段，寻求最优方案往往意味着过度设计，整个项目在时间和成本变得不可控，而为每个问题去找最优秀的解决方案是不现实的奢求。最优化原则的要求是全面的，不仅仅要考虑的运行时资源，还需要考虑工程师资源和时间成本等，而这些点往往相互矛盾。在如下情况下，避免蚊子大炮模式所带来的好处有限：在可预见的未来，某个业务请求量非常小，这时候花大量精力去找最优技术方案效果不明显。 在设计阶段，避免蚊子大炮模式是一个需要工程师去权衡的选择，需要在开发成本和系统运行成本之间保持一个平衡点。当很多功能融入到一个通用系统里而出现性能问题的时候，要拆分出来每一个功能点所造成的影响也不是件轻易的事情，所以采用分开部署而共用代码库的原则可以快速定位问题，然后有针对性地解决“蚊子大炮”问题。总的来说，在设计阶段，避免蚊子大炮模式是工程师们进行分析和设计的一个重要准则，工程师可以暂时不解决潜在的问题，但是一定要清楚潜在的危害。构建可重用系统或方案，一定要明确其所不能解决和不建议解决的问题，避免过度使用。 实时离线分离模式（Sandbox Pattern）原理和动机本模式的极端要求是：离线服务永远不要调用实时服务。该模式比较简单也容易理解，但是，严格地讲它不是一种系统设计模式，而是一种管理规范。离线服务和在线服务从可用性、可靠性、一致性的要求上完全不同。原则上，工程师在编写离线服务代码的时候，应该遵循的就是离线服务编程规范，按照在线服务编程规范要求，成本就会大大提高，不符合经济原则；从另外一方面讲，按照离线服务的需求去写在线服务代码，可用性、可靠性、一致性等往往得不到满足。 具体而言，实时离线分离模式建议如下几种规范： 如果离线程序需要访问在线服务，应该给离线程序单独部署一套服务； 类似于MapReduce的云端多进程离线程序禁止直接访问在线服务； 分布式系统永远不要直接写传统的DBMS。 案例分析因为违反实时离线分离模式而导致的事故非常常见。有一次，因为一个离线程序频繁的向Tair集群写数据，每一次写10M数据，使得整个Tair集群宕机。另一次，因为Storm系统直接写MySQL数据库导致数据库连接数耗尽，从而使在线系统无法连接数据库。 缺点和优点为了实现实时在线分离，可能需要为在线环境和离线环境单独部署，维护多套环境所带来运维成本是工程师需要考虑的问题。另一方面，在线环境的数据在离线环境中可能很难获取，这也是很多离线系统直接访问在线系统的原因。但是，遵从实时离线分离模式是一个非常重要的安全管理准则，任何违背这个准则的行为都意味着系统性安全漏洞，都会增大线上故障概率。 降级模式（Degradation Pattern）原理和动机降级模式是系统性能保障的最后一道防线。理论上讲，不存在绝对没有漏洞的系统，或者说，最好的安全措施就是为处于崩溃状态的系统提供预案。从系统性能优化的角度来讲，不管系统设计地多么完善，总会有一些意料之外的情况会导致系统性能恶化，最终可能导致崩溃，所以对于要求高可用性的服务，在系统设计之初，就必须做好降级设计。根据作者的经验，良好的降级方案应该包含如下措施： 在设计阶段，确定系统的开始恶化数值指标（例如：响应时间，内存使用量）； 当系统开始恶化时，需要第一时间报警； 在收到报警后，或者人工手动控制系统进入降级状态，或者编写一个智能程序让系统自动降级； 区分系统所依赖服务的必要性，一般分为：必要服务和可选服务。必要服务在降级状态下需要提供一个快速返回结果的权宜方案（缓存是常见的一种方案），而对于可选服务，在降级时系统果断不调用； 在系统远离恶化情况时，需要人工恢复，或者智能程序自动升级。 典型的降级策略有三种：流量降级、效果降级和功能性降级。流量降级是指当通过主动拒绝处理部分流量的方式让系统正常服务未降级的流量，这会造成部分用户服务不可用；效果降级表现为服务质量的降级，即在流量高峰时期用相对低质量、低延时的服务来替换高质量、高延时的服务，保障所有用户的服务可用性；功能性降级也表现为服务质量的降级，指的是通过减少功能的方式来提高用户的服务可用性。效果降级和功能性降级比较接近，效果降级强调的是主功能服务质量的下降，功能性降级更多强调的是辅助性功能的缺失。做一个类比如下：计划将100个工程师从北京送到夏威夷度假，但是预算不够。采用流量降级策略，只有50工程师做头等舱去了夏威夷度假，其余工程师继续编写程序（这可不好）；效果降级策略下，100个工程师都坐经济舱去夏威夷；采用功能性降级策略，100个工程师都坐头等舱去夏威夷，但是飞机上不提供食品和饮料。 案例分析我们的系统大量使用了智能降级程序。在系统恶化的时候，智能降级程序自动降级部分流量，当系统恢复的时候，智能降级程序自动升级为正常状态。在采用智能降级程序之前，因为系统降级问题，整体系统不可用的情况偶尔发生。采用智能降级程序之后，基本上没有因为性能问题而导致的系统整体不可用。我们的智能降级程序的主要判定策略是服务响应时间，如果出现大量长时间的响应异常或超时异常，系统就会走降级流程，如果异常数量变少，系统就会自动恢复。 缺点和优点为了使系统具备降级功能，需要撰写大量的代码，而降级代码往往比正常业务代码更难写，更容易出错，所以并不符合奥卡姆剃刀原则。在确定使用降级模式的前提下，工程师需要权衡这三种降级策略的利弊。大多数面向C端的系统倾向于采用效果降级和功能性降级策略，但是有些功能性模块（比如下单功能）是不能进行效果和功能性降级的，只能采用流量降级策略。对于不能接受降级后果的系统，必须要通过其他方式来提高系统的可用性。 总的来说，降级模式是一种设计安全准则，任何高可用性要求的服务，必须要按照降级模式的准则去设计。对于违背这条设计原则的系统，或早或晚，系统总会因为某些问题导致崩溃而降低可用性。不过，降级模式并非不需要成本，也不符合最小可用原则，所以对于处于MVP阶段的系统，或者对于可用性要求不高的系统，降级模式并非必须采纳的原则。 其他性能优化建议对于无法采用系统性的模式方式讲解的性能优化手段，作者也给出一些总结性的建议： 1. 删除无用代码有时候可以解决性能问题，例如：有些代码已经不再被调用但是可能被初始化，甚至占有大量内存；有些代码虽然在调用但是对于业务而言已经无用，这种调用占用CPU资源。 2. 避免跨机房调用，跨机房调用经常成为系统的性能瓶颈，特别是那些伪batch调用（在使用者看起来是一次性调用，但是内部实现采用的是顺序单个调用模式）对系统性能影响往往非常巨大 。 总结Christopher Alexander曾说过：”Each pattern describes a problem which occurs over and over again in our environment, and then describes the core of the solution to that problem, in such a way that you can use this solution a million times over, without ever doing it the same way twice” 。 尽管Christopher Alexander指的是建筑模式，软件设计模式适用，基于同样的原因，性能优化模式也适用。每个性能优化模式描述的都是工程师们日常工作中经常出现的问题，一个性能优化模式可以解决确定场景下的某一类型的问题。所以要理解一个性能优化模式不仅仅要了解性能模式的所能解决的问题以及解决手段，还需要清楚该问题所发生的场景和需要付出的代价。 参考文献 Chang F, Dean J, Ghemawat S, et al. Bigtable: A Distributed Storage System for Structured Data Gamma E, Helm R, Johnson R, et al. Design Patterns-Elements of Reusable Object-Oriented Software. Machinery Industry, 2003 Motlik F. Monolithic Core Versus Full Microservice Architecture Monolithic Design WikiWikiWeb. Bovet D P, Cesati M. Understanding the Linux Kernel. 3rd ed. O’Reilly Media, 2005. Bloch J. Effective Java. 2nd ed. Addison-Wesley, 2008. Alexander C, Ishikawa S, Silverstein M. A Pattern Language: Towns, Buildings, Construction. Oxford University Press, 1977.]]></content>
      <tags>
        <tag>performance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何减少团队的低质量代码？]]></title>
    <url>%2F2019%2F05%2F06%2Fcode-quality%2F</url>
    <content type="text"><![CDATA[第二个方向，就是降低员工编写高质量代码的难度。第三个方向，是要确保由最专业的人员做自己最专业的事情。他们只需要提交这样的代码，然后你的框架自动为他们做好任务调度器、错误捕捉和处理、日志记录和处理、dry-run、重试、API、相关的 UI 界面等等各种逻辑，执行好相关的单元测试：主程每天应该看完所有的提交记录强制上静态检测。制定编码规范或者使用现成的规范强制 code review保证一定的单元测试覆盖率通过培训、技术分享、招聘等手段提升程序员素质。 代码结构是真实业务场景的写照，如果业务规划和前景不够清晰，代码是好不了的，不论我们采取多么灵活的处理方案。虽然我们可以通过技术手段，让这种复杂性更容易被理解，但是复杂性的程度却本质上没有改变。因此，工程师们就不得不提高自己在业务上的话语权，对问题域有更深入的理解。 能力+态度 &gt; 经验 + 学历 自动化运行你的产品 自动化运行以上各种检测工具 这些工具只能提高产品的下限，不能提升产品的上限]]></content>
      <tags>
        <tag>code-quality</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[后台token防重复提交]]></title>
    <url>%2F2019%2F04%2F12%2Frepeat-submit-interceptor%2F</url>
    <content type="text"><![CDATA[思路 添加拦截器，拦截需要防重复提交的请求 通过注解@Token来添加token/移除token 前端页面表单添加（如果是Ajax请求则需要在请求的json数据中添加token值） 核心代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394/** * com.xxx.interceptor.TokenInterceptor.java * Copyright 2018 Lifangyu, Inc. All rights reserved. */package com.xxx.common.interceptor;import org.apache.log4j.Logger;import org.springframework.web.method.HandlerMethod;import org.springframework.web.servlet.handler.HandlerInterceptorAdapter;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.lang.reflect.Method;import java.util.Random;import java.util.UUID;/** * Desc:防重复提交的拦截器 * &lt;p&gt; * Created by lifangyu on 2018/02/27. */public class TokenInterceptor extends HandlerInterceptorAdapter &#123; Logger logger = Logger.getLogger(TokenInterceptor.class); static String splitFlag = "_"; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if (handler instanceof HandlerMethod) &#123; HandlerMethod handlerMethod = (HandlerMethod) handler; Method method = handlerMethod.getMethod(); Token annotation = method.getAnnotation(Token.class); if (annotation == null) &#123; return true; &#125; boolean needSaveSession = annotation.add(); if (needSaveSession) &#123; Random random = new Random(); String uuid = UUID.randomUUID().toString().replace(splitFlag, String.valueOf(random.nextInt(100000))); String tokenValue = String.valueOf(System.currentTimeMillis()); request.setAttribute("token", uuid + splitFlag + tokenValue); // session 中 token 的key 每次都是变化的[适应浏览器 打开多个带有token的页面不会有覆盖session的key] request.getSession(true).setAttribute(uuid, tokenValue); &#125; boolean needRemoveSession = annotation.remove(); if (needRemoveSession) &#123; if (isRepeatSubmit(request)) &#123; logger.warn("please don't repeat submit,url:" + request.getServletPath()); return false; &#125; String clinetToken = request.getParameter("token"); if (clinetToken != null &amp;&amp; clinetToken.indexOf(splitFlag) &gt; -1) &#123; request.getSession(true).removeAttribute(clinetToken.split("_")[0]); &#125; &#125; return true; &#125; else &#123; return super.preHandle(request, response, handler); &#125; &#125; /** * 判断是否是重复提交 * * @param request * @return */ private boolean isRepeatSubmit(HttpServletRequest request) &#123; String clinetToken = request.getParameter("token"); if (clinetToken == null) &#123; return true; &#125; if (clinetToken.indexOf(splitFlag) &lt;= -1) &#123; return false; &#125; String uuid = clinetToken.split("_")[0]; String token = clinetToken.split("_")[1]; String serverToken = (String) request.getSession(true).getAttribute(uuid); if (serverToken == null) &#123; return true; &#125; if (!serverToken.equals(token)) &#123; return true; &#125; return false; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435/** * com.xxx.interceptor.Token.java * Copyright 2018 Lifangyu, Inc. All rights reserved. */package com.xxx.common.interceptor;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * Desc:Token 注解 * &lt;p&gt; * Created by lifangyu on 2018/02/27. */@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface Token &#123; /** * 添加token的开关[true：添加；false:不添加，default：false] * * @return */ boolean add() default false; /** * 移除token的开关[true：删除；false:不删除，default：false] * * @return */ boolean remove() default false;&#125; 12345678&lt;!-- 拦截器配置 --&gt;&lt;mvc:interceptors&gt; &lt;!-- 配置Token拦截器，防止用户重复提交数据 --&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/**"/&gt; &lt;bean class="com.xxx.interceptor.TokenInterceptor"/&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 123456@Token(add = true)@RequestMapping("toXxxHtml")public String toXxxHtml(Model mv) &#123; ...... return "xxx/xxxHtml";&#125; 123456&lt;form id="xxx_submit_form" class="form-horizontal" action="$&#123;ctx&#125;/xxx/addXxx.do" method="post"&gt; ...... &lt;!-- 注：name必须是token --&gt; &lt;input type="hidden" name="token" value="$&#123;token!''&#125;"/&gt; ......&lt;/form&gt; 123456@Token(remove = true)@RequestMapping("addXxx")public String addXxx() throws Exception &#123; ...... return "redirect:toXxxHtml.do";&#125;]]></content>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作中如何学好技术]]></title>
    <url>%2F2019%2F04%2F01%2Flearning-at-work%2F</url>
    <content type="text"><![CDATA[引言古人云：“活到老，学到老。”互联网算是最辛苦的行业之一，“加班”对工程师来说已是“家常便饭”，同时互联网技术又日新月异，很多工程师都疲于应付，叫苦不堪。以至于长期以来流传一个很广的误解：35岁是程序员工作的终点。 如何在繁忙的工作中做好技术积累，构建个人核心竞争力，相信是很多工程师同行都在思考的问题。本文是我自己的一些总结，试图从三个方面来解答： 第一部分阐述了一些学习的原则。任何时候，遵循一些经过检验的原则，都是影响效率的重要因素，正确的方法是成功的秘诀。 提升工作和学习效率的另一个重要因素是释惑和良好心态。第二部分分析了我在工作中碰到和看到的一些典型困惑。 成为优秀的架构师是大部分初中级工程师的阶段性目标。第三部分剖析架构师的能力模型，让大家对目标所需能力有一个比较清晰的认知。 如何学习在繁忙的工作中，持之以恒、不断学习和进步是一件艰巨的任务，需要坚强的毅力和坚定的决心。如果方法不得当，更是事倍功半。幸好我们的古人和现在哲人已经总结了很多优秀的学习方法论，这里汇总了一些重要原则。遵循这些方法必会对大家的工作学习大有裨益。 贵在坚持有报道指出，过去几十年的知识量超过之前人类几千年的知识量总和。而计算机领域绝对是当代知识更新最快的领域之一，因此，工程师必须要接受这样一个现实，现在所掌握的深厚知识体系很快就会被淘汰。要想在计算机领域持续做优秀架构师，就必须不停的学习，掌握最新技术。总之，学不可以已。 所谓“冰冻三尺，非一日之寒，水滴石穿，非一日之功”，通往架构师的道路漫长而又艰巨，轻易放弃，则所有付出瞬间付之东流。要想成为优秀的架构师，贵在坚持！ 虽然知识更新很快，但是基础理论的变化却非常缓慢。这就是“道”和“象”关系，纵是世间万象，道却万变不离其宗。对于那些非常基础的理论知识，我们需要经常复习，也就是“学而时习之”。 重视实践古人云：“纸上得来终觉浅，绝知此事要躬行。” 学习领域有所谓721模型：个人的成长70%来自于岗位实践，20%来自向他人学习，10%来自于培训。虽然这种理论存在争议，但对于工程师们来说，按照实践、学习和培训的方式进行重要性排序，大致是不错的。所以重视实践，在实践中成长是最重要的学习原则。 人类的认知有两种：感性认知和理性认知。这两种认知互相不可替代性。实践很大程度来自于感性学习，看书更像是理性学习。以学开汽车做例子，很难想象什么人能够仅仅通过学习书本知识就会开汽车。 书本知识主要是传道——讲述抽象原型，而对其具体应用场景的讲述往往含糊其辞，对抽象原型之间的关系也是浅尝辄止。采用同样精确的语言去描述应用场景和关联关系将会失去重点，让人摸不着头脑。所以，仅仅通过看书来获得成长就像是用一条腿走路。 重视实践，充分运用感性认知潜能，在项目中磨炼自己，才是正确的学习之道。在实践中，在某些关键动作上刻意练习，也会取得事半功倍的效果。 重视交流牛顿说：“如果说我看得比别人远一些，那是因为我站在巨人的肩膀上。”我们需要从别人身上学习。从老师、领导、同事、下属甚至对手身上学习，是快速成长的重要手段。 向老师和领导学习已经是人们生活习惯的一部分了。但是从同事甚至对手那里学习也很重要，因为这些人和我们自身更相似。所以要多多观察，取其所长，弃其所短。对于团队的小兄弟和下属，也要“不耻下问”。 此外，在项目中积极参与具体方案讨论也非常重要。参与者先验感知了相关背景，并且讨论的观点和建议也是综合了发言者多种知识和技能。所以，讨论让参与者能够非常全面，立体地理解书本知识。同时，和高手讨论，他们的观点就会像修剪机剪树枝一样，快速的剪掉自己知识领域里面的疑惑点。 重视总结和输出工程师在实践中会掌握大量细节，但是，即使掌握了所有细节，却没有深刻的总结和思考，也会陷入到“学而不思则罔”的境地。成长的“量变”来自于对细节的逐渐深入地把控，而真正的“质变”来自于对“道”的更深层次的理解。 将经验输出，接受别人的检验是高层次的总结。这种输出不仅帮助了别人，对自身更是大有裨益。总结的方式有很多，包括组织分享，撰写技术文章等等。当然“日三省吾身”也是不错的总结方式。总之，多多总结，多多分享，善莫大焉！ 解答别人的问题也是个人成长的重要手段。有时候，某个问题自己本来不太懂，但是在给别人讲解的时候却豁然开朗。所以，“诲人不倦”利人惠己。 重视规划凡事预则立，不预则废。对于漫长的学习生涯而言，好的计划是成功的一半。 长期规划长期规划的实施需要毅力和决心，但是做正确的长期规划还需要高瞻远瞩的眼界、超级敏感的神经和中大奖的运气。对于大部分人来说，长期规划定主要是“定方向”。但遵循如下原则能够减少犯方向性错误的概率： 远离日暮西山的行业。 做自己感兴趣的事情。 做有积累的事情。 一边走一边看，切勿一条道走到黑。 短期规划良好的短期规划应该在生活、成长、绩效和晋升之间取得平衡。大部分公司都会制定一个考核周期——少则一个月，多则一年。所以不妨以考核周期作为短期学习规划周期。本质上，规划是一个多目标优化问题，它有一系列的理论方案，这里不一一细说。基于相关理论，我给出一个简单易行的方案： 确定目标优先级。比如：成长、生活、绩效。 确定每个目标的下限。从优化理论的角度来看，这被称为约束。比如绩效必须在一般以上，之前已经规划好的旅行不能更改，必须读完《Effective Java》等等。 优先为下限目标分配足够的资源。比如，事先规划好的旅行需要10天，这10天就必须预算出去。 按照各主目标的顺序依次分配资源。比如，最终分配给学习的时间是10天。 在给定的学习预算下，制定学习目标，要激进。然后给出执行方案。比如，学习目标是掌握基本的统计学知识，并成为Java专家。具体方案为：完成《Effective Java》、《Java Performance》、《Design Pattern》、《Head First Statistics》四本书的阅读。 对规划中的各学习任务按目标优先级进行排序，并最先启动优先级最高的任务。比如，最高优先级是掌握统计理论，那么就要先看《Head First Statistics》。 对于该方案，要注意以下几点： 最低目标必须能够轻松达成的目标，否则，从优化理论的角度来讲，该命题无解。比如，类似“半年内完成晋级两次、绩效全部S、从菜鸟成为Java专家”就不太合适作为最低目标。总之，要区分理想和梦想。 主要目标规划必须具备一定的挑战性，需要规划出不可能完成的目标。过度规划本质上是一种贪婪算法，目的是目标价值最大化。因为一切皆有变数，如果其他目标能够提前完成，就不妨利用这些时间去完成更多的学习目标。总之，前途必须光明，道路必须坎坷。 各目标之间不一定共享资源，规划不一定互有冲突。 此外，短期规划还可以从如下几个方面进行优化： 学习计划最好能结合工作计划，理论联系实际结合，快速学以致用。比如，本季度规划去做一些数据分析工作，那么不妨把学习目标设置为学习统计知识。 要灵活对待规划的目标和具体执行步骤，需要避免“郑人买履”式的笑话。面临新的挑战和变化，规划需要不断地调整。 那些令人纠结的困惑人生是一场马拉松，在漫长的征途中，难免有很多困惑。困惑就像枷锁，使我们步履蹒跚，困惑就像死锁，让我们停滞不前。 接下来我将总结自己在工作中碰到和看到的一些典型困惑。这些困惑或者长期困扰作者本人，或者困扰我身边的同事和朋友。当这些困惑被释然之后，大家都感觉如重获释，为下一阶段的征程提供满满的正能量。人生就像一场旅途，不必在乎目的地，在乎的，应该是沿途的风景，以及看风景的心情。良好的心态是技术之旅最好的伴侣。期望通过这个解惑之旅，让大家拥有一个愉快的心情去感受漫长的学习旅途。 学无止境吗必须要承认一个残酷的现实：人的生命是有限的，知识却是无限的。用有限的生命去学习无限的知识是不可能完成的任务。一想到此，有些工程师不免产生一些悲观情绪。如果方法得当并且足够勤奋，悲伤大可不必。 虽然，人类的整体知识体系一直在扩张。但是就很多重要的工程细分领域，基础理论并不高深。计算机的很多重要领域，工程师有能力在有限时间内抓住核心要害。 比如，密码学被认为是门非常高深的学科，但是一大类密码技术的基础是数论中一个非常简单的理论——素因数分解：给出两个素数，很容易算出它们的积，然而反过来给定两个素数的积，分解的计算量却非常惊人。 “一致性”算得上是计算机领域里面最经典的难题，它是所有分布式系统的基础，从多核多CPU到多线程，从跨机器到跨机房，无所不在，几乎所有的计算机从业人员都在解决这个问题，但是Paxos给出了一个很优雅的解决方案。 权限管理是很多工程师的噩梦，但如果你能搞定“Attribute Based Access Control(ABAC)”和“Role-Based Access Control(RBAC)”，也能达到相当高度。 另外，技术学习是一场对抗赛，虽然学无止境，超越大部分对手就是一种胜利。所以，以正确的学习方式，长时间投入就会形成核心竞争力。 没有绝对高明的技术，只有真正的高手致力于在技术上有所成就的工程师，都梦想有朝一日成为技术高手。但技术高手的标准却存在很大的争议。这是一个有着悠久历史的误解：以某种技术的掌握作为技术高手的评判标准。我经常碰到这样一些情景：因为掌握了某些技术，比如Spring、Kafka、Elasticsearch等，一些工程师就自封为高手。有些工程师非常仰慕别的团队，原因竟是那个团队使用了某种技术。 这种误解的产生有几个原因：首先，技多不压身，技术自然是掌握的越多越好，掌握很多技术的人自然不是菜鸟。其次，在互联网时代来临之前，信息获取是非常昂贵的事情。这就导致一项技能的掌握可以给个人甚至整个公司带来优势地位。互联网时代，各种框架的出现以及开源的普及快速淘汰或者降低了很多技能的价值，同时降低了很多技术的学习门槛。所以，在当前，掌握某项技能知识只能是一个短期目标。怀揣某些技能就沾沾自喜的人需要记住：骄傲使人退步。 所谓“麻雀虽小，五脏俱全”。如果让你来做造物主，设计麻雀和设计大象的复杂度并没有明显区别。一个看起来很小的业务需求，为了达到极致，所需要的技术和能力是非常综合和高深的。真正的高手不是拿着所掌握的技术去卡客户需求，而是倾听客户的需求，给出精益求精的方案。完成客户的需求是一场擂台赛，真正的高手，是会见招拆招的。 不做项目就无法成长吗在项目中学习是最快的成长方式之一，很多工程师非常享受这个过程。但是一年到头都做项目，你可能是在一家外包公司。对于一个做产品的公司，如果年头到年尾都在做项目，要不然就是在初步创业阶段，要不然就是做了大量失败的项目，总之不算是特别理想的状态。正常情况，在项目之间都会有一些非项目时间。在这段时间，有些同学会产生迷茫，成长很慢。 项目真的是越多越好吗？答案显然是否定的。重复的项目不会给工程师们带来新的成长。不停的做项目，从而缺乏学习新知识的时间，会导致“做而不学则殆”。真正让工程师出类拔萃的是项目的深度，而不是不停地做项目。所以，在项目之间的空档期，工程师们应该珍惜难得的喘息之机，深入思考，把项目做深、做精。 如何提高项目的深度呢？一般而言，任何项目都有一个目标，当项目完成后，目标就算基本达成了。但是，客户真的满意了吗？系统的可用性、可靠性、可扩展性、可维护性已经做到极致了吗？这几个问题的答案永远是否定的。所以，任何一个有价值的项目，都可以一直深挖。深挖项目，深度思考还可以锻炼工程师的创造力。期望不停地做项目的人，就像一个致力于训练更多千里马的人是发明不出汽车的。锻炼创造力也不是一蹴而就的事情，需要长时间地思考。总之，工程师们应该总是觉得时间不够用，毕竟时间是最宝贵的资源。 职责真的很小吗很多时候，一个工程师所负责系统的数量和团队规模与其“江湖地位”正相关。但是，江湖地位与技术成长没有必然关联。提升技术能力的关键是项目深度以及客户的挑剔程度。项目越多，在单个项目中投入的时间就越少，容易陷入肤浅。特别需要避免的是“ 在其位不谋其政”的情况。团队越大，在管理方面需要投入的精力就越多。在管理技巧不成熟，技术眼界不够高的前提强行负责大团队，可能会导致个人疲于应付，团队毫无建树。最终“ 一将无能，累死三军”，效果可能适得其反。 从技术发展的角度来说，技术管理者应该关注自己所能把控的活跃项目的数量，并致力于提高活跃项目的影响力和技术深度。团队人数要与个人管理能力、规划能力和需求把控能力相适应。一份工作让多个人来干，每个人的成长都受限。每个人都做简单重复的工作，对技术成长没有任何好处。团队管理和项目管理需要循序渐进，忌“拔苗助长”。 一定要当老大吗有一些工程师的人生理想是做团队里的技术老大，这当然是一个值得称赞的理想。可是，如果整个团队技术能力一般，发展潜力一般，而你是技术最强者，这与其说是幸运，不如说是悲哀。这种场景被称之为“武大郎开店”。 团队里的技术顶尖高手不是不能做，但为了能够持续成长，需要满足如下几个条件： 首先你得是行业里面的顶尖专家了——实在很难找到比你更强的人了！ 其次，你经常需要承担对你自己的能力有挑战的任务，但同时你拥有一批聪明能干的队友。虽然你的技术能力最高，但是在你不熟悉的领域，你的队友能够进行探索并扩展整个团队的知识。 最后，你必须要敏而好学，不耻下问。 否则，加入更强的技术团队或许是更好的选择，最少不是什么值得骄傲的事情。 平台化的传说平台化算得上是“高大上”的代名词了，很多工程师挤破头就为了和“平台化”沾点边。然而和其他业务需求相比，平台化需求并没有本质上的区别。无论是平台化需求还是普通业务需求，它的价值都来自于客户价值。不同点如下： 很多平台化需求的客户来自于技术团队，普通需求的客户来自于业务方。 产品经理不同。普通业务需求来自于产品经理，平台化需求的产品经理可能就是工程师自己。长期被产品经理“压迫”的工程师们，在平台化上终于找到“翻身农奴把歌唱”的感觉。 很多平台化的关注点是接入能力和可扩展性，而普通业务的关注点更多。 归根结底，平台化就是一种普通需求。在实施平台化之前，一定要避免下面两个误区： 平台化绝对不是诸如“统一”、“全面”之类形容词的堆砌。是否需要平台化，应该综合考虑：客户数量，为客户解决的问题，以及客户价值是否值得平台化的投入。 平台化不是你做平台，让客户来服务你。一些平台化设计者的规划设计里面，把大量的平台接入工作、脏活累活交给了客户，然后自己专注于所谓“最高大上”的功能。恰恰相反，平台化应该是客户什么都不做，所有的脏活累活都由平台方来做。本质上讲，平台化的价值来自于技术深度。真正体现技术深度的恰恰是设计者能够很轻松的把所有的脏活累活搞定。 所以平台化的最佳实践是：投入最少的资源，解决最多的问题。平台解决一切，客户坐享其成。 搞基础技术就一定很牛吗经常听到同学们表达对基础技术部同学的敬仰之情，而对搞业务技术的同学表现出很轻视，认为存储、消息队列、服务治理框架（比如美团点评内部使用的OCTO）、Hadoop等才能被称为真正的技术。事实并非如此，更基础的并不一定更高深。 比如下面这个流传很久的段子：越高级的语言就越没有技术含量。但真是这样吗，就拿Java和C来说，这是完全不同的两种语言，所需要的技能完全不同。C或许跟操作系统更加接近一点，和CPU、内存打交道的机会更多一点。但是为了用好Java，程序员在面向对象、设计模式、框架技术方面必须要非常精通。Java工程师转到C方向确实不容易，但作者也见过很多转到Java语言的C工程师水土不服。 基础技术和业务应用技术必然会有不同的关注点，没有高低之分。之所以产生这种误解，有两个原因： 基础技术相对成熟，有比较完整的体系，这给人一个高大上的感觉。业务应用技术相对来说，由于每个团队使用的不一样，所以成熟度参差不齐，影响力没有那么大。 基础技术的门槛相对来说高一点，考虑到影响面，对可靠性、可用性等有比较高的最低要求。但是门槛高不代表技术含量高，另外成熟技术相对来说在创新方面会受到很大的约束。但是最先进的技术都来自活跃的创新。 对比下来，业务技术和基础技术各有千秋。但真正的高手关注的是解决问题，所有的技术都是技能而已。 可行性调研的那些坑工作中开展可行性调研时有发生。做可行性调研要避免如下情况： 把可行性调研做成不可行性调研。这真的非常糟糕。不可行性的结论往往是：因为这样或者那样的原因，所以不可行。 避免“老鼠给猫挂铃铛”式的高风险可行性方案。“天下大事必作于细”，可行性调研一定要细致入微，避免粗枝大叶。 避免调研时间过长。如果发现调研进展进入到指数级复杂度，也就是每前进一步需要之前两倍的时间投入，就应该果断的停止调研。 可行性调研的结论应该是收益与成本的折衷，格式一般如下： 首先明确预期的结果，并按照高中低收益进行分级。 阐述达成每种预期结果需要采取的措施和方案。 给出实施各方案需要付出的成本。 工程师天生不善沟通吗实际工作中，沟通所导致的问题层出不穷。工程师有不少是比较内向的，总是被贴上“不善沟通”的标签。实际上，沟通能力是工程师最重要的能力之一，良好的沟通是高效工作学习的基础，也是通过学习可以掌握的。下面我按工程师的语言说说沟通方面的经验。 第一类常见的问题是沟通的可靠性。从可靠性的角度来讲，沟通分为TCP模式和UDP模式。TCP模式的形象表述是：我知道你知道。UDP模式的形象表述是：希望你知道。TCP模式当然比较可靠，不过成本比较高，UDP模式成本低，但是不可靠。在沟通可靠性方面，常见错误有如下两种： 经常听到的这样的争论。一方说：“我已经告诉他了”，另一方说：“我不知道这个事情呀”。把UDP模式被当作TCP模式来使用容易产生扯皮。 过度沟通。有些同学对沟通的可靠性产生了过度焦虑，不断的重复讨论已有结论问题。把TCP模式当成UDP来使用，效率会比较低。 第二类沟通问题是时效性问题。从时效性讲，沟通分为：同步模式和异步模式。同步沟通形象地说就是：你现在给我听好了。异步沟通的形象表述是：记得给我做好了。在沟通时效性方面，有如下两种常见错误： 已经出现线上事故，紧急万分。大家你一言，我一语，感觉事故可能和某几个人有关，但是也不能完全确定，所以没有通知相关人员。最终，一个普通的事故变成了严重事故。对于紧急的事情，必须要同步沟通。 半夜三点你正在熟睡，或者周末正在逛街，接到一个电话：“现在有个需求，能否立刻帮忙做完。”这会非常令人郁闷，因为那并不是紧急的事情。不是所有的需求都需要立刻解决。 有效沟通的一个重要原则是提前沟通。沟通本质是信息交流和处理，可以把被沟通对象形象地比喻成串行信息处理的CPU。提前沟通，意味着将处理请求尽早放入处理队列里面。下面的例子让很多工程师深恶痛绝：一个需求策划了1个月，产品设计了2周。当开发工程是第一次听说该需求的时候，发现开发的时间是2天。工程师据理力争，加班加点1周搞定。最后的结论是工程师非常不给力，不配合。就像工程师讨厌类似需求一样。要协调一个大项目，希望获得别人的配合，也需要尽早沟通。 有效沟通的另外一个重点是“不要跑题”。很多看起来很接近的问题，本质上是完全不同的问题。比如：一个会议的主题是“如何实施一个方案”，有人却可能提出“是否应该实施该方案”。 “如何实施”和“是否应该实施”是完全不同的两个问题，很多看起来相关的问题实际上跑题很远。“跑题”是导致无效沟通的重要原因。 良好沟通的奥秘在于能掌握TCP模式和UDP模式精髓，正确判断问题的紧急性，尽量提前沟通，避免跑题。 带人之道有些初为导师的工程师由于担心毕业生的能力太弱，安排任务时候谆谆教诲，最后感觉还是有所顾虑，干脆自己写代码。同样的事情发生在很多刚刚管理小团队的工程师身上。最终的结果他们：写完所有的代码，让下属无代码可写。“ 事必躬亲”当然非常糟糕，最终的往往是团队的整体绩效不高，团队成员的成长很慢，而自己却很累。 古人说：“用人不疑，疑人不用。”这句话并非“放之四海而皆准”。在古代，受限于通信技术，反馈延迟显著，而且信息在传递过程中有大量噪音，变形严重。在这种情况下，如果根据短期内收集的少量变形的信息做快速决断，容易陷于草率。在公司里，这句话用于选人环节更为恰当，应该改为：录用不疑，疑人不录。 考虑到招聘成本，就算是在录用层面，有时候也无法做到。作为一个小团队的管理者，能够快速准确的获取团队成员的各种反馈信息，完全不需要“用人不疑，疑人不用”。用人的真正理论基础来自于“探索和利用”(Exploration and Exploitation )。不能因为下属能做什么就只让他做什么，更不能因为下属一次失败就不给机会。 根据经典的“探索和利用”(Exploration and Exploitation )理论，良好的用人方式应该如下： 首选选择相信，在面临失败后，收缩信任度。 查找失败的原因，提供改进意见，提升下属的能力。 总是给下属机会，在恰当地时机给下属更高的挑战。 总之，苍天大树来自一颗小种子，要相信成长的力量。 效率、效率、效率经常看到有些同学给自己的绩效评分是100分——满分，原因是在过去一段时间太辛苦了，但最终的绩效却一般般。天道酬勤不错，但是天道更酬巧。工程师们都学过数据结构，不同算法的时间复杂度的差距，仅仅通过更长的工作时间是难以弥补的。为了提升工作学习效率，我们需要注意以下几点： 主要关注效率提升。很多时候，与效率提升所带来的收益相比，延长时间所带来的成果往往不值得一提。 要有清晰的结果导向思维。功劳和苦劳不是一回事。 做正确的事情，而不仅仅正确地做事情。这是一个被不断提起的话题，但是错误每天都上演。为了在规定的时间内完成一个大项目，总是要有所取舍。如果没有重点，均匀发力，容易事倍功半。如果“南辕北辙”，更是可悲可叹。 架构师能力模型前面我们已经讲完了原则和一些困惑，那么工程师到底应该怎么提升自己呢？ 成为优秀的架构师是大部分初中级工程师的阶段性目标。优秀的架构师往往具备八种核心能力：编程能力、调试能力、编译部署能力、性能优化能力、业务架构能力、在线运维能力、项目管理能力和规划能力。 这几种能力之间的关系大概如下图。编程能力、调试能力和编译部署能力属于最基础的能力。不能精通掌握这三种能力，很难在性能优化能力和业务架构能力方面有所成就。具备了一定的性能优化能力和业务架构能力之后，才能在线运维能力和项目管理能力方面表现优越。团队管理能力是最高能力，它对项目管理能力的依赖度更大。 编程能力对工程师而言，编程是最基础的能力，必备技能。其本质是一个翻译能力，将业务需求翻译成机器能懂的语言。 提升编程能力的书籍有很多。精通面向对象和设计模式是高效编程的基础。初级工程师应该多写代码、多看代码。找高手做Code Review，也是提升编程水平的捷径。 调试能力程序代码是系统的静态形式，调试的目的是通过查看程序的运行时状态来验证和优化系统。本质上讲，工程师们通过不断调试可以持续强化其通过静态代码去预测运行状态的能力。所以调试能力也是工程师编程能力提升的关键手段。很早之前有个传说：“调试能力有多强，编程能力就有多强。”不过现在很多编辑器的功能很强大，调试能力的门槛已经大大降低。 调试能力是项目能否按时、高质量提交的关键。即使一个稍具复杂度的项目，大部分工程师也无法一次性准确无误的完成。大项目都是通过不断地调试进行优化和纠错的。所以调试能力是不可或缺的能力。 多写程序，解决Bug，多请教高手是提升调试能力的重要手段。 编译部署能力编译并在线上部署运行程序是系统上线的最后一个环节。随着SOA架构的普及以及业务复杂度的增加，大部分系统只是一个完整业务的一个环节，因此，本地编译和运行并不能完全模拟系统在线运行。为了快速验证所编写程序的正确性，编译并在线上部署就成了必要环节。所以编译部署能力是一个必备技能。 让盘根错节的众多子系统运行起来是个不小的挑战。得益于SOA架构的普及以及大量编译、部署工具的发展，编译部署的门槛已经大大降低。基于应用层进行开发的公司，已经很少有“编译工程师”的角色了。但是对于初级工程师而言，编译部署仍然不是一个轻松的事情。 性能优化能力衡量一个系统成功的一个重要指标是使用量。随着使用量的增加和业务复杂度的增加，大部分系统最终都会碰到性能问题。 性能优化能力是一个综合能力。因为： 影响系统性能的因素众多，包括：数据结构、操作系统、虚拟机、CPU、存储、网络等。为了对系统性能进行调优，架构师需要掌握所有相关的技术。 精通性能优化意味着深刻理解可用性、可靠性、一致性、可维护性、可扩展性等的本质。 性能优化与业务强耦合，最终所采取的手段是往往折衷的结果。所以，性能优化要深谙妥协的艺术。 可以说，性能优化能力是工程师们成长过程中各种技能开始融会贯通的一个标志。这方面可以参考之前的博客文章“常见性能优化策略的总结”。市场上还有很多与性能优化相关的书籍，大家可以参考。多多阅读开源框架中关于性能优化方面的文档和代码也不失为好的提升手段。动手解决线上性能问题也是提升性能优化能力的关键。如果有机会，跟着高手学习，分析性能优化解决方案案例（我们技术博客之前也发表了很多这方面的文章），也是快速提升性能优化能力的手段。 在线运维能力如果说性能优化能力体现的是架构师的静态思考能力，在线运维能力考验的就是动态反应能力。残酷的现实是，无论程序多么完美，Bug永远存在。与此同时，职位越高、责任越大，很多架构师需要负责非常重要的在线系统。对于线上故障，如果不能提前预防以及快速解决，损失可能不堪设想，所以在线运维能力是优秀架构师的必备技能。 为了对线上故障进行快速处理，标准化的监控、上报、升级，以及基本应对机制当然很重要。通过所观察到的现象，快速定位、缓解以及解决相关症状也相当关键。这要求架构师对故障系统的业务、技术具备通盘解读能力。解决线上故障的架构师就好比一个在参加比赛F1的车手。赛车手必须要了解自身、赛车、对手、同伴、天气、场地等所有因素，快速决策，不断调整。架构师必须要了解所有技术细节、业务细节、处理规范、同伴等众多因素，快速决断，迅速调整。 在线运维本质上是一个强化学习的过程。很多能力都可以通过看书、查资料来完成，但在线运维能力往往需要大量的实践来提升。 业务架构能力工程师抱怨产品经理的故事屡见不鲜，抱怨最多的主要原因来自于需求的频繁变更。需求变更主要有两个来源：第一个原因是市场改变或战略调整，第二个原因是伪需求。对于第一个原因，无论是工程师还是产品经理，都只能无奈的接受。优秀的架构师应该具备减少第二种原因所导致的需求变更的概率。 伪需求的产生有两个原因： 第一个原因是需求传递变形。从信息论的角度来讲，任何沟通都是一个编码和解码的过程。典型的需求从需求方到产品经理，最终到开发工程师，最少需要经历三次编码和解码过程。而信息的每一次传递都存在一些损失并带来一些噪音，这导致有些时候开发出来的产品完全对不上需求。此外，需求方和产品经理在需求可行性、系统可靠性，开发成本控制方面的把控比较弱，也会导致需求变形。 第二个原因就是需求方完全没有想好自己的需求。 优秀的架构师应该具备辨别真伪需求的能力。应该花时间去了解客户的真实业务场景，具备较强的业务抽象能力，洞悉客户的真实需求。系统的真正实施方是工程师，在明确客户真实需求后，高明的架构师应该具备准确判断项目对可行性、可靠性、可用性等方面的要求，并能具备成本意识。最后，由于需求与在线系统的紧耦合关系，掌握在线系统的各种细节也是成功的业务架构的关键。随着级别的提升，工程师所面对的需求会越来越抽象。承接抽象需求，提供抽象架构是架构师走向卓越的必经之途。 市场上有一些关于如何成为架构师的书，大家可以参考。但是架构能力的提升，实践可能是更重要的方式。业务架构师应该关注客户的痛点而不是PRD文档，应该深入关注真实业务。掌握现存系统的大量技术和业务细节也是业务架构师的必备知识。 项目管理能力作为工业时代的产物，分工合作融入在互联网项目基因里面。架构师也需要负责几个重大项目才能给自己正名。以架构师角色去管理项目，业务架构能力当然是必备技能。此外，人员管理和成本控制意识也非常重要。 项目管理还意味着要有一个大心脏。重大项目涉及技术攻关、人员变动、需求更改等众多可变因素。面临各种变化，还要在确保目标顺利达成，需要较强的抗压能力。 人员管理需要注意的方面包括：知人善用，优化关系，简化沟通，坚持真理。 知人善用意味着架构师需要了解每个参与者的硬技能和软素质。同时，关注团队成员在项目过程中的表现，按能分配 优化关系意味着管理团队的情绪，毕竟项目的核心是团队，有士气的团队才能高效达成目标。 简化沟通意味着快速决策，该妥协的时候妥协，权责分明。 坚持真理意味着顶住压力，在原则性问题上绝不退步。 成本控制意味着对项目进行精细化管理，需要遵循如下几个原则： 以终为始、确定里程碑。为了达成目标，所有的计划必须以终为始来制定。将大项目分解成几个小阶段，控制每个阶段的里程碑可以大大降低项目失败的风险。 把控关键路径和关键项目。按照关键路径管理理论（CPM）的要求，架构师需要确定每个子项目的关键路径，确定其最早和最晚启动时间。同时，架构师需要关注那些可能会导致项目整体延期的关键节点，并集中力量攻破。 掌控团队成员的张弛度。大项目持续时间会比较长，也包含不同工种。项目实施是一个不断变化的动态过程，在这个过程中不是整个周期都很紧张，不是所有的工种都一样忙。优秀的架构师必须要具备精细阅读整体项目以及快速反应和实时调整的能力。这不仅仅可以大大降低项目成本，还可以提高产出质量和团队满意度。总体来说，“前紧后松”是项目管理的一个重要原则。 项目管理方面的书籍很多。但是，提高业务架构能力同样重要。积极参与大项目并观察别人管理项目的方式也是非常重要的提升手段。 团队管理能力不想做CTO的工程师不是一个好的架构师。走向技术管理应该是工程师的一个主流职业规划。团队管理的一个核心能力就是规划能力，这包括项目规划和人员规划。良好的规划需要遵循如下原则： 规划是利益的博弈。良好的规划上面对得起老板，中间对得起自己，下面对得起团队。在三者利益者寻找平衡点，实现多方共赢考验着管理者的智慧和精细拿捏的能力。 任何规划都比没有规划好。没有规划的团队就是没头的苍蝇，不符合所有人的利益。 规划不是本本主义。市场在变，团队在变，规划也不应该一成不变。 客户至上的是项目规划的出发点。 就人员规划而言，规划需要考量团队成员的能力、绩效、成长等多方面的因素。 市场上有很多规划管理方面的书籍，值得阅读。最优化理论虽然是技术书籍，但它是规划的理论基础，所以不妨多看看翻阅一下。从自我规划开始，多多学习别人的规划也是规划能力提升的重要手段。 总结因为受邀去做一个关于“一边工作，一边学习”的分享，作者花了一段时间去思考和汇总学习方法论，接着每天不断地采集谣言并尝试解惑，再根据个人经验绘制出优秀架构师的能力模型，最后汇集成文。 文章系统性地阐述了学习原则、分析了常见困惑，并制定明确学习目标，期望对工程师们的工作学习有所帮助。需要申明的是，文章内容挂一漏万，所谓的架构师能力模型也是作者的个人观点。欢迎大家在评论中分享自己在学习成长方面的心得。]]></content>
      <tags>
        <tag>learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis开发规范]]></title>
    <url>%2F2019%2F03%2F18%2Fredis-specification%2F</url>
    <content type="text"><![CDATA[一、键值设计1. key名设计 (1)【建议】: 可读性和可管理性 以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id 1ugc:video:1 (2)【建议】：简洁性 保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如： 1user:&#123;uid&#125;:friends:messages:&#123;mid&#125;简化为u:&#123;uid&#125;:fr:m:&#123;mid&#125;。 (3)【强制】：不要包含特殊字符 反例：包含空格、换行、单双引号以及其他转义字符 2. value设计 (1)【强制】：拒绝bigkey(防止网卡流量、慢查询) string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。 反例：一个包含200万个元素的list。 非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞，而且该操作不会不出现在慢查询中(latency可查))，查找方法和删除方法 (2)【推荐】：选择适合的数据类型。 例如：实体类型(要合理控制和使用数据结构内存编码优化配置,例如ziplist，但也要注意节省内存和性能之间的平衡) 反例： 123set user:1:name tomset user:1:age 19set user:1:favor football 正例: 1hmset user:1 name tom age 19 favor football 3.【推荐】：控制key的生命周期，redis不是垃圾桶。建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)，不过期的数据重点关注idletime。 二、命令使用1.【推荐】 O(N)命令关注N的数量例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。 2.【推荐】：禁用命令禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。 3.【推荐】合理使用selectredis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。 4.【推荐】使用批量操作提高效率12原生命令：例如mget、mset。非原生命令：可以使用pipeline提高效率。 但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。 注意两者不同： 1231. 原生是原子操作，pipeline是非原子操作。2. pipeline可以打包不同的命令，原生做不到3. pipeline需要客户端和服务端同时支持。 5.【建议】Redis事务功能较弱，不建议过多使用Redis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot上(可以使用hashtag功能解决) 6.【建议】Redis集群版本在使用Lua上有特殊要求： 1.所有key都应该由 KEYS 数组来传递，redis.call/pcall 里面调用的redis命令，key的位置，必须是KEYS array, 否则直接返回error，”-ERR bad lua script for redis cluster, all the keys that the script uses should be passed using the KEYS array” 2.所有key，必须在1个slot上，否则直接返回error, “-ERR eval/evalsha command keys must in same slot” 7.【建议】必要情况下使用monitor命令时，要注意不要长时间使用。三、客户端使用1.【推荐】避免多个应用使用一个Redis实例 正例：不相干的业务拆分，公共数据做服务化。 2.【推荐】使用带有连接池的数据库，可以有效控制连接，同时提高效率，标准使用方式： 12345678910111213执行命令如下：Jedis jedis = null;try &#123; jedis = jedisPool.getResource(); //具体的命令 jedis.executeCommand()&#125; catch (Exception e) &#123; logger.error("op key &#123;&#125; error: " + e.getMessage(), key, e);&#125; finally &#123; //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。 if (jedis != null) jedis.close();&#125; 下面是JedisPool优化方法的文章: Jedis常见异常汇总 JedisPool资源池优化 3.【建议】高并发下建议客户端添加熔断功能(例如netflix hystrix) 4.【推荐】设置合理的密码，如有必要可以使用SSL加密访问（阿里云Redis支持） 5.【建议】根据自身业务类型，选好maxmemory-policy(最大内存淘汰策略)，设置好过期时间。 默认策略是volatile-lru，即超过最大内存后，在过期键中使用lru算法进行key的剔除，保证不过期数据不被删除，但是可能会出现OOM问题。 其他策略如下： allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。 allkeys-random：随机删除所有键，直到腾出足够空间为止。 volatile-random:随机删除过期键，直到腾出足够空间为止。 volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。 noeviction：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息”(error) OOM command not allowed when used memory”，此时Redis只响应读操作。 四、相关工具1.【推荐】：数据同步redis间数据同步可以使用：redis-port 2.【推荐】：big key搜索redis大key搜索工具 3.【推荐】：热点key寻找(内部实现使用monitor，所以建议短时间使用)facebook的redis-faina 1阿里云Redis已经在内核层面解决热点key问题，欢迎使用。 五 附录：删除bigkey121. 下面操作可以使用pipeline加速。2. redis 4.0已经支持key的异步删除，欢迎使用。 1. Hash删除: hscan + hdel123456789101112131415161718192021public void delBigHash(String host, int port, String password, String bigHashKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; ScanParams scanParams = new ScanParams().count(100); String cursor = "0"; do &#123; ScanResult&lt;Entry&lt;String, String&gt;&gt; scanResult = jedis.hscan(bigHashKey, cursor, scanParams); List&lt;Entry&lt;String, String&gt;&gt; entryList = scanResult.getResult(); if (entryList != null &amp;&amp; !entryList.isEmpty()) &#123; for (Entry&lt;String, String&gt; entry : entryList) &#123; jedis.hdel(bigHashKey, entry.getKey()); &#125; &#125; cursor = scanResult.getStringCursor(); &#125; while (!"0".equals(cursor)); //删除bigkey jedis.del(bigHashKey);&#125; 2. List删除: ltrim12345678910111213141516public void delBigList(String host, int port, String password, String bigListKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; long llen = jedis.llen(bigListKey); int counter = 0; int left = 100; while (counter &lt; llen) &#123; //每次从左侧截掉100个 jedis.ltrim(bigListKey, left, llen); counter += left; &#125; //最终删除key jedis.del(bigListKey);&#125; 3. Set删除: sscan + srem123456789101112131415161718192021public void delBigSet(String host, int port, String password, String bigSetKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; ScanParams scanParams = new ScanParams().count(100); String cursor = "0"; do &#123; ScanResult&lt;String&gt; scanResult = jedis.sscan(bigSetKey, cursor, scanParams); List&lt;String&gt; memberList = scanResult.getResult(); if (memberList != null &amp;&amp; !memberList.isEmpty()) &#123; for (String member : memberList) &#123; jedis.srem(bigSetKey, member); &#125; &#125; cursor = scanResult.getStringCursor(); &#125; while (!"0".equals(cursor)); //删除bigkey jedis.del(bigSetKey);&#125; 4. SortedSet删除: zscan + zrem123456789101112131415161718192021public void delBigZset(String host, int port, String password, String bigZsetKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; ScanParams scanParams = new ScanParams().count(100); String cursor = "0"; do &#123; ScanResult&lt;Tuple&gt; scanResult = jedis.zscan(bigZsetKey, cursor, scanParams); List&lt;Tuple&gt; tupleList = scanResult.getResult(); if (tupleList != null &amp;&amp; !tupleList.isEmpty()) &#123; for (Tuple tuple : tupleList) &#123; jedis.zrem(bigZsetKey, tuple.getElement()); &#125; &#125; cursor = scanResult.getStringCursor(); &#125; while (!"0".equals(cursor)); //删除bigkey jedis.del(bigZsetKey);&#125;]]></content>
      <tags>
        <tag>Redis, specification</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据同步机制设计]]></title>
    <url>%2F2019%2F03%2F17%2Fdata-sync-design%2F</url>
    <content type="text"><![CDATA[数据同步是异地多活的基础，所有具备数据存储能力的组件如：数据库、缓存、MQ等，数据都可以进行同步，形成一个庞大而复杂的数据同步拓扑。 1. 什么是单元化可以理解为将数据划分到多个单元进行存储。”单元”是一个抽象的概念，通常与数据中心(IDC)概念相关，一个单元可以包含多个IDC，也可以只包含一个IDC。本文假设一个单元只对应一个IDC。 考虑一开始只有一个IDC的情况，所有用户的数据都会写入同一份底层存储中，如下图所示： 存在以下几个问题： 不同地区的用户体验不同。一个IDC必然只能部署在一个地区，例如部署在北京，那么北京的用户访问将会得到快速响应；但是对于上海的用户，访问延迟一般就会大一点，上海到北京的一个RTT可能有20ms左右。 容灾问题。这里容灾不是单台机器故障，而是指机房断电，自然灾害，或者光纤被挖断等重大灾害。一旦出现这种问题，将无法正常为用户提供访问，甚至出现数据丢失的情况。 为了解决这些问题，我们可以将服务部署到多个不同的IDC中，不同IDC之间的数据互相进行同步。如下图： 当一个机房挂了之后，我们可以将这个机房用户的流量调度到另外一个正常的机房，由于不同机房之间的数据是实时同步的，用户流量调度过去后，也可以正常访问数据 (故障发生那一刻的少部分数据可能会丢失)。 机房容灾 —— 两地三中心 上面的案例中，我们使用了2个IDC，但是2个IDC并不能具备机房容灾能力。至少需要3个IDC，例如，一些基于多数派协议的一致性组件，如zookeeper，redis、etcd、consul等，需要得到大部分节点的同意。例如我们部署了3个节点，在只有2个机房的情况下， 必然是一个机房部署2个节点，一个机房部署一个节点。当部署了2个节点的机房挂了之后，只剩下一个节点，无法形成多数派。在3机房的情况下，每个机房部署一个节点，任意一个机房挂了，还剩2个节点，还是可以形成多数派。 城市级容灾 —— 三地五中心 在发生重大自然灾害的情况下，可能整个城市的机房都无法访问。一些组件，例如蚂蚁的ocean base，为了达到城市级容灾的能力，使用的是”三地五中心”的方案。这种情况下，3个城市分别拥有2、2、1个机房。当整个城市发生灾难时，其他两个城市依然至少可以保证有3个机房依然是存活的，同样可以形成多数派。 实现单元化，技术层面我们要解决的事情很多，例如：流量调度，即如何让用户就近访问附近的IDC；数据互通，如何实现不同机房之间数据的相互同步。 如何进行数据同步我们就可以考虑自己编写一个组件，其作用类似与mysql slave，也是去主库上拉取binlog，只不过binlog不是保存到本地，而是将binlog转换成sql插入到目标mysql集群中，实现数据的同步。 阿里巴巴开源的canal 美团开源的puma linkedin开源的databus 这些组件都要完成最基本的2件事：从源库拉取binlog并进行解析，我们把这部分功能称之为binlog syncer；将获取到的binlog转换成SQL插入目标库，这个功能称之为sql writer。 为什么划分成两块独立的功能？因为binlog订阅解析的实际应用场景并不仅仅是数据同步 因此，通常我们把binlog syncer单独作为一个模块，其只负责解析从数据库中拉取并解析binlog，并在内存中缓存(或持久化存储)。另外，binlog syncer另外提一个sdk，业务方通过这个sdk从binlog syncer中获取解析后的binlog信息，然后完成自己的特定业务逻辑处理。 显然，在数据同步的场景下，我们可以基于这个sdk，编写一个组件专门用于将binlog转换为sql，插入目标库，实现数据同步，如下图所示： 北京用户的数据不断写入离自己最近的机房的DB，通过binlog syncer订阅这个库binlog，然后下游的binlog writer将binlog转换成SQL，插入到目标库。上海用户类似，只不过方向相反，不再赘述。通过这种方式，我们可以实时的将两个库的数据同步到对端。当然事情并非这么简单，我们有一些重要的事情需要考虑。 如何获取全量+增量的历史数据？通常，mysql不会保存所有的历史binlog。 expire_logs_days = 0，默认不清空 通常，如果binlog如果从来没被清理过，那么binlog文件名字后缀通常是000001，如果不是这个值，则说明可能已经被清理过。当然，这也不是绝对，例如执行”reset master”命令，可以将所有的binlog清空，然后从000001重新开始计数。 反正! 我们知道了，binlog可能不会一直保留，所以直接同步binlog，可能只能获取到部分数据。因此，通常的策略是，由DBA先dump一份源库的完整数据快照，增量部分，再通过binlog订阅解析进行同步。 如何解决重复插入？考虑以下情况下，源库中的一条记录没有唯一索引。对于这个记录的binlog，通过sql writer将binlog转换成sql插入目标库时，抛出了异常，此时我们并不知道知道是否插入成功了，则需要进行重试。如果之前已经是插入目标库成功，只是目标库响应时网络超时(socket timeout)了，导致的异常，这个时候重试插入，就会存在多条记录，造成数据不一致。 因此，通常，在数据同步时，通常会限制记录必须有要有主键或者唯一索引。 如何解决唯一索引冲突？由于两边的库都存在数据插入，如果都使用了同一个唯一索引，那么在同步到对端时，将会产生唯一索引冲突。对于这种情况，通常建议是使用一个全局唯一的分布式ID生成器来生成唯一索引，保证不会产生冲突。 另外，如果真的产生冲突了，同步组件应该将冲突的记录保存下来，以便之后的问题排查。 对于DDL语句如何处理？如果数据库表中已经有大量数据，例如千万级别、或者上亿，这个时候对于这个表的DDL变更，将会变得非常慢，可能会需要几分钟甚至更长时间，而DDL操作是会锁表的，这必然会对业务造成极大的影响。 因此，同步组件通常会对DDL语句进行过滤，不进行同步。DBA在不同的数据库集群上，通过一些在线DDL工具(如gh-ost)，进行表结构变更。 如何解决数据回环问题？INSERT操作假设在A库插入数据，A库产生binlog，之后同步到B库，B库同样也会产生binlog。由于是双向同步，这条记录，又会被重新同步回A库。由于A库应存在这条记录了，产生冲突。 UPDATE操作先考虑针对A库某条记录R只有一次更新的情况，将R更新成R1，之后R1这个binlog会被同步到B库，B库又将R1同步会A库。对于这种情况下，A库将不会产生binlog。因为A库记录当前是R1，B库同步回来的还是R1，意味着值没有变。 在一个更新操作并没有改变某条记录值的情况下，mysql是不会产生binlog，相当于同步终止。下图演示了当更新的值没有变时，mysql实际上不会做任何操作： 然而，这并不意味UPDATE 操作没有问题，事实上，其比INSERT更加危险。 考虑A库的记录R被连续更新了2次，第一次更新成R1，第二次被更新成R2；这两条记录变更信息都被同步到B库，B也产生了R1和R2。由于B的数据也在往A同步，B的R1会被先同步到A，而A现在的值是R2，由于值不一样，将会被更新成R1，并产生新的binlog；此时B的R2再同步会A，发现A的值是R1，又更新成R2，也产生binlog。由于B同步回A的操作，让A又产生了新的binlog，A又要同步到B，如此反复，陷入无限循环中。 DELETE操作同样存在先后顺序问题。例如先插入一条记录，再删除。B在A删除后，又将插入的数据同步回A，接着再将A的删除操作也同步回A，每次都会产生binlog，陷入无限回环。 数据同步架构设计前面的架构中，只涉及到2个DB的数据同步，如果有多个DB数据需要相互同步的情况下，架构将会变得非常复杂。例如： 这个图演示的是四个DB之间数据需要相互同步，这种拓扑结构非常复杂。为了解决这种问题，我们可以将数据写入到一个数据中转站，例如MQ中进行保存，如下： 我们在不同的机房各部署一套MQ集群，这个机房的binlog syncer将需要同步的DB binlog数据写入MQ对应的Topic中。对端机房如果需要同步这个数据，只需要通过binlog writer订阅这个topic，消费topic中的binlog数据，插入到目标库中即可。一些MQ支持consumer group的概念，不同的consumer group的消费位置offset相互隔离，从而达到一份数据，同时供多个消费者进行订阅的能力。 当然，一些binlog订阅解析组件，可能实现了类似于MQ的功能，此时，则不需要独立部署MQ。 数据同步回环问题解决方案1. 往目标库插入不生成binlog在mysql中，我们可以设置session变量，来控制当前会话上的更新操作，不产生binlog。这样当往目标库插入数据时，由于不产生binlog，也就不会被同步会源库了。为了演示这个效果，笔者清空了本机上的所有binlog(执行reset master)]]></content>
      <tags>
        <tag>数据同步, design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo最佳实践]]></title>
    <url>%2F2019%2F03%2F12%2Fdubbo-best-practice%2F</url>
    <content type="text"><![CDATA[1. 分包 将自定义异常也放在API包里，它也是API的一部分 可以在API包中放置一份Spring的引用配置文件，方便使用方 2. 粒度 尽可能大一点，每个方法代表一个完整的功能，否则会出现分布式事务 3. 版本号 定义3位的版本号，第3位表示兼容性升级 当不兼容时，先升级一半的 provider 为新版本，再将消费者全升级为新版本，然后将剩下的一半 provider 升级为新版本 4. 兼容性与枚举值 如果是业务类别，以后明显会有类型增加的，不建议使用Enum，可以用String代替 如果在返回值中用了Enum，并增加了新类型，建议先升级 Consumer 相反，如果在传入参数中新增了类型，建议先升级 Provider 5. 异常 使用异常而不是错误码 如果担心性能问题，可通过 override 掉异常的 fillInStackTrace()方法为空 查询方法里不建议抛出 checked 异常，否则调用方需要 try..catch 且不能有效滴处理 6. 在Provider上尽量多配置Consumer端属性 provider 比服务使用方更清楚服务的性能指标，如调用的超时时间、合理的重试次数等等 Consumer 可使用 Provoider 端的默认配置 12345678&lt;dubbo:service interface="com.alibaba.hello.api.HelloService" version="1.0.0" ref="helloService" timeout="300" retry="2" loadbalance="random" actives="0"/&gt; &lt;dubbo:service interface="com.alibaba.hello.api.WorldService" version="1.0.0" ref="helloService" timeout="300" retry="2" loadbalance="random" actives="0" &gt; &lt;dubbo:method name="findAllPerson" timeout="10000" retries="9" loadbalance="leastactive" actives="5" /&gt;&lt;dubbo:service/&gt; 7. 在Provider上配置合理的Provider参数123456&lt;dubbo:protocol threads="200" /&gt; &lt;dubbo:service interface="com.alibaba.hello.api.HelloService" version="1.0.0" ref="helloService" executes="200" &gt; &lt;dubbo:method name="findAllPerson" executes="50" /&gt;&lt;/dubbo:service&gt; threads，服务线程池大小 executes，一个服务提供者并行执行请求上限，即当Provider对一个服务的并发调用到上限后，新调用会Wait（Consumer可能到超时）。在方法上配置（dubbo:method ）则并发限制针对方法，在接口上配置（dubbo:service），则并发限制针对服务。 8. Dubbo 通讯协议默认采用单一长连接和 NIO 异步通讯，hessian2 序列化，netty 通信，适合小数据量、大并发的服务调用，不适合传送大数据量的服务，比如传文件，传视频等，除非请求量很低。 Dubbo 的设计目的是为了满足高并发小数据量的 rpc 调用，在大数据量下的性能表现并不好，建议使用 rmi 或 http 协议。 9. 多连接配置Dubbo 协议缺省每服务每提供者每消费者使用单一长连接，如果数据量较大，可以使用多个连接。 &lt;dubbo:service connections=”0”&gt; 或 &lt;dubbo:reference connections=”0”&gt; 表示该服务使用 JVM 共享长连接。缺省 &lt;dubbo:service connections=”1”&gt; 或 &lt;dubbo:reference connections=”1”&gt; 表示该服务使用独立长连接。 &lt;dubbo:service connections=”2”&gt; 或&lt;dubbo:reference connections=”2”&gt; 表示该服务使用独立两条长连接。 为防止被大量连接撑挂，可在服务提供方限制大接收连接数，以实现服务提供方自我保护。 &lt;dubbo:protocol name=”dubbo” accepts=”1000” /&gt; 10. 尽快失败11. 防御性编程，但不忽略异常比如：获取程序的版本号，会通过扫描 Manifest 和 jar 包名称抓取版本号，这个逻辑是辅助性的，但代码却不少，初步测试也没啥问题，但应该在整个 getVersion() 中加上一个全函数的 try-catch 打印错误日志，并返回基本版本，因为 getVersion() 可能存在未知特定场景异常，或被其他的开发人员误修改逻辑(但一般人员不会去掉 try-catch)，而如果它抛出异常会导致主流程异常，这是我们不希望看到的。但这里要控制个度，不要随意 try-catch，更不要无声无息的吃掉异常。 12. 配置上管理者信息有问题时便于的找到服务的负责人，至少写两个人以便备份。负责人和组织的信息可以在注册中心的上看到。示例：应用配置负责人、组织&lt;dubbo:application owner=”ding.lid,william.liangf” organization=”intl” /&gt;service配置负责人&lt;dubbo:service owner=”ding.lid,william.liangf” /&gt;reference配置负责人&lt;dubbo:reference owner=”ding.lid,william.liangf” /&gt;]]></content>
      <tags>
        <tag>dubbo, 最佳实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo 服务暴露消费过程解析]]></title>
    <url>%2F2019%2F03%2F11%2Fdubbo-service-implement%2F</url>
    <content type="text"><![CDATA[Dubbo 调用流程 Provider start 启动服务 register 服务到服务中心 Consumer subscribe 向注册中心订阅服务。只订阅使用到的服务，首次会拉取订阅的服务列表，缓存在本地 [异步] notify 当服务发生变化，获取最新的服务列表，更新本地缓存 invoke 调用 Conusmer 直接发起对 Provider 的调用，无需注册中心。而对多个 Provider 的负载均衡，Consumer 通过 cluster 组件实现 count 监控 [异步] Conusmer 和 Provider 都异步通知监控中心 服务暴露和服务引用解析服务 基于 dubbo.jar 内的 META-INF/spring.handles 配置，Spring 在遇到 dubbo 名称空间时，会回调 DubboNamespaceHandler 所有的 dubbo 标签，都会统一用 DubboBeanDefinitionParser 进行解析，将 XML 标签解析成 Bean 对象 在 ServiceConfig#export() 或 ReferenceConfig#get() 初始化时，将 Bean 对象转换成 URL 格式，所有 Bean 属性转成 URL 参数 将 URL 传给 Dubbo SPI，基于 SPI 自适应机制，根据 URL 协议进行不同服务的暴露或引用。 服务暴露官方文开发者指南 - 实现细节给出服务提供者暴露一个服务的详细过程： 远程暴露 在有注册中心，需要注册提供者地址的情况下，ServiceConfig 解析出的 URL 格式为：registry:// registry-host/org.apache.dubbo.registry.RegistryService?export=URL.encode(“dubbo://service-host/{服务名}/{版本号}”) 基于 Dubbo SPI 的自适应机制，通过 URL registry:// 协议头识别，就调用 RegistryProtocol#export() 方法 将具体的服务类名，比如 DubboServiceRegistryImpl，通过 ProxyFactory 包装成 Invoker 实例 调用 doLocalExport 方法，使用 DubboProtocol 将 Invoker 转化为 Exporter 实例，并打开 Netty 服务端监听客户请求 创建 Registry 实例，连接 Zookeeper，并在服务节点下写入提供者的 URL 地址，注册服务 向注册中心订阅 override 数据，并返回一个 Exporter 实例 根据 URL 格式中的 “dubbo://service-host/{服务名}/{版本号}”中协议头 dubbo:// 识别，调用 DubboProtocol#export() 方法，开发服务端口 RegistryProtocol#export() 返回的 Exporter 实例存放到 ServiceConfig 的 List exporters 中 服务引用官方文开发者指南 - 实现细节给出服务提供者暴露一个服务的详细过程： 从注册中心发现引用服务：ReferenceConfig 解析出的 URL 格式为：registry://registry-host:/org.apache.registry.RegistryService?refer=URL.encode(“conumer-host/com.foo.FooService?version=1.0.0”)。 通过 URL 的 registry:// 协议头识别，就会调用 RegistryProtocol#refer() 方法 查询提供者 URL，如 dubbo://service-host/com.foo.FooService?version=1.0.0 ，来获取注册中心 创建一个 RegistryDirectory 实例并设置注册中心和协议 生成 conusmer 连接，在 consumer 目录下创建节点，向注册中心注册 注册完毕后，订阅 providers，configurators，routers 等节点的数据 通过 URL 的 dubbo:// 协议头识别，调用 DubboProtocol#refer() 方法，创建一个 ExchangeClient 客户端并返回 DubboInvoker 实例 由于一个服务可能会部署在多台服务器上，这样就会在 providers 产生多个节点，这样也就会得到多个 DubboInvoker 实例，就需要 RegistryProtocol 调用 Cluster 将多个服务提供者节点伪装成一个节点，并返回一个 Invoker Invoker 创建完毕后，调用 ProxyFactory 为服务接口生成代理对象，返回提供者引用]]></content>
  </entry>
  <entry>
    <title><![CDATA[性能优化checklist]]></title>
    <url>%2F2019%2F03%2F06%2Fperformance-checklist%2F</url>
    <content type="text"><![CDATA[1. 总原则 可扩展性架构，堆机器能不能解决问题是最最优先考虑的问题 去中心化的点对点通信，优于通过中心代理的通信 池化的长连接，优于短连接 二进制数据，优于文本数据 尽量减少交互，一次调用的粗粒度聚合接口 优于 多次调用的细粒度接口 尽量减少交互，批量接口优于循环调用 尽量只交互必要的数据 尽量就近访问 尽量使用缓存 总是设定超时 在合适的场景，并行化执行 在合适的场景，异步化执行 2. 环境准备线下压测服务器的配置要与生产环境一致 2.1 操作系统 调优应包含TCP内核参数，网卡参数及多队列绑定，IO&amp;Swap内核参数，ulimit资源限制等。 2.2 JVM与应用服务器 使用JDK7.0 u80 或 JDK8 最新版。 检查JVM启动参数已按自家规范调优，见《关键业务系统的JVM参数推荐》 检查应用服务器(Tomcat或微服务容器) 已按自家指南调优，如线程数等。 2.3 周边依赖系统 检查数据库，缓存，消息系统，已按自家指南调优。 2.4 后台辅助程序 检查日志收集，系统监控等，已使用最新版本，最优配置。 最好其最大消耗已被控制（通过cgroup，taskset等方式）。 2.5 测试程序 压测工具如JMeter，启动参数要参考真实应用客户端的参数优化（如JVM参数，Netty参数等）。 测试脚本和客户端程序经过review，不存在影响性能的步骤，不存在System.out.println（）等明显的瓶颈。 2.5 流量模型 扇入模型：平时与高峰期的流量估算，各接口的流量比例，响应时间要求 扇出模型：各接口对远程服务、数据库、缓存、消息系统的调用比例，响应时间估算。 3.数据库3.1 拓扑根据扩展性原则考虑： 垂直拆分：按业务将不同的表拆分到不同的库。 水平拆分：水平分库分表。 读写分离：在业务允许的情况下，在从库读取非实时数据。 3.2 Schema 统一的存储引擎，主键策略。 禁用存储过程，函数，触发器，外键约束。 列类型永远越短越好，建议：布尔/枚举：tinyint，日期与时间戳：timestamp或int，char/text/blob: 尽量用符合实际长度的varchar（n），小数及货币：移位转为int 或 decimal，IP地址：int。 索引策略：索引字段的顺序需要考虑字段值去重之后的个数，较多的放前面，合理创建联合索引，避免冗余索引，合理利用覆盖索引等。 3.3 SQL 自家规范应包含： 如禁止多于3表join，禁用子查询 禁止where子句中对字段施加函数，如to_date（add_time）&gt;xxxxx 避免MySQL进行隐式类型转化，如ISENDED&eq;1 与 ISENDED&eq;1 不建议使用%前缀模糊查询，模糊查询较多时建议使用ElasticSearch 根据尽量少数据原则与尽量少交互的原则来设计SQL: 禁止select ＊ 合理的SQL语句，减少交互次数 根据扩展性原则，将负载放在更容易伸缩的应用服务实例上： 尽量不要做数学运算，函数运算, 或者输出格式转换等非必要操作 避免count（＊），计数统计实时要求较强使用memcache或者redis，非实时统计使用单独统计表，定时更新。 甚至排序都是不鼓励的，尽量在应用侧进行。另外避免多余的排序，使用GROUP BY 时，默认会进行排序，当你不需要排序时，可以使用order by null。 联系DBA进行MySQL统计的慢查询的Review，解析SQL查询计划时尽量避免extra列出现：Using File Sort，Using Temporary 3.4 DAO框架 根据尽量少交互与尽量少数据的原则，需使用对SQL完全可控的DAO框架，建议为MyBatis 或 Spring JDBC Template。 必须使用prepareStatement，提升性能与防注入。 根据一切皆有超时的原则，配置SQL执行的超时。可在连接池里设置default值，可在MyBatis的Mapper定义里可设置每个请求的超时，可惜规范是秒级的。 JDBC driver 规范本身不支持异步模式，如果一定要异步，可以像Quasar那样把请求封装成Callable交给另外的线程池执行，但要注意其额外开销。 3.5 事务 不使用事务，连接池设置autocommit，使用其他方式来保持数据一致性。 通过Transaction Annotation控制事务，事务跨度尽量短，把非事务范围内的业务逻辑剔除到被标注的函数之外。 只读事务可以不加事务标注。 3.6 连接池 在分库分表时，根据点对点通信优先的原则，尽量使用客户端分片的实现。功能不满足时才用MyCat中央代理。 推荐使用性能最高HikariCP，或者Druid，不推荐c3p0与DBCP。 连接池的配置： 配置初始值，再联系DBA获得线上数据库支持的连接数，计算最大连接数。 连接有效性检查，只在连接空闲检测时执行，不在拿出和归还连接时执行，最好是直接使用数据的Ping方案，不要配置检查SQL。 根据总是设置超时的原则，配置获取连接超时的时间。 配置合理的空闲连接回收间隔和空闲时间。 4. 缓存4.1 多级缓存 根据缓存原则， 缓存 &gt; 数据库/远程调用 根据就近原则， 堆内缓存 &gt; 堆外缓存 &gt; 集中式缓存 堆内缓存受大小限制，并影响GC 堆内缓存与堆外缓存，分布在每一台应用服务器上，刷新方式比集中式缓存复杂 堆外缓存与集中式缓存，需要序列化/反序列化对象 集中式缓存，有网络传输的成本，特别是数据超过一个网络包的大小。 集中式缓存，一次获取多个键时，在有分区的情况下，需要收发多个网络包。 使用上述条件选择合适的缓存方案，或同时使用多级缓存，逐层回源。 4.2 综述 需要对回源进行并发控制，当key失效时，只有单一线程对该key回源。 基于二进制优于文本数据的原则，JSON的序列化方案较通用与更高的可读性。而对于较大，结构较复杂的对象，基于Kyro，PB，Thrift的二进制序列化方案的性能更高，见后面的序列化方案部分。 4.3 堆内缓存 推荐Guava Cache。 Ehcache较重，性能也较差。更不要使用存在严重bug的Jodd Cache。 GuavaCache： 正确设置并行度等参数。 重载load（）参数，实现单一线程回源。 Guava Cache能后台定时刷新，在刷新的过程中，依然使用旧数据响应请求，不会造成卡顿，但需要重载实现reload（）函数。 Guava Cache同时还支持并发安全版的WeakHashMap。 4.4 堆外缓存 推荐Cassandra的OHC 或者 OpenHFT的Chronical map2。 OHC够简单，其实R大不喜欢Chronical，玩的太深，换个JDK都可能跑不起来。 Chronical map3的license则较不友好，复杂度高且要求JDK8。 其他的Ehcache的Terracota Offheap 一向不喜欢。 4.5 Memcached​客户端： 基于点对点通信优于网关的原则，使用客户端一致性哈希分区。 推荐Spymemcached。 XMemcached 太久没更新，Folsom知名度不高。 注意Spymemcached为单线程单连接架构（一个MemcachedClient只有一条IO线程，与每台Memcached只有一条连接），必要时可多建几个MemcachedClient随机选择，但不要用Commons Pool去封装它，把Spy原本的设计一笔抹杀。 根据在合适场景使用并发的原则，Spymemcached支持异步API。 根据一切皆设超时的原则，可在连接工厂中设置最大超时数，默认值两秒半太长。 数据结构： Key必须设置失效时间。 Key必须有长度限制。 Value长度需要控制，以不超过1个网络包（MTU，千五字节）为佳。 Value大小差别较大的缓存类型，建议拆分到不同MC集群，否则会造成低使用率并且产生踢出。 4.6 Redis as CacheRedis拓扑： 基于点对点通信优于网关的原则，使用如下两种拓扑 无HA的普通分片：由Jedis客户端完成分片路由。 Redis Cluster：同样由Jedis客户端封装分区，跳转，重试等逻辑，需要使用最新版的Jedis版本。 服务端： Cache节点与持久化数据节点不要混用。 Cache节点是否需要持久化要仔细衡量。 由于Redis是单线程，使用taskset进行cpu绑定后可以有效地利用cpu，并在单机上运行多个redis实例。 对热键进行监控，发现不合理的热健要进行分拆等处理。 客户端： Jedis基于Apache Commons Pool进行了多连接的封装，正确配置总连接数不超过Redis Server的允许连接数。 性能考虑，空闲连接检查不要过于频繁（建议30秒以上），另不要打开testOnBorrow等测试参数。 根据一切皆有超时的原则，设定统一的调用超时，获取连接的最长等待时间参数，重试次数 根据在合适的地方异步的原则，Jedis本身没有异步API，只在PipleLine模式下支持。 数据结构： 必须对Key设置失效时间。 Key必须有长度限制。 Value长度需要控制，不要超过一个网络包。另外集合的元素不要超过五千个。 除了使用序列化的String，同样可以考虑用Hash来存储对象，注意内部结构为ZipList与HashTable时，hmget 与hgetall的不同复杂度。 命令： 慎用的命令：LANGE（0, -1）, HGETALL, SMEMBER 高复杂度的命令: ZINTERSTORE, SINTERSTORE, ZUNIONSTORE, ZREM 尽量使用多参数的命令：MGET/MSET，HMGET/HMSET, LPUSH/RPUSH, LRANGE 尽量使用pipeline 根据减少交互的原则，必要时可使用Redis的Lua脚本 5. 服务调用5.1 接口设计 尽量少交互的原则： 支持批量接口，最大的批量，综合考虑调用者的需求与 后端存储的能力。 支持粗粒度接口，在支持原子细粒度接口的同时，支持粗粒度接口/聚合层接口，将多个数据源的获取，多个动作，合并成一个粗粒度接口。 尽量少数据的原则： 在提供返回所有数据的大接口的同时，提供只提供满足部分调用者需要的轻量接口。 最好再提供能定制返回字段的接口。 二进制数据优于文本数据 同样是一个简单通用性，与性能的选择，特别是大数据量时。 5.2 RESTful仅以Apache HttpClient为例，大部分Restful框架都是对Apache HttpClient的封装。 另外OkHttp也值得看看。 不要重复创建ApacheClient实例，使用连接池，正确配置连接池的连接数。 连接池总是有锁，针对不同的服务，使用不同的Apache HttpClient实例，将锁分散开来。在高并发时比使用全局单例的ApacheClient，有很大的性能提升。 根据一切调用皆有超时的原则，每次调用均设置超时时间。RequestConfig里共有Connect Timeout, Socket Timout 和 从Pool中获取连接的Timeout三种超时。 需要异步或并行的场景，使用Apache AsyncHttpClient项目。但要注意AsyncHttpClient项目，检查调用超时的周期默认为1秒。 5.3 自家RPC框架每家的RPC框架特性不同，但考虑点都类似。 6.消息异步6.1 选型 根据就近原则，可以先尝试用JVM内的队列来解决，然后再考虑中央消息系统。 可靠性要求极高的选择RabbitMQ，可支持单条消息确认。 海量消息场景，允许极端情况下少量丢失则使用Kafka。 6.2 Kafka 在同步和异步之间做好权衡，异步批量发送可以极大的提高发送的速度。 关注消费者如下参数：commitInterval(自动提交offset间隔)，prefetchSize(指单次从服务器批量拉取消息的大小)，过大和过小都会影响性能，建议保持默认。 6.3 RabbitMQ 根据扩展性原则，RabbitMQ本身没有分片功能，但可以在客户端自行分片。 如非必要情况，应该保持默认的同步发送模式。 关注消费者如下参数：autocommit(自动提交确认，默认false) ，在消息拉取到本地即认为消费成功，而不是真正消费成功后提交。prefetchCount(预取消息条数，默认64条) 生产者在必要时也可以临时降级不进行confirm。 7. 日志7.1 综述 Log4j2或logback，不要再使用Log4j。 除了应用启停日志，不允许使用超慢的System.out.println() 或 e.printStack(); 严格控制日志量避免过高IO，对海量日志，应该有开关可以动态关停。 如果可能出现海量异常信息，可仿效JDK的优化，用RateLimiter进行限流，丢弃过多的异常日志。 7.2 内容 严格控制日志格式，避免出现消耗较大的输出如类名，方法名，行号等。 业务日志不要滥用toJSONString（）来打印对象，尽量使用对象自身的toString()函数，因为JSON转换的消耗并不低。 在生产环境必定输出的日志，不要使用logger.info（”hello {}”, name）的模式，而是使用正确估算大小的StringBuilder直接拼装输出信息。 7.3 异步日志 同步日志的堵塞非常严重，特别是发生IO的时候，因此尽量使用异步日志。 Logback的异步方案存在一定问题，需要正确配置Queue长度，阀值达到多少时丢弃Warn以下的日志，最新版还可以设置如果队列已满，是等待还是直接丢弃日志。 如果觉得Logback的异步日志每次插入都要询问队列容量太过消耗，可重写一个直接入列，不成功则直接丢弃的版本。 8. 工具类8.1 JSON 使用Jackson 或 FastJSON。GSON的性能较前两者为差，尤其是大对象时。 超大对象可以使用Jackson或FastJSON的流式 API进行处理。 将不需要序列化的属性，通过Annotation排除掉。 FastJson： 尽量使用最新的版本。 SerializerFeature.DisableCircularReferenceDetect 关闭循环引用检查。 Jackson： 设置参数，不序列化为空的属性，等于默认值的属性。 除了jackson-databinding，可试用简化版没那么多花样的jackon-jr。 8.2 二进制序列化需要定义IDL的PB与Thrift，不需要定义的Storm等用的Kyro 都可选择，其他一些比较旧就算了。 8.3 Bean复制在VO，BO之间复制时，使用Orika（生成代码） 或 Dozer（缓存反射），不要使用需要每次进行反射的Apache BeanUitls，Spring BeanUtils。 8.4 日期JDK的日期类与字符串之间的转换很慢且非线程安全。 继续用Java日期不想大动作的，就用CommonsLang的FastDateFormat。 能大动作就用joda time，或者JDK8的新日期API。 9.Java代码优化 与 业务逻辑优化参考《Java调优指南1.8版》，对内存使用，并发与锁等方面进行优化。 规则前置，将消耗较大的操作放后面，如果前面的条件不满足时可。 另外前面提到的一堆原则，比如尽量缓存，尽量少交互，尽量少数据，并行，异步等，都可在此使用。]]></content>
      <tags>
        <tag>checklist, performance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务调用超时处理]]></title>
    <url>%2F2018%2F12%2F11%2Ftimeout-design%2F</url>
    <content type="text"><![CDATA[1. 同步超时 请求超时，客户端给服务端发送请求时超时，此时服务端没有收到客户端的请求； 服务端内部超时，服务端可能存在DB操作、IO操作、调用其他服务超时； 响应超时，服务端给客户端返回响应时超时，此时服务端已经处理了请求。 客户端无论是何种超时，对于客户端来说都是透明的，即客户端无法知道具体发生超时的点。客户端对于超时的处理，有如下两种常见方法： 查询，通过主动查询去拉取超时请求的状态。这种方法需要服务端提供查询接口，并且是根据客户端生成的请求流水号作为查询的条件，因为同一个服务或者接口可能会存在多个调用方，这就需要服务端能够唯一标识某一个客户端请求。 重试，需要设置重试梯度（5s,30s,1min…），以及重试次数的阈值(最多重试的次数)。另外，客户端的重试需要服务端支持幂等（多次执行和只执行一次的效果一样）。 服务端对于①.请求超时和③.响应超时服务端是无法感知的，也就没法进行处理。而在②.服务端内部超时时服务端应该快速失败，立即响应客户端。如果是服务端调用其他服务(例如，服务C)超时，服务端除了快速失败之外，还需要调用服务C的冲正操作。 服务C的冲正接口需要能够判断之前是否接收过服务端超时的请求，如果接收过请求并做了处理，则应该执行反向的回滚操作，如果没有接收过，则忽略冲正请求。 2. 异步超时 请求超时，客户端给服务端发送请求时超时，此时服务端没有收到客户端的请求； 服务端内部超时，服务端可能存在DB操作、IO操作、调用其他服务超时； 同步响应超时，服务端同步返回响应给客户端超时，此时服务端已经接收了请求。 异步响应超时，服务端异步返回响应给客户端超时，此时服务端已经处理完了请求。 客户端此时客户端的处理方式和同步调用时客户端的方式一样。 服务端服务端对于请求超时和同步响应超时无能为力，不过对于异步响应超时、服务端内部超时是可以处理的，具体如下： 对于异步通知超时可以采用最大努力通知，服务端要求客户端在收到异步通知时明确回应服务端接收成功，如果服务端没有收到客户端的回应，服务端重发异步结果。关于异步结果通知超时处理具体可以参考微信支付中的支付结果通知文档 服务端内部超时，我们应该尽最大努力使得用户的请求处理成功。如果是服务端调用其他服务超时，可以通过查询其他服务，根据查询到的结果再进行后续的操作，并将最终的结果通过异步通知反馈给客户端。 消息队列超时 生产者投递消息超时，对应上图的①,②； 消费者消费消息超时。 生产者超时生产者超时一般都采用可靠消息服务来解决 消费者超时一般在开发过程中，基本上都可以认为只要生产者将消息投递到了MQ中间件的服务端，那么该消息就一定会被消费者所消费，这主要是基于对消息中间件的信赖。一般而言，各大MQ中间件都有一定的机制来保障其到消费者之间的消息不会丢失。不同MQ中间件的消费者机制有所不同，大概可以概括成以下两类： 一旦消费者从消息中间件取走消息（无论是推模式或者拉模式都一样），不管消费者是否成功处理，消息中间件都会将该条消息删除； 消费者从消息中间件取走消息之后，消息中间件不会立马将该消息删除，必须要等到消费者告知消息中间件已经处理完了该消息后，消息中间件才会将消息进行删除。 所以在使用消息中间件的时候，我们必须得清楚这个消息中间件产品，它消息消费的具体逻辑是怎样的。]]></content>
      <tags>
        <tag>timeout, design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web安全开发规范]]></title>
    <url>%2F2018%2F11%2F23%2Fweb-security-specification%2F</url>
    <content type="text"><![CDATA[1. 编码安全1. 输入验证 说明 检查项 概述 任何来自客户端的数据，如URL和参数、HTTP头部、 JS戓其他嵌入代码提交的信息都属于不可信数据 白名单 能使用白名单就使用白名单 黑名单 不可信数据中包含不良输入字符时,如空字节(%00)、换行符(%0d,%0a,\r, \n)、路径字符(…/ 或 …)等,建议直接阻止该数据,若需要接受该数据,则应做不同方式的净化处理 规范化 不可信数据的净化和校验前置进行规范化,如将目录遍历(./或)等相对路径转化成绝对路径URL解码等 净化 不可信数据需实施各种净化处理时,应彻底删除恶意字符,只留下已知安全的字符,或者在处理前对它们进行适当编码或”转义”,如数据输出到页面时对其进行HTML编码可防止脚本攻击 合法性校验 不可信数据的合法性校验包括:数据类型如字符.数字、日期等特征;数据范围;数据长度等 防范SQL注入 不可信数据进入后端数据库操作前,使用参数化查询来处理,避免出现SQL注入 文件校验 不可信数据为解压缩的文件时,如果文件位于服务目录外或文件大小超过限制,应拒绝处理 访问控制 不可信数据通过上述校验后,还应确认所提交的内容是否与用户的身份匹配,避免越权访问 2. 输出验证 说明 检查项 概述 考虑目标编译器的安全性，对所有输出字符进行正确编码与数据脱敏 编码场景 不可信数据输出到前后端页面时,根据输出场景对其进行相关编码,如HTML实体编码、UR编码 净化场景 针对操作系统命令、SQL和LDAP查询,净化所有输出的敏感信息,如银行卡、手机号、系统信息等 3. SQL注入1234567let querySQL = ` SELECT * FROM user WHERE username='$&#123;username&#125;' AND psw='$&#123;password&#125;'`;// 接下来就是执行 sql 语句... 恶意攻击者输入的用户名是 zoumiaojiang’ OR 1 = 1 –，密码随意输入 说明 检查项 概述 用户的输入参数进入SQL操作前,对输入进行合法性校验 参数化处理 用参数化查询(Java用 PreparedStatement,C#用 Sqlparameter)方法对敏感字符如”进行转义,然后再进行SQL操作 最小化授权 为每个应用配置最小化数据库操作权限,禁止用管理员权限进行数据库操作,限制操作连接数 敏感数据加密 敏感信息都采用了加密、哈希或混淆等方式进行保密存储,降低可能漏洞带来的数据泄露风险 禁止错误回显 禁止系统开启 Debug模式或异常时返回包含敏感信息的提示,建议使用自定义的错误信息模板异常信息应存放在日志中用于安全审计 4. XSS跨站 Cross Site Script 持久型XSS 非持久型XSS 基于字符集的 XSS 说明 检查项 输入校验 对输入的数据进行过滤和转义,包含但不限于&lt;&gt;”9%0&amp;+\V”等危险特殊字符 页面渲染的所有内容或者渲染的数据都必须来自于服务端。前端渲染的时候对任何的字段都需要做 escape 转义编码。不一定来源于 URL，refferer，forms 等，还有可能来源于数据库中读出来的数据 输出编码 输入数据输出到不同场景中进行不同形式的编码,如输出到HTML标签中则进行HTML编码输出到URL中则进行URL编码,输出到JS中则行 Script编码,输出到 CSS中则进行CSS编码 4. XML注入 说明 检查项 输入校验 在XML文档内部或外部引用数据时,过滤用户提交的参数,如&lt;、&gt;&amp;等特殊字符。禁止加载外部实体,禁止报错 输出编码 建议对XML元素属性或者内容进行输出转义 5. CSRF跨站请求伪造Cross-Site Request Forgery 盗用你的登录身份，可以理解为有一个小偷在你配钥匙的地方得到了你家的钥匙，然后拿着钥匙去你家想偷什么偷什么 说明 检查项 Token使用 在非 GET 请求中增加 token。在重要操作的表单中增加会话生成的 Token字段一次一用,提交后在服务端校验该字段 二次验证 在关键表单提交时,要求用户进行二次身份验证如密码、短信验证码等 Referer验证 检验用户请求中 Referer:字段是否存在跨域提交的情况 2. 逻辑安全1. 身份验证 说明 检查项 概述 所有对非公开的网页和资源的访问,必须在后端服务上执行标准的、通用的身份验证过程 提交凭证 用户凭据必须经过加密且以POST方式提交,建议用HTTPS协议来加密通道、认证服务端 错误提示 安全地处理失败的身份校验,如使用”用户名或密码错误”来提示失败,防止泄露过多信息 异常处理 登录入口应具有防暴力或撞库猜解(利用已泄露的密码字典进行批量登录尝试)的措施,超过1次验证失败自动启用图灵测试,超过多次验证失败自动启用账户锁定机制限制其访问 二次验证 在执行关键操作(如账户密码修改、资料更新、交易支付等)时,先启动图灵测试,再对用户身份进行二次验证。交易支付过程还应该形成完整的证据链,待交易数据应经过发起方数字签名 多因子验证 高度敏感或核心的业务系统,建议使用多因子身份验证机制,如短信验证码、软硬件 Token等。 2. 短信验证 说明 检查项 验证码生成 复杂度至少6位数字或字母,一次一用,建议有效期不超过180秒 验证码限制 前后端设置用户获取频率为60秒一次,建议每个用户每天获取的短信最多10条 安全提示 增加安全提示:至少含本次操作的功能、验证码发送编号、是否是个人自己操作的风险等信息 凭证校验 禁止在响应中返回验证码,服务器端同时校验密码、短信验证码等凭证信息,防止出现多阶段认证绕过的漏洞 3. 图灵测试 说明 检查项 验证码生成 复杂度至少4位数字或字母,或者采用拼图等验证方式,一次一用,建议有效期不超过180秒 验证码使用 建议从用户体验和安全角度出发,可设计为当用户输错1次密码后自动弹出验证码输入框验证 验证码校验 禁止在响应中返回验证码,验证码校验应在服务端进行 4. 密码管理 说明 检查项 密码设置 密码设置时,应该满足8位及以上长度,含大小写字母、数字及特殊字符等的要求。用户密码设置必须经过后端验,不允许设置不满定复杂度要求的敏感密码 密码存储 用户密码存储时,应采用哈希算法(如SHA1)计算用户密码和唯一随机盐值(Salt)的摘要值保存其摘要和Sat值,建议分开存储这两个值 密码修改 用户修改密码时,修改操作需要通过手机号或者邮箱地均进行一次身份验证。密码变更时,应短信或者邮件通知如用户是否是本人操作,告知其安全风险 密码找回 用户密码找回时,后端需要对注册手机号或邮箱进行二次验证,验证码和验证链接应发送至预先注册的地址,并设置有效期以防止暴力破解。密保问题,应当支持尽可能随机的问题提问 密码使用 应用开发中禁止设置万能密码、硬编码明文的密 码、使用数据库管理员账户操作、不同用户公用账户操作或者将密码输出到日志文件或者控制台 5. 会话安全 说明 检查项 防止会话劫持 在应用程序进行身份验证时,建议持续使用HTTPS连接,认证站点使用HTTPS协议。如果连接是从防止会话劫持HTTP跳转到HTTPS,需要重新生成会话标识符。禁止在HTTP和HTTPS之间来回转换,这可能会导致会话被劫持 会话标识符安全 设置会话 Cookie时,正确设置” Httponly’属性(禁止脚本等读取 Cookie信息)” Secure’属性(禁止Cookie通过HTTP连接传递到服务器端进行验证);” Domain”属性(跨域访问时可指定的授权访问域名),”Path”属性(授权可访问的目录路径) 防止CSRF攻击 服务器端执行了完整的会话管理机制,保证每个会话请求都执行了合法的身份验证和权限控制 会话有效期 会话应在平衡风险和功能需求的基础上设置有效期。定期生成一个新的会话标识符并使上一个会话标识符失效,这可以缓解那些因原会活标识符被盗而产生的会话劫持风险 会话注销 注销功能应用于所有受身份验证保护的网页,用户会话注销登出后应立即清理会话相关信息,终止相关的会话连接 6. 访问控制 说明 检查项 控制管理 限制只有授权的用户才能访问受保护的URL、文件、服务、应用数据、配置等 接口管理 限制只有授权的外部应用程序或接口才能访问受保护的本地程序或资源等 权限变更 当权限发生变更时,应记录日志,并通知用户是否是本人操作,告知存在的安全风险 7. 文件上传安全 说明 检查项 身份校验 进行文件上传时,在服务端对用户的身份进行合法性校验 合法性校验 进行文件上传时,在服务端对文件属性进行合法性校验,白名单形式检查文档类型(如文件的后缀名、文件头信息校验等)和大小(图片校验长、宽和像素等) 存储环境设置 进行文件保存时,保存在与应用环境独立的文档服务器中(配置独立域名),保存的目录权限应设置为不可执行 隐藏文件路径 进行文件保存时,成功上传的文件需要进行随机化重命名,禁止给客户端返回保存的路径信息 文件访问设置 进行文件下载时,应以二进制形式下载,建议不提供直接访问(防止木马文件直接执行) 8. 接口安全 说明 检查项 网络限制 调用方网络限制,比如通过防火墙、主机host和Nginx deny等技术措施进行校验 身份认证 调用方身份认证,比如key、 secret、证书等技术措施进行校验,禁止共享凭证 完整性校验 调用的数据安全,对全部参数使用SHA1等摘要运算进行数字签名,识别数据被篡改 合法性校验 调用的参数检查,如参数是否完整,时间戳和Token是否有效,调用权限是否合法等 可用性要求 调用的服务要求,调用满足等幂性即保持数据一致性,对调用频率和有效期进行限制 异常处理 调用的异常处理,调用行为实时检测,发现异常及时阻拦 4. 数据安全1. 敏感信息 说明 检查项 敏感信息传输 敏感信息传输时,禁止在GET请求参数中包含敏感信息,如用户名、密码、卡号等。建议为所有敏感信息采用TSL加密传输 客户端保存 客户端保存敏感信息时,禁止其表单中的自动填充功能、以明文形式保存敏感信息 服务端保存 服务端保存敏感信息时,禁止在程序中硬编码敏感信息,明文存储用户密码、身份证号、银行卡号、持卡人姓名等敏感信息,临时写入内存或文件中的敏感数据,应及时清除和释放 敏感信息维护 敏感信息维护时,禁止将源码或SQL库上传到开源平台或社区,如 Github、开源中国等 敏感信息展示 敏感信息展示时,如果是展示在web页面上,应在后端服务器上进行敏感字段的脱敏处理 2. 日志规范 说明 检查项 记录原则 确保日志记录包含了重要的应用事件,但禁止保存敏感信息,如会话标识,账户密码、证件等 事件类型 记录所有的身份验证、访问操作、数据变更、关键操作、管理功能、登出记录等事件 事件要求 要记录时间、IP地址和用户账户(如果已通过验证) 日志保护 日志受到严格保护,避免未授权的读取或写入访问 3. 异常处理 说明 检查项 容错机制 在应用实现时应包含完整的功能异常捕获机制如try-catch块,典型位置:文件、网络、数据库、命令操作等。一旦出现异常,应该在日志中完整记录异常的发生时间、代码位置、报错详情、触发错误的可能用户等,重要系统的严重异常应该有报警的机制,及时通知系统运营者及时排查并修复 自定义错误信息 禁止在异常中系统、应用服务器的指纹信息，禁止返回任何系统生成的消息或其他调试信息 隐藏用户信息 禁止在系统异常时泄露用户的隐私信息,典型的有:身份信息、个人住址、电话号码、银行账号、通讯记录、定位信息等 隐藏系统信息 禁止在系统异常时泄露系统的敏感信息(用户账户和密码、系统开发密钥、系统源代码、应用架构、系统账户和密码、网络拓扑等) 异常状态恢复 方法发生异常时要恢复到之前的对象状态,如业务操作失败时的回滚操作等,对象修改失败时要恢复对象原来的状态,维持对象状态的一致性 5. 主机安全1. I/O操作 说明 检查项 共享环境文件安全 在多用户系统中创建文件时应指定合适的访问许可,以防止未授权的文件访问,共享目录中文件的读/写/可执行权限应该使用白名单机制,实现最小化授权 数据访问检查 防止封装好的数据对象被未授权使用,设置合理的数据缓存区大小以防止耗尽系统资源 应用文件处理 应用程序运行过程中创建的文件,需设置访问权限(读、写、可执行),临时文件使用完毕及时删除 2. 运行环境 说明 检查项 最小化开放端口 关闭操作系统不需要的端口和服务 后台服务管理 后台(如数据缓存和存储、监控、业务管理等)限内部网络访问,开放在公网的必须设置身份验证和访问控制 环境配置 使用安全稳定的操作系统版本、Web股务器软件各种应用框架、数据库组件等 敏感代码处理 将客户端敏感代码(如软件包签名、用户名密码校验等)都放在o等软件包中防止篡改 关闭调试通道 生产代码不包含任何调试代码或接口 通信安全 配置网站的HTTPS证书或其它加密传输措施 6. DDoS 攻击Distributed Denial of Service 我开了一家店。平时门庭若市，生意特别红火，而对面二狗家的火锅店却无人问津。二狗为了对付我，想了一个办法，叫了五十个人来我的火锅店坐着却不点菜，让别的客人无法吃饭。 网络层 DDoSSYN Flood 攻击 TCP 三次握手、慢型 DDoS 攻击 网络层 DDoS 防御流量清洗、负载均衡、限制SYN 半连接数目、缩短 SYN 半连接的 Timeout 时间、限制单 IP 请求频率、禁止 ICMP 包、加钱堆机器、CDN分流隐藏IP 应用层 DDoS目的就是耗尽你的带宽 恶意刷消耗资源比较多的页面 HTTP 慢速连接攻击 设置一个较大的 Conetnt-Length，每次只发送很少的字节，让服务器一直以为 HTTP 头部没有传输完成，这样连接一多就很快会出现连接耗尽。 应用层 DDoS 防御 判断 User-Agent 字段（不可靠，因为可以随意构造） 针对 IP + cookie，限制访问频率（由于 cookie 可以更改，IP 可以使用代理，或者肉鸡，也不可靠) 关闭服务器最大连接数等，合理配置中间件，缓解 DDoS 攻击。 请求中添加验证码，比如请求中有数据库操作的时候。 编写代码时，尽量实现优化，并合理使用缓存技术，减少数据库的读取操作。 加钱堆机器。。 应用层 DDoS 防御的核心就是区分人与机器（爬虫） 利用 XSS，借刀杀人 举个例子，如果 12306 页面有一个 XSS 持久型漏洞被恶意攻击者发现，只需在春节抢票期间在这个漏洞中执行脚本使得往某一个小站点随便发点什么请求，然后随着用户访问的增多，感染用户增多，被攻击的站点自然就会迅速瘫痪了。 7. 流量劫持当用户访问 baidu.com 的时候，给你展示的并不是或者不完全是 baidu.com 提供的 “内容” DNS 劫持电脑中毒，被恶意篡改了路由器的 DNS 配置 HTTP 劫持 不法运营商和黑产勾结能够截获 HTTP 请求返回内容，并且能够篡改内容，然后再返回给用户，从而实现劫持页面，轻则插入小广告，重则直接篡改成钓鱼网站页面骗用户隐私。 全站改造成 HTTPS]]></content>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo的问题与坑]]></title>
    <url>%2F2018%2F11%2F06%2Fdubbo-trouble%2F</url>
    <content type="text"><![CDATA[问题与坑0. dubbo中的反序列化异常：构造函数抛出java.lang.NullPointerException？1. 同时配置了 XML 和 properties 文件，则 properties 中的配置无效只有 XML 没有配置时，properties 才生效。 2. dubbo 缺省会在启动时检查依赖是否可用，不可用就抛出异常，阻止 spring 初始化完成，check 属性默认为 true。测试时有些服务不关心或者出现了循环依赖，将 check 设置为 false 3. 服务注册不上检查 dubbo 的 jar 包有没有在 classpath 中，以及有没有重复的 jar 包 检查暴露服务的 spring 配置有没有加载 在服务提供者机器上测试与注册中心的网络是否通 4. 出现 RpcException: No provider available for remote service 异常表示没有可用的服务提供者， a. 检查连接的注册中心是否正确 b. 到注册中心查看相应的服务提供者是否存在 c. 检查服务提供者是否正常运行 5. 出现” 消息发送失败” 异常通常是接口方法的传入传出参数未实现 Serializable 接口。 6. Dubbo 在Telnet下的bug1.目前使用的dubbo-2.5.3方法重载存在问题，判断逻辑存在bug，导致选择方法存在错误，不能正常使用Telnet命名 查看官方issue：https://github.com/alibaba/dubbo/commit/27917f2e86bbd97ee047d69817730a57bdf5ad6b#diff-025ea1457d9d7d70588648a38beba029 2.解决方法： 升级到2.5.4 Telnet文本协议调用dubbo接口 dubbo传输对象使用Transient标识后,有序列化bug! 虽然标识了Transient关键字,还是可以得到该对象，有安全漏洞！]]></content>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot 自动配置原理]]></title>
    <url>%2F2018%2F10%2F16%2Fspringboot-autoconfig%2F</url>
    <content type="text"><![CDATA[1. 快速入门工程1. 配置属性 YAML 注意键和值由冒号及空白字符分开。强调下，空白字符是必须的 .properties 文件默认编码方式是 iso-8859 ，Spring Boot 应用以 UTF-8 的编码方式读取，就导致出现乱码问题 2. 创建属性类1234567891011121314151617181920212223import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Component;/** * 书属性 */@Componentpublic class BookProperties &#123; /** * 书名 */ @Value("$&#123;demo.book.name&#125;") private String name; /** * 作者 */ @Value("$&#123;demo.book.writer&#125;") private String writer; // ... 省略 getter / setter 方法&#125; @Component 注解 @Component 对类进行标注，职责是泛指组件 Bean ，应用启动时会被容器加载并加入容器管理。常见的 @Controller、@Service 、@Repository 是 @Component 的分类细化组件，分别对应控制层、服务层、持久层的 Bean。 @Value 注解 @Value 对 Bean 的字段或者方法参数进行标注，职责是基于表达式给字段或方法参数设置默认属性值。通常格式是注解 + SpEL 表达式，如 @Value(“SpEL 表达式”)。 使用 @Vlaue 注解来引用属性值时，确保所引用的属性值在 application.properties 文件存在并且相对应匹配，否则会造成 Bean 的创建错误，引发 java.lang.IllegalArgumentException 非法参数异常。 2. 配置属性的获取方式2.1 @Value 注解@Value 注解对 Bean 的变量或者方法参数进行标注，职责是基于表达式给字段或方法参数设置默认属性值。通常格式是注解 + SpEL 表达式，如 @Value(“SpEL 表达式”)，并标注在对应的字段或者方法上方，且必须对变量一一标注。这种方式适用于小而不复杂的属性结构。属性结构复杂，字段很多的情况下，这种方式会比较繁琐，应该考虑使用 @ConfigurationProperties 注解。 12345678910111213141516171819202122232425import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.PropertySource;import org.springframework.stereotype.Component;/** * 书属性 */@Component@PropertySource("classpath:book.properties")public class BookProperties &#123; /** * 书名 */ @Value("$&#123;demo.book.name&#125;") private String name; /** * 作者 */ @Value("$&#123;demo.book.writer&#125;") private String writer; // ... 省略 getters / setters 方法&#125; 2.2 @ConfigurationProperties 注解1234567891011121314151617181920212223import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;/** * 书属性 * */@Component@ConfigurationProperties(prefix = "demo.book")public class BookComponent &#123; /** * 书名 */ private String name; /** * 作者 */ private String writer; // ... 省略 getters / setters 方法&#125; @ConfigurationProperties 注解的 prefix 是指定属性的参数名称。会匹配到配置文件中 “ demo.book. ” 结构的属性，星号 “ ” 是指会一一对应匹配 BookComponent 类的字段名。例如，字段 name 表示书名，会匹配到 demo.book.name 属性值。 @Value 注解方式强制字段必须对应在配置文件， @ConfigurationProperties 注解方式则不是必须的。一般情况下，所有字段应该保证一一对应在配置文件。如果没有属性值对应的话，该字段默认为空， @ConfigurationProperties 注解方式也不会引发任何异常，Spring Boot 推荐使用 @ConfigurationProperties 注解方式获取属性。 org.springframework.boot.context.properties.ConfigurationProperties 注解参数 prefix字符串值，绑定该名称前缀的属性对象。 value字符串值，功能同 prefix 参数。 ignoreInvalidFields布尔值，默认 false。绑定对象时，忽略无效字段。 ignoreUnknownFields布尔值，默认 true。绑定对象时，忽略未知字段。 2.3 @ConfigurationProperties 数据验证当属性类被 @Validated 注解标注时，Spring Boot 初始化时会验证类的字段。在类的字段上添加 JSR-303 约束注解，进行数据验证。 123456789101112131415161718192021222324252627282930import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;import org.springframework.validation.annotation.Validated;import javax.validation.constraints.NotEmpty;import javax.validation.constraints.NotNull;/** * 书属性 * */@Component@ConfigurationProperties(prefix = "demo.book")@Validatedpublic class BookComponent &#123; /** * 书名 */ @NotEmpty private String name; /** * 作者 */ @NotNull private String writer; // ... 省略 getters / setters 方法&#125; 3. 外化配置配置分离存储在 classpath 之外 3.1 外化配置优先级java -jar target/chapter-2-spring-boot-config-1.0.jar --demo.book.writer=Jeff SpringApplication.setAddCommandLineProperties(false); 本地 Devtools 全局配置 测试时 @TestPropertySource 注解配置 测试时 @SpringBootTest 注解的 properties 配置 命令行配置 SPRING_APPLICATION_JSON 配置 ServletConfig 初始化参数配置 ServletContext 初始化参数配置 Java 环境的 JNDI 参数配置 Java 系统的属性配置 OS 环境变量配置 只能随机属性的 RandomValuePropertySource 配置 工程 jar 之外的多环境配置文件（application- {profile}.properties 或 YAML） 工程 jar 之内的多环境配置文件（application- {profile}.properties 或 YAML） 工程 jar 之外的应用配置文件（application.properties 或 YAML） 工程 jar 之内的应用配置文件（application.properties 或 YAML） @Configuration 类中的 @PropertySource 注解配置 默认属性配置（SpringApplication.setDefaultProperties 指定） 3.2 属性引用属性之间可以直接通过 “${propName}” 的形式引用其他属性 1234## 书信息demo.book.name=[Spring Boot 2.x Core Action]demo.book.writer=BYSocketdemo.book.description=$&#123;demo.book.writer&#125;'s$&#123;demo.book.name&#125; 3.3 使用随机数例如注入某些密钥、UUID 或者测试用例，需要每次不是一个固定的值。RandomValuePropertySource 类随机提供整形、长整形数、UUID 或者字符串。 123456my.secret=$&#123;random.value&#125;my.number=$&#123;random.int&#125;my.bignumber=$&#123;random.long&#125;my.uuid=$&#123;random.uuid&#125;my.number.less.than.ten=$&#123;random.int(10)&#125;my.number.in.range=$&#123;random.int[1024,65536]&#125; 3.4 多环境配置类似 Maven 构建配置文件的思路，即配置多个不同环境的配置文件，再通过 spring.profiles.active 命令去指定读取特定配置文件的属性。 多环境配置文件的约定命名格式为 application-{profile}.properties。多环境配置功能默认为激活状态，如果其他配置未被激活，则 {profile} 默认为 default，会加载 application-default.properties 默认配置文件，没有该文件就会加载 application.properties 应用配置文件。 4. SpringBoot 自动配置原理4.1 外化配置和自动配置spring-boot-autoconfigure 包里面定义了很多默认的配置项。Spring Boot 会根据所添加的依赖，自动加载依赖相关的配置属性。 自动化配置代替了传统的繁琐的xml配置模式，以前使用 Spring MVC ，需要进行配置组件扫描、调度器、视图解析器等，使用 Spring Boot 自动配置后，只需要添加 MVC 组件即可自动配置所需要的 Bean。 External Configuration指的不是把配置内容分离到properties文件里，而是配置存储在classpath之外，比如spring cloud config 中 自动化配置本身包含了两块内容：@Configuration的定义和properties属性的定义，外部化配置是跟加载过程相关的。 4.2 自动配置原理浅析spring-boot-autoconfigure 包 通过 @EnableAutoConfiguration 核心注解初始化，并扫描 ClassPath 目录中自动配置类对应依赖。比如工程中有木有添加 Thymeleaf 的 Starter 组件依赖。如果有，就按按一定规则获取默认配置并自动初始化所需要的 Bean。 4.3 @EnableAutoConfiguration 核心注解的工作原理@EnableAutoConfiguration 注解核心点是 @Import 的自动配置导入选择器类 AutoConfigurationImportSelector 。 AutoConfigurationImportSelector 会读取 ClassPath 下面的 META-INF/spring.factories 文件。 spring.factories 文件中配置的 Spring Boot 自动配置类，例如常见的Jpa 自动配置类 JpaRepositoriesAutoConfiguration、Thymeleaf 自动配置类 ThymeleafAutoConfiguration 、 WebMvcAutoConfiguration Web MVC 自动配置类和ServletWebServerFactoryAutoConfiguration 容器自动配置类等 。 spring.factories 文件和 application.properties 文件都属于配置文件，均为键值对格式。里面配置的每个自动配置类都会定义相关 Bean 的默认配置，也会定义什么条件下自动配置和哪些 Bean 被实例化。 当 pom.xml 添加某 Starter 依赖组件的时候，就会自动触发该依赖的默认配置。 4.4 spring-boot-starter-web Starter 组件浅析容器自动配置类 ServletWebServerFactoryAutoConfiguration 的部分代码如下：123456789101112package org.springframework.boot.autoconfigure.web.servlet;@Configuration@ConditionalOnClass(&#123;ServletRequest.class&#125;)@ConditionalOnWebApplication( type = Type.SERVLET)@EnableConfigurationProperties(&#123;ServerProperties.class&#125;)@Import(&#123;ServletWebServerFactoryAutoConfiguration.BeanPostProcessorsRegistrar.class&#125;)public class ServletWebServerFactoryAutoConfiguration &#123;... 省略&#125; @ConditionalOnClass 注解表示对应的 ServletRequest 类在 ClassPath 目录下面存在，并且 @ConditionalOnWebApplication 注解表示该应用是 Servlet Web 应用时，才会去启动容器默认配置 通过 ServerProperties 类默认设置了端口为 8080 Type.SERVLET 枚举代表 Servlet Web 应用，Type.REACTIVE 枚举代表响应式 WebFlux 应用。 @ConditionalOnClass 注解类似功能的还有 @ConditionalOnMissingBean 、@ConditionalOnProperty等注解 4.5 一些自动化配置造成的问题 Spring Boot 工程添加某些 Starter 组件依赖，但不想触发组件自动配置 Spring Boot 配置多个不同数据源配置时，比如使用 XML 配置多数据源，但其默认数据源配置会触发自动配置出现问题。 解决方式是排除不需要的特定自动配置类：@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class}) 5. 利用自动配置自定义 Starter 组件一个完整的 Starter 组件包括以下两点： 提供自动配置功能的自动配置模块。 提供依赖关系管理功能的组件模块，即封装了组件所有功能，开箱即用。 实现自定义 Starter 组件，并不会将这两点严格区分，可以将自动配置功能和依赖管理结合在一起实现。 5.1 创建一个新的 Spring Boot 工程，命名为 spring-boot-starter-swagger。在 pom.xml 配置相关123456789101112131415161718192021222324252627282930313233&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;$&#123;version.swagger&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;$&#123;version.swagger&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-bean-validators&lt;/artifactId&gt; &lt;version&gt;$&#123;version.swagger&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.12&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 5.2 新建 SwaggerProperties 配置类新建名为 SwaggerProperties Swagger2 属性配置类，包含了所有默认属性值。使用该组件时，可以在 application.properties 配置文件配置对应属性项，进行覆盖默认配置。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import lombok.Data;import lombok.NoArgsConstructor;import org.springframework.boot.context.properties.ConfigurationProperties;import springfox.documentation.schema.ModelRef;import java.util.ArrayList;import java.util.LinkedHashMap;import java.util.List;import java.util.Map;@Data@ConfigurationProperties("swagger")public class SwaggerProperties &#123; /**是否开启swagger**/ private Boolean enabled; /**标题**/ private String title = ""; /**描述**/ private String description = ""; /**版本**/ private String version = ""; /**许可证**/ private String license = ""; /**许可证URL**/ private String licenseUrl = ""; /**服务条款URL**/ private String termsOfServiceUrl = ""; private Contact contact = new Contact(); /**swagger会解析的包路径**/ private String basePackage = ""; /**swagger会解析的url规则**/ private List&lt;String&gt; basePath = new ArrayList&lt;&gt;(); /**在basePath基础上需要排除的url规则**/ private List&lt;String&gt; excludePath = new ArrayList&lt;&gt;(); /**分组文档**/ private Map&lt;String, DocketInfo&gt; docket = new LinkedHashMap&lt;&gt;(); /**host信息**/ private String host = ""; /**全局参数配置**/ private List&lt;GlobalOperationParameter&gt; globalOperationParameters; ... 省略，具体代码见 GitHub&#125; 用 @ConfigurationProperties(prefix = “swagger”) 标注在类上方是指定属性的参数名称为 swagger。会对应匹配到配置文件中 “ swagger.* ” 结构的属性，例如，字段标题 title 表示标题，会匹配到 swagger.title 属性值。 5.3 新建自动化配置类 SwaggerAutoConfiguration （提供 Swagger2 依赖关系管理功能和自动配置功能）12345678910111213141516171819202122232425262728293031323334import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Import;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;@Configuration@ConditionalOnProperty(name = "swagger.enabled", matchIfMissing = true)@Import(&#123; Swagger2DocumentationConfiguration.class, BeanValidatorPluginsConfiguration.class&#125;)public class SwaggerAutoConfiguration implements BeanFactoryAware &#123; private BeanFactory beanFactory; @Bean @ConditionalOnMissingBean public SwaggerProperties swaggerProperties() &#123; return new SwaggerProperties(); &#125; @Bean @ConditionalOnMissingBean @ConditionalOnProperty(name = "swagger.enabled", matchIfMissing = true) public List&lt;Docket&gt; createRestApi(SwaggerProperties swaggerProperties) &#123; ... 省略，具体代码见 GitHub &#125; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; this.beanFactory = beanFactory; &#125;&#125; @Configuration 注解标注在类上方，表明该类为配置类。 @Import 注解引入 Swagger2 提供的配置类 Swagger2DocumentationConfiguration 和 Bean 数据验证插件配置类 BeanValidatorPluginsConfiguration。 @ConditionalOnMissingBean 注解标注了两处方法，当 Bean 没有被创建时会执行被标注的初始化方法。第一处被标记方法是 swaggerProperties() ，用来实例化属性配置类 SwaggerProperties;第二处被标记方法是 createRestApi()， 用来实例化 Swagger2 API 映射的 Docket 列表对象。 @ConditionalOnProperty 注解标注在 createRestApi() 方法，name 属性会去检查环境配置项 swagger.enabled 。默认情况下，属性存在且不是 false 的情况下，会触发该初始化方法。matchIfMissing 属性默认值为 false ，这里设置为 true，表示如果环境配置项没被设置，也会触发。 5.4 新建启动注解类 EnableSwagger2Doc用于开关 spring-boot-starter-swagger 组件依赖 1234567@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(&#123;SwaggerAutoConfiguration.class&#125;)public @interface EnableSwagger2Doc &#123;&#125; 上面代码 @Import 注解引入 Swagger2 自动配置类 SwaggerAutoConfiguration。当将该注解配置在应用启动类上方，即可开启 Swagger2 自动配置及其功能。]]></content>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 集成配置 HTTPS]]></title>
    <url>%2F2018%2F08%2F18%2Fspringboot-https%2F</url>
    <content type="text"><![CDATA[简单来说，修改 Tomcat 容器配置，加一层对应的安全约束配置即可。 申请SSL证书打开阿里云证书，可以申请免费证书一年有效。一年后继续免费申请一年即可。 下载，这块选择 Tomcat ，因为这次集成只需要修改 Spring Boot 内嵌容器 Tomcat 配置。如果是 nginx ，也可以对应下载并集成配置 配置 HTTPS将 .pfx 文件复制到 resources 根目录，然后配置 application-prod.properties （生产配置文件）： 12345## HTTPSserver.ssl.key-store=classpath:xx.com.pfxserver.ssl.key-store-password=123456server.ssl.key-store-type=PKCS12server.port=443 然后新增 HttpsConfig 类，代码如下 123456789101112131415161718192021222324@Configurationpublic class HttpsConfig &#123; /** * spring boot 1.x */ /* */ @Bean public EmbeddedServletContainerFactory servletContainer() &#123; TomcatEmbeddedServletContainerFactory tomcat = new TomcatEmbeddedServletContainerFactory() &#123; @Override protected void postProcessContext(Context context) &#123; SecurityConstraint constraint = new SecurityConstraint(); constraint.setUserConstraint("CONFIDENTIAL"); SecurityCollection collection = new SecurityCollection(); collection.addPattern("/*"); constraint.addCollection(collection); context.addConstraint(constraint); &#125; &#125;; return tomcat; &#125;&#125; 运行即可，从日志看出已经支持 HTTPS: 122019-06-16 10:42:42.989 INFO 16727 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 443 (https)2019-06-16 10:42:45.782 INFO 16727 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 443 (https) 修改链接所有的http链接修改为https，你懂的 301重定向对于不好修改的http地址，需在Nginx配置中HTTP链接301重定向 HTTP Strict Transport Security (HSTS)浏览器自动将http转写成https CookieSet-Cookie字段加上Secure标志 确保浏览器只在使用 HTTPS 时，才发送Cookie]]></content>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java线上问题排查总结]]></title>
    <url>%2F2018%2F08%2F01%2Fonline-troubleshoot%2F</url>
    <content type="text"><![CDATA[Linux命令类tail1tail -300f fixed-center.log #倒数300行并进入实时监听文件写入模式 grep12345678910grep forest f.txt #文件查找grep forest f.txt cpf.txt #多文件查找grep 'log' /home/admin -r -n #目录下查找所有符合关键字的文件cat f.txt | grep -i shopbase #匹配的行 grep 'shopbase' /home/admin -r -n --include *.&#123;vm,java&#125; #指定文件后缀grep 'shopbase' /home/admin -r -n --exclude *.&#123;vm,java&#125; #反匹配seq 10 | grep 5 -A 3 #上匹配seq 10 | grep 5 -B 3 #下匹配seq 10 | grep 5 -C 3 #上下匹配，平时用这个就妥了cat f.txt | grep -c ‘SHOPBASE’ #匹配计数 find12345678910111213sudo -u admin find /home/admin /tmp /usr -name \*.log #多个目录去找find . -iname \*.txt #大小写都匹配find . -type d #当前目录下的所有子目录find /usr -type l #当前目录下所有的符号链接find /usr -type l -name "z*" -ls #符号链接的详细信息 eg:inode,目录find /home/admin -size +250000k #超过250000k的文件，当然+改成-就是小于了find /home/admin f -perm 777 -exec ls -l &#123;&#125; \; #按照权限查询文件find /home/admin -atime -1 #1天内访问过的文件find /home/admin -ctime -1 #1天内状态改变过的文件 find /home/admin -mtime -1 #1天内修改过的文件find /home/admin -amin -1 #1分钟内访问过的文件find /home/admin -cmin -1 #1分钟内状态改变过的文件 find /home/admin -mmin -1 #1分钟内修改过的文件 top12ps -ef | grep javatop -H -p pid #获得线程10进制转16进制 netstat1netstat -nat|awk '&#123;print $6&#125;'|sort|uniq -c|sort -rn #查看当前连接，注意close_wait偏高的情况 btrace &amp; greys12sc -df xxx #输出当前类的详情,包括源码位置和classloader结构trace class method #打印出当前方法调用的耗时情况 系统异常排查流程常见的系统异常现象包括: CPU 占用率过高、CPU上下文切换频率次数较高、磁盘满了、磁盘 I/O 过于频繁、网络流量异常（连接数过多）、系统可用内存长期处于较低值（导致 oom killer）等等。 业务应用排查流程常见的业务服务异常现象包括:PV量过高、服务调用耗时异常、线程死锁、多线程并发问题、频繁进行 Full GC、异常安全攻击扫描等。 GC的JVM参数 -XX:+PrintGCDetails -XX:+PrintGCDateStamps`-Xloggc:/usr/local/gc/gc.log -XX:+UseConcMarkSweepGC GC日志分析：MAT、 http://gceasy.io/]]></content>
      <tags>
        <tag>经验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载机制]]></title>
    <url>%2F2018%2F08%2F01%2Fclass-loading%2F</url>
    <content type="text"><![CDATA[初始化时机new、静态字段或方法被使用、反射、父类、main函数调用 加载过程 加载（获取字节流并转换成运行时数据结构，然后生成Class对象） 验证（验证字节流信息符合当前虚拟机的要求） 准备（为类变量分配内存并设置初始值） 解析（将常量池的符号引用替换为直接引用） 初始化（执行类构造器-类变量赋值和静态块的过程） 类加载器 启动类加载器（Bootstrap ClassLoader）：是虚拟机自身的一部分，它负责加载以java.*开头的核心类库 扩展类加载器（Extension ClassLoader）：它负责加载javax.*开头的类和存放在JRE的ext目录下的类 系统类加载器（ApplicationClassLoader）：它负责加载应用程序自身的类 定义：如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式。 优点：采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次。其次防止恶意覆盖Java核心API。 实际使用场景通过编写你自己的ClassLoader，你可以做到： 容器加载（如tomcat） 热部署 代码保护 动态修改类（例如数据库中取得java class） 当创建自己的Class Loader时，只需要重载findClass()这个方法。]]></content>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java内存区域]]></title>
    <url>%2F2018%2F08%2F01%2Fmemory-area%2F</url>
    <content type="text"><![CDATA[内存区域划分所有线程共享的数据区： 方法区: 存储已被虚拟机加载的类信息、方法信息、常量、静态变量、字节码、JIT编译后的本地代码，并使用永久代来实现方法区。1.8中用元空间替代了永久代，元空间并不在虚拟机中，而是使用本地内存，元空间中可能还存在短指针数据区CCS 堆区: 最大的一块区域，用于存放对象的区域，1.7之后常量池移到这里 每个线程都会有一块私有的数据区： 虚拟机栈: 每个方法执行时在其中创建一个栈帧，用于存储局部变量、操作数栈、动态链接、方法出口等信息 本地方法栈: 功能与虚拟机栈相同，为native方法服务 程序计数器: 存放当前正在执行的指令的地址 直接内存： 直接内存并非Java标准。 JDK1.4 加入了新的 NIO 机制，目的是防止 Java 堆 和 Native 堆之间往复的数据复制带来的性能损耗，此后 NIO 可以使用 Native 的方式直接在 Native 堆分配内存。 直接内存区域是全局共享的内存区域。 新生代进入条件优先选择在新生代的Eden区被分配。 老年代进入条件 大对象，-XX:PretenureSizeThreshold 大于这个参数的对象直接在老年代分配，来避免新生代GC以及分配担保机制和Eden与Survivor之间的复制 经过第一次Minor GC仍然存在，能被Survivor容纳，就会被移动到Survivor中，此时年龄为1，当年龄大于预设值就进入老年代 如果Survivor中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于等于该年龄的对象进入老年代 如果Survivor空间无法容纳新生代中Minor GC之后还存活的对象 Java对象不都是分配在堆上还能分配在栈上 逃逸分析逃逸是指在某个方法之内创建的对象，除了在方法体之内被引用之外，还在方法体之外被其它变量引用到；这样带来的后果是在该方法执行完毕之后，该方法中创建的对象将无法被GC回收，由于其被其它变量引用。正常的方法调用中，方法体中创建的对象将在执行完毕之后，将回收其中创建的对象；故由于无法回收，即成为逃逸。 方法逃逸： 1234567public static StringBuffer craeteStringBuffer(String s1, String s2) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb; &#125; 线程逃逸：方法中的局部变量甚至还有可能被外部线程访问到，譬如赋值给类变量或可以在其他线程中访问的实例变量，称为线程逃逸。 如果能证明一个对象不会逃逸到方法或线程外，则可能为这个变量进行一些高效的优化。 栈上分配如果能够通过逃逸分析确定某些对象不会逃出方法之外，那就可以让这个对象在栈上分配内存，这样该对象所占用的内存空间就可以随栈帧出栈而销毁，就减轻了垃圾回收的压力。 同步消除（锁优化） 减少锁持有时间（减少锁的势力范围） 减小锁粒度（如ConcurrentHashMap） 锁分离（如ReadWriteLock） 锁粗化（频繁获取、释放锁优化成一次） 锁消除（编译器做的-server -XX:+DoEscapeAnalysis -XX:+EliminateLocks，并要开启逃逸分析） 标量替换原始数据类型称为标量，对象是聚合量。如果逃逸分析证明一个对象不会被外部访问，并且这个对象是可分解的，那程序真正执行的时候将可能不创建这个对象，而改为直接创建它的若干个被这个方法使用到的成员变量来代替。拆散后的变量便可以被单独分析与优化，可以各自分别在栈帧或寄存器上分配空间，原本的对象就无需整体分配空间了。 注意：逃逸分析比较耗时，效果不稳定。目前HotSpot虚拟机由于实现会比较复杂，暂时还没有做这项优化。 TLABJVM在内存新生代Eden Space中开辟了一小块线程私有的区域TLAB（Thread-local-allocation-buffer）。在Java程序中很多对象都是小对象且用过即丢，它们不存在线程共享也适合被快速GC，所以对于小对象通常JVM会优先分配在TLAB上，并且TLAB上的分配由于是线程私有所以没有锁开销。因此在实践中分配多个小对象的效率通常比分配一个大对象的效率要高。也就是说，Java中每个线程都会有自己的缓冲区称作TLAB，在对象分配的时候不用锁住整个堆，而只需要在自己的缓冲区分配即可。 GC回收机制回收对象不可达对象：通过一系列的GC Roots的对象作为起点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时则此对象是不可用的。GC Roots包括：虚拟机栈中引用的对象、方法区中类静态属性引用的对象、方法区中常量引用的对象、本地方法栈中JNI（Native方法）引用的对象。 彻底死亡条件：条件1：通过GC Roots作为起点的向下搜索形成引用链，没有搜到该对象，这是第一次标记。条件2：在finalize方法中没有逃脱回收（将自身被其他对象引用），这是第一次标记的清理。 如何回收新生代因为每次GC都有大批对象死去，只需要付出少量存活对象的复制成本且无碎片所以使用“复制算法”老年代因为存活率高、没有分配担保空间，所以使用“标记-清理”或者“标记-整理”算法 复制算法：将可用内存按容量划分为Eden、from survivor、to survivor，分配的时候使用Eden和一个survivor，Minor GC后将存活的对象复制到另一个survivor，然后将原来已使用的内存一次清理掉。这样没有内存碎片。标记-清除：首先标记出所有需要回收的对象，标记完成后统一回收被标记的对象。会产生大量碎片，导致无法分配大对象从而导致频繁GC。标记-整理：首先标记出所有需要回收的对象，让所有存活的对象向一端移动。 Minor GC条件当Eden区空间不足以继续分配对象，发起Minor GC。 Full GC条件 调用System.gc时，系统建议执行Full GC，但是不必然执行 老年代空间不足（通过Minor GC后进入老年代的大小大于老年代的可用内存） 方法区空间不足]]></content>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java内存模型]]></title>
    <url>%2F2018%2F07%2F31%2Fjmm%2F</url>
    <content type="text"><![CDATA[定义 JMM是一种规范，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题，保证并发编程场景中的原子性、可见性和有序性。 对象、数组在堆内存中，局部变量、方法定义参数、异常处理器参数不会有内存可见性问题，也不受内存模型的影响。 JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。 实现 volatile、synchronized、final、concurrent包等。其实这些就是Java内存模型封装了底层的实现后提供给程序员使用的一些关键字 主内存：所有变量都保存在主内存中 工作内存：每个线程的独立内存，保存了该线程使用到的变量的主内存副本拷贝，线程对变量的操作必须在工作内存中进行 每个线程都有自己的本地内存共享副本，如果A线程要更新主内存还要让B线程获取更新后的变量，那么需要： 将本地内存A中更新共享变量 将更新的共享变量刷新到主内存中 线程B从主内存更新最新的共享变量 happen-before原则如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系。 它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们解决在并发环境下两操作之间是否可能存在冲突的所有问题。 程序有序性：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作； 锁的有序性：一个unlock操作先行发生于后面对同一个锁的lock操作； volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作； 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C； 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作； 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生； 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行； 对象终结规则：一个对象的初始化完成先行发生于它的finalize()方法的开始；]]></content>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重构实践手册]]></title>
    <url>%2F2018%2F07%2F31%2Frefactor%2F</url>
    <content type="text"><![CDATA[重构是什么 在不改变软件可观察行为的前提下，提高其可理解性，降低其修改成本。 好的重构应该像一边开车一边换轮胎一样，保证系统随时可工作的前提下，还可以对其结构做出安全高效的调整。 重构之前的事 写好单元测试 持续集成、持续交付 代码的坏味道 重复代码 过长的函数、类 过长的参数列表 冗余代码及参数 不可读的名称 什么时候应该重构 事不过三，三则重构 什么时候不应该重构 重构它还不如重新写一个来得简快 项目已经进入了尾期 重构技巧 小步重构，逐步验证 事不过三，三则重构 函数重构 条件表达式 以卫语句取代多层嵌套的if/else 重构指导思想 Solid设计原则 类的单一职责 开闭原则 里氏替换原则 接口隔离原则 依赖倒置原则 工欲善其事必先利其器 SonarLint、阿里巴巴编码扫描插件 IDEA–&gt;Analyze菜单 根目录右键Optimize Imports 参考编码最佳实践]]></content>
      <tags>
        <tag>优化, 重构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存设计模式]]></title>
    <url>%2F2018%2F06%2F15%2Fcache-design%2F</url>
    <content type="text"><![CDATA[一种经典的错误做法：先删除缓存，再更新数据库，再加载最新数据到缓存中。 错误原因：假如，有两个并发操作，一个是更新、一个是查询。更新操作先删除了缓存，然后，查询操作只得去DB拿数据，接着，更新操作才更新DB。这样就产生了脏数据。 缓存更新模式SoR(system-of-record)：数据源，实际存放数据的地方。 缓存更新模式主要分为两类： Cache-Aside Cache-As-SoR(Read Through、Write Through、Write Behind) Cache-Aside 看图：Cache在前，业务代码围绕着Cache写： 12345// 读场景：先从缓存中获取数据if(value == null) &#123; value = loadFromSoR(key); myCache.put(key, value);&#125; 1234// 写场景：先将数据写入SoRwriteToSoR(key, value);// 失效缓存，然后下次读时再加载缓存myCache.invalidate(key); Cache-Aside 适合用 AOP实现。 注意：这里的更新是先更新数据库，成功后，再让缓存失效。 现在，不删除缓存了，读操作依然可以拿到老数据，然后更新操作使缓存失效，后续的查询就都是正确的了。 123为什么不是写完数据库后更新缓存？—— 主要是怕两个并发的写操作导致脏数据。 123是不是这样就不会有并发问题了？不是！比如，读操作没有命中缓存，就去DB取数据，此时来了个更新操作，写完数据后让缓存失效，然后刚才那个读操作又把老数据加载进去了，造成了脏读！但是！！实际上出现的概率非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。 要么通过2PC或是Paxos协议保证一致性，要么就是拼命的降低并发时脏数据的概率，而Facebook使用了这个降低概率的玩法，因为2PC太慢，而Paxos太复杂。当然，最好还是为缓存设置上过期时间 1234567Cache-Aside 并发场景怎么办？- 如果是用户维度的数据(如订单数据、用户数据)，因为并发情况少，可以不考虑，加上过期时间来解决- 对于如商品这种基础数据，可以考虑使用canal订阅binlog，来进行增量更新分布式缓存，但是本地缓存更新会有延迟，需要根据不一致容忍度设置合理的过期时间- 读服务场景，可考虑使用一致性哈希，将相同的操作负载均衡到同一个实例，从而减少并发机率，或设置较短的过期时间。 Cache-As-SoR即把Cache看作是SoR，业务代码只操作Cache，然后由Cache实现对SoR的真实读写。 Read-Through当缓存失效时(过期或LRU换出)，Cache Aside是由调用方负责把数据加载入缓存中，而 Read-Through 是由缓存服务自身来加载，对应用是透明的。 需要配置一个 CacheLoader 组件来回源到 SoR 加载源数据。Guava Cache、Ehcache 3.x 都支持该模式。 优点： 业务代码更简洁。 解决了 Dog-pile effect，即当某个缓存失效时，又有大量请求没命中从而回源到后端，会导致后端压力过大，此时限定一个请求去拿即可。 Write-Through和Read-Through类似，只是把缓存更新操作挪到了更新操作中。 业务代码首先调用Cache写(新增/修改)数据，然后由Cache负责写SoR，而不是由业务代码(注意：SoR写入成功后，再写入Cache)。 Write-Behind 回写模式这玩意其实就是Linux文件系统的Page Cache算法！ 不同于 Write-Through 是同步写 SoR 和 Cache，Write-Behind 是异步写。异步之后可以实现批量写、合并写、限时、限流。让 IO 操作奇快无比！ 但是，带来的问题就是数据一致性问题。数据不是强一致的，可能会丢失(非正常关机)。反正Trade-Off吧！ 另外，Write-Back 实现逻辑比较复杂，因为它需要track有哪些数据是被更新了的，需要刷到持久层上。操作系统的write-back机制会在仅当这个Cache需要失效的时候，才会被真正持久化，比如，内存不够了、进程退出了等等，所谓 Lazy Write。 上面，我们没有考虑缓存（Cache）和持久层（Repository）的整体事务的问题。比如，更新Cache成功，更新数据库失败了怎么吗？或是反过来。关于这个事，如果你需要强一致性，你需要使用“两阶段提交协议”——prepare, commit/rollback，比如Java 7 的XAResource，还有MySQL 5.7的 XA Transaction，有些cache也支持XA，比如EhCache。当然，XA这样的强一致性的玩法会导致性能下降，关于分布式的事务的相关话题，你可以看看《分布式系统的事务处理》一文。 参考资料 https://coolshell.cn/articles/17416.html 《亿级流量网站架构核心技术》]]></content>
      <tags>
        <tag>cache, design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo的SPI扩展机制]]></title>
    <url>%2F2018%2F06%2F12%2Fdubbo-spi%2F</url>
    <content type="text"><![CDATA[Dubbo 微内核 + 插件 通常可扩展的实现有下面几种: Factory模式 IoC容器 OSGI容器 Dubbo作为一个框架，不希望强依赖其他的IoC容器，比如Spring，Guice。OSGI也是一个很重的实现，不适合Dubbo。最终Dubbo的实现参考了Java原生的SPI机制，但对其进行了一些扩展，以满足Dubbo的需求。 Dubbo的SPI机制Java SPI有以下的不足: 需要遍历所有的实现，并实例化，然后我们在循环中才能找到我们需要的实现。 配置文件中只是简单的列出了所有的扩展实现，而没有给他们命名。导致在程序中很难去准确的引用它们。 不提供类似于Spring的IOC和AOP功能 扩展很难和其他的框架集成，比如扩展里面依赖了一个Spring bean，原生的Java SPI不支持 Dubbo扩展点机制基本概念扩展点(Extension Point)是一个Java的接口。 扩展(Extension)扩展点的实现类。 扩展实例(Extension Instance)扩展点实现类的实例。 扩展自适应实例(Extension Adaptive Instance)扩展代理类，其实就是一个Extension的代理，它实现了扩展点接口。在调用扩展点的接口方法时，会根据实际的参数来决定要使用哪个扩展。 @SPI@SPI，表明该接口是一个扩展点。可以被Dubbo的ExtentionLoader加载。 @Adaptive@Adaptive 自适应方法。代理会为该方法生成对应的代码。方法内部会根据方法的参数，来决定使用哪个扩展。 ExtentionLoader类似于Java SPI的ServiceLoader，负责扩展的加载和生命周期维护。 扩展别名和Java SPI不同，Dubbo中的扩展都有一个别名，用于在应用中引用它们。比如 12random=com.alibaba.dubbo.rpc.cluster.loadbalance.RandomLoadBalanceroundrobin=com.alibaba.dubbo.rpc.cluster.loadbalance.RoundRobinLoadBalance 其中的random，roundrobin就是对应扩展的别名。这样我们在配置文件中使用random或roundrobin就可以了。 加载路径和Java SPI从/META-INF/services目录加载扩展配置类似，Dubbo也会从以下路径去加载扩展配置文件: META-INF/services/：应用级扩展配置（比如定点项目的扩展）。 META-INF/dubbo/：框架外部扩展配置（比如架构组的扩展）。 META-INF/dubbo/internal/：框架内置扩展配置。 Dubbo的LoadBalance扩展点解读Dubbo中的一个服务，通常有多个Provider，consumer调用服务时，需要在多个Provider中选择一个。这就是一个LoadBalance。我们一起来看看在Dubbo中，LoadBalance是如何成为一个扩展点的。 LoadBalance接口123456@SPI(RandomLoadBalance.NAME)public interface LoadBalance &#123; @Adaptive("loadbalance") &lt;T&gt; Invoker&lt;T&gt; select(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) throws RpcException;&#125; @SPI注解有一个默认参数 random的定义在配置文件META-INF/dubbo/internal/com.alibaba.dubbo.rpc.cluster.LoadBalance中:1234random=com.alibaba.dubbo.rpc.cluster.loadbalance.RandomLoadBalanceroundrobin=com.alibaba.dubbo.rpc.cluster.loadbalance.RoundRobinLoadBalanceleastactive=com.alibaba.dubbo.rpc.cluster.loadbalance.LeastActiveLoadBalanceconsistenthash=com.alibaba.dubbo.rpc.cluster.loadbalance.ConsistentHashLoadBalance 可以看到Dubbo提供了4种负载均衡的实现，我们可以通过xml文件，properties文件，JVM参数显式的指定一个实现。如果没有，默认使用随机。 @Adaptive注解修饰select方法，表明方法select方法是一个可自适应的方法。Dubbo会自动生成该方法对应的代码。 当调用select方法时，会根据具体的方法参数来决定调用哪个扩展实现的select方法。@Adaptive注解的参数loadbalance表示方法参数中的loadbalance的值作为实际要调用的扩展实例。 但奇怪的是，我们发现select的方法中并没有loadbalance参数，那怎么获取loadbalance的值呢？ select方法中还有一个URL类型的参数，Dubbo就是从URL中获取loadbalance的值的。这里涉及到Dubbo的URL总线模式，简单说，URL中包含了RPC调用中的所有参数。URL类中有一个Map&lt;String, String&gt; parameters字段，parameters中就包含了loadbalance。 获取LoadBalance扩展1LoadBalance lb = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(loadbalanceName); 使用ExtensionLoader.getExtensionLoader(LoadBalance.class)方法获取一个ExtensionLoader的实例，然后调用getExtension，传入一个扩展的别名来获取对应的扩展实例。 自定义一个LoadBalance扩展https://github.com/vangoleo/dubbo-spi-demo 1234567package com.dubbo.spi.demo.consumer;public class DemoLoadBalance implements LoadBalance &#123; @Override public &lt;T&gt; Invoker&lt;T&gt; select(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) throws RpcException &#123; System.out.println("DemoLoadBalance: Select the first invoker..."); return invokers.get(0); &#125; 添加文件:META-INF/dubbo/com.alibaba.dubbo.rpc.cluster.LoadBalance。文件内容如下: 1demo=com.dubbo.spi.demo.consumer.DemoLoadBalance 1&lt;dubbo:reference id="helloService" interface="com.dubbo.spi.demo.api.IHelloService" loadbalance="demo" /&gt; 总结 对Dubbo进行扩展，不需要改动Dubbo的源码 自定义的Dubbo的扩展点实现，是一个普通的Java类，Dubbo没有引入任何Dubbo特有的元素，对代码侵入性几乎为零。 将扩展注册到Dubbo中，只需要在ClassPath中添加配置文件。使用简单。而且不会对现有代码造成影响。符合开闭原则。 dubbo的扩展机制设计默认值：@SPI(“dubbo”) 代表默认的spi对象 Dubbo的扩展机制支持IoC,AoP等高级功能 Dubbo的扩展机制能很好的支持第三方IoC容器，默认支持Spring Bean，可自己扩展来支持其他容器，比如Google的Guice。 切换扩展点的实现，只需要在配置文件中修改具体的实现，不需要改代码。使用方便。]]></content>
      <tags>
        <tag>Dubbo, SPI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[principles-of-security-design]]></title>
    <url>%2F2018%2F03%2F15%2Fprinciples-of-security-design%2F</url>
    <content type="text"><![CDATA[本文不涉及web安全方面的东西，只是根据接口设计，讲讲开发一个可靠的服务，需要考虑的几个维度，这些都是老生常谈的东西，每个人都清楚，但是很少有人能够考虑全面（比如前端发起一个删除数据的请求，后端直接调用xxxDao.delete而不做任何验证），这里单独拎出来讲讲，旨在提高意识。 1. 参数校验参数校验的目的是不相信前端传过来的数据，一方面是因为前端js问题导致校验失效，还有前端数据都是可以篡改的。 1.1 格式校验字段大小、长短、范围、格式校验；// todo 整理一份参数校验手册 1.2 特殊业务校验比如起草合同时采购计划不能跨单位、起草期次时标项不能大于10个，严格意义上来说，后端都应该做好校验； 偷懒的底线：一些次要信息（比如名字、地址长度这些可以为空，仅仅作为展示的字段）可以放到前端来做校验，但是对于会影响后续流程的关键性字段（比如金额、评分方式枚举等），后端必须做严格的校验，需要分辨这些关键信息。 2. 权限校验2.1 垂直越权说明：A并没有配置“生成项目”的权限，但是可以通过postman等http工具访问这个接口，导致越权。后果：危害性较大，抛开主动攻击不谈，最常见的危害是，不少用户具有多账号多类别，在双开界面下，如果不同界面的所属机构或者用户类别不同，就会导致session串掉，后台获取的LoginUser就会有问题（detailCategory、operatorId、orgId、orgName等），尤其是用了新的用户API，employee按照类别横向拆分成了多个Operator，用户切换类别导致operatorId不同（而老用户接口employeeId是相同的），使得问题出现频率更高。举例：（1）跨类别：在一个账号下，用户同时具有采购人和代理机构两个类别，然后在一个界面是采购人身份，填了一些项目信息，然后新开了一个界面是代理机构类别，此时在第一个界面点击保存，那么LoginUser就有问题——首先detailCategory是不同的，如果用的是老用户API，用的是loginUser.id，同一个账号下用户类别不同，但是id都是相同的，所以只要不用detailCategory，老用户API下即使用户类别串掉了，也没有影响的，但是在新用户模块下，用户类别不同则operatorId不同，就会产生数据问题。（2）跨机构（跨类别）：采购人生成委托单，然后委托给代理机构审核，不少用户为了操作方便，有采购人和代理机构两个账号，习惯性先用一个账号开一个采购人界面，再用一个账号开代理机构界面，然后在采购人界面操作，此时session已经串掉了，导致获取到的LoginUser的detailCategory、id、operatorId都串掉。 两者本质都是一样的，都是在另一个界面偷偷更换了用户session信息。 后果演示： （1）跨类别：登录binjiangcgjg账号，切换到采监处类别，在第一个界面填好期次信息，然后开另一个窗口，并切换到采购单位类别，回到第一个界面点击保存，检查后端获取的LoginUser;（2）跨机构：登录binjiangcgjg账号，切换到采监处类别，在第一个界面填好期次信息，然后开另一个窗口，登录binjiangcgr账号，回到第一个界面点击保存，检查后端获取的LoginUser; 解决：配置@AuthZcy注解，该注解应该加在方法级（类级别尽量不要加），对于增、删、改、审核等接口，必须配置categorys和privileges属性，对于查询接口，至少需要配置categorys属性，privileges属性需要尽力配置。 2.2 水平越权说明：A和B都有“修改项目”的权限，此时如果A将projectId换成了B拥有的一个项目的ID，由于接口没有做数据权限校验，导致A偷偷越权修改（访问）了B的数据。后果：就用户操作来说，相对来说危害性小一些，出现频率不高，但被恶意攻击，数据安全性危害就很大。解决：（1）明确数据权限粒度：是平台级、区化级、机构级还是用户级； （2）在创建数据时，关键的数据权限信息，不要从前端获取，而要从loginUser里面拿，比如某个项目的创建人、机构、区划信息，直接从LoginUser里拿，前端传的话容易被篡改。 （3）删、改、查、审核等操作时，需要加上数据权限验证（查询接口危害很小，但安全性检测时最常检测的就是查询接口）。 12345678910111213@Transactional@Overridepublic PubfundProjectOpenBidModel queryOpenBidDetail(Long projectId) &#123; validThrow(projectId, "项目id不能为空"); PubfundProject project = validThrow(this.pubfundProjectDao.selectById(projectId), "项目不存在"); PubfundProjectFile projectFile = validThrow(this.pubfundProjectFileDao.getProjectFile(projectId), "招标文件不存在"); // 数据权限校验 LoginUser user = getAndCheckLoginUser(); if (!user.getOperatorId().equals(project.getAgencyOperatorId())) &#123; throw ExcpUtil.genServiceException("无权查看该项目"); &#125; ...&#125; 三、业务校验（上下文越权）说明：上下文越权，主要就是绕过了状态机校验、包括一些业务上的特殊限制。后果：只通过前端校验，后端不校验的情况下，在双开界面下，或者通过http工具发送请求，就会绕开这些限制。后果演示：在一个界面创建期次，然后新开一个界面提交期次，此时回到第一个界面，依然能够保存。解决：提高意识。 四、并发及幂等校验说明：是上下文越权的特例，侧重于并发访问下导致的问题，主要是消息、关键性一次性的节点，平台目前还没有推行一套token防并发的方案，前端的一些控制也是治标不治本，但是不管怎么样后端也是要校验的。解决：提高意识，一些方案，如基于版本号的乐观锁、基于状态的乐观锁、去重表，以及其他一些复杂的方案。 123456789101112131415161718192021int count = 0;if (userInfo.isExpert) &#123; // 状态更新加锁校验（利用数据库事务的原子性，本质上也是基于状态的幂等校验） count = this.pubfundExpertDao.updateStatusNoLock(itemId, // beforeStatusNo BidOpenPageEnum.SCORE_GATHER_PAGE.getExpertStatus().getCode(), // afterStatusNo PubfundExpertContext.ExamineStatus.WAIT_ASSIGN_AMOUNT.getCode(), Lists.newArrayList(user.getOperatorId()));&#125; else &#123; // 状态更新加锁校验（利用数据库事务的原子性，本质上也是基于状态的幂等校验） count = this.pubfundProjectItemDao.updateExamineStatusLock(itemId, // beforeStatusNo PubfundProjectItemContext.BidExamineStatus.WAIT_SCORE_GATHER.getCode(), // afterStatusNo PubfundProjectItemContext.BidExamineStatus.WAIT_ASSIGN_AMOUNT.getCode());&#125;// 幂等校验if (count &gt; 0) &#123; this.amountAssignService.computeSupplierBidLimit(itemId, RE_COMPUTE);&#125; 五、关注事务和日志存在的问题：（1）涉及db更新的接口，不少地方都忘记加事务控制；（2）加了事务控制，也要思考程序在某些关键步骤（尤其是涉及外部调用失败）执行失败该如何回滚，比如本地的db优先执行，外部调用放到代码后面；（3）关键节点和一些比较容易出错的操作，要做好详细的日志，作日志不是简单记录一下，要记录关键信息，便于以后排查问题搜索，根据某个字段能搜出整个流程日志。 六、一份样本1234567891011121314151617181920212223242526272829// 垂直权限校验@AuthZcy(categorys = &#123;Category.PROCUREMENT_AGENCY, EVALUATION_EXPERTS&#125;, privileges = &#123;TREASURY_AGENCY_OPENBID, TREASURY_EXPERT_EXAMINE&#125;)@RequestMapping(value = "/startAssignBidAmount", method = RequestMethod.POST)public Boolean startAssignBidAmount(@RequestParam(value = "itemId") Long itemId) &#123; return this.pubfundBidOpenService.startAssignBidAmount(itemId);&#125; @Transactional // 1.事务控制@Overridepublic Boolean startAssignBidAmount(Long itemId) &#123; validThrow(itemId, "标项id不能为空"); LoginUser user = getAndCheckLoginUser(); PubfundProjectItem item = validThrow(this.pubfundProjectItemDao.selectById(itemId), "标项不存在"); PubfundProject project = validThrow(this.pubfundProjectDao.selectById(item.getProjectId()), "项目不存在"); // 2.数据权限校验 UserInfo userInfo = getAndCheckUser(user, project.getAgencyOperatorId(), itemId); // 3.状态机校验 checkPageAction(userInfo, project, item, BidOpenActionEnum.BID_ASSIGN, true); List&lt;PubfundSupplierBid&gt; suppliers = this.queryBidSuccSuppliers(itemId, project, true, true); validThrow(!CollectionUtils.isEmpty(suppliers), "没有评审通过的供应商，请废标"); // 4.关键节点：基于状态机的幂等校验 int count = this.pubfundProjectItemDao.updateExamineStatus(itemId, project.getId(), PubfundProjectItemContext.BidExamineStatus.BID_FINISH.getCode()); if (count == 0) &#123; throw ExcpUtil.genServiceException("已经分配过存款额"); &#125; // 分配存款额 ...&#125; 七、全文总结 一个可靠的接口，可能有40%以上的校验代码； 前端都是不可靠的，一方面是因为浏览器兼容问题，js校验在某些场景下并不能控住，一方面是接口都有可能被绕过的。 墨菲定律：会出错的事总会出错，担心的坏事更有可能发生 对于增、删、改、审等涉及到db更新的操作，要从上述几个方面去思考，不同场景并不一定要求非要这样做，可以有选择地控制，关键是要有这个意识。 再次强调一下讲的几个方面：参数校验、垂直越权、水平越权、上下文越权、幂等校验、关注事务和日志。]]></content>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GFW与翻墙原理]]></title>
    <url>%2F2017%2F09%2F23%2FGFW-fanqiang%2F</url>
    <content type="text"><![CDATA[DNS污染和劫持DNS劫持是指返回给你一个伪造页面的IP地址，DNS污染是返回给你一个不存在的页面的IP地址。 解决办法： 使用OpenDNS（208.67.222.222）或GoogleDNS（8.8.8.8） 使用一些第三方的DNS服务器 自己用VPS搭建DNS服务器 修改机器host文件，直接IP访问 封锁IP虽然通过上面一些方式，可以绕过DNS污染。但是目前针对IP进行大范围的封锁。 不过目前不可能把所有国外的IP全部封锁掉，所以我们才有机会从国内连接到国外的VPS，进行翻墙。 解决办法： 使用VPS搭建代理 使用IPV6 （IPV6地址巨大，采用封地址不现实，但是目前国内只有部分高校部署了IPV6） 封锁HTTP代理对于没有办法搭建VPS的人来说，最好的办法就是使用HTTP代理。客户端不在直接请求目标服务器，而是请求代理服务器，代理服务器在去请求目标服务器。然后返回结果。 对于HTTP代理来说，封锁起来非常简单。因为HTTP协议是明文，Request Message中就带有要请求的URL或IP地址，这样很容易就被检测到。对于HTTPS来说，虽然通信是进行加密了，但是在建连之前会给代理服务器发送CONNECT方法，这里也会带上要访问的远端服务器地址。如果代理服务器在国外，在出去前就会被检测到。 如果代理服务器在国内，呵呵，你也出不去啊。 对于HTTP代理，因为是明文，所以很容易被服务器了解你的一些数据。所以不要随便使用第三方的HTTP代理访问HTTP网站，而HTTPS虽然不知道你的数据，但是可以知道你去了那里。 解决办法： 使用VPS搭建VPN 使用第三方VPN 封锁VPN虚拟专用网（英语：Virtual Private Network，简称VPN），是一种常用于连接中、大型企业或团体与团体间的私人网络的通讯方法。虚拟私人网络的讯息透过公用的网络架构（例如：互联网）来传送内联网的网络讯息。它利用已加密的通道协议（Tunneling Protocol）来达到保密、发送端认证、消息准确性等私人消息安全效果。 正常网络通信时，所有网络请求都是通过我们的物理网卡直接发送出去。而VPN是客户端使用相应的VPN协议先与VPN服务器进行通信，成功连接后就在操作系统内建立一个虚拟网卡，一般来说默认PC上所有网络通信都从这虚拟网卡上进出，经过VPN服务器中转之后再到达目的地。 通常VPN协议都会对数据流进行强加密处理，从而使得第三方无法知道数据内容，这样就实现了翻墙。翻墙时VPN服务器知道你干的所有事情（HTTP，对于HTTPS，它知道你去了哪）。 VPN有多种协议：OPENVPN、PPTP、L2TP/IPSec、SSLVPN、IKEv2 VPN，Cisco VPN等。其中的PPTP和L2TP是明文传输协议。只负责传输，不负责加密。分别利用了MPPE和IPSec进行加密。 OpenVPN 速度快，并且安全可信。但劣势是缺乏对移动设备的支持，另外还需要安装第三方客户端。 对于VPN和其他一些加密的传输的协议来说，没有办法直接获取明文的请求信息，所以没有办法直接封锁，而是使用了监控分析的方式： 暴力破解对于一些使用弱加密方式的协议来说，直接使用暴力破解检查传输内容。比如PPTP使用MPPE加密，但是MPPE是基于RC4，对于强大的防火墙背后的超级计算机集群，破解就是几秒钟的事情。 破解后明文中一旦包含了违禁内容，请求就会被封。而对应的IP可能会进入重点关怀列表。 特征检测要想成功翻墙都必须与对应的远程服务器建立连接，然后再用对应的协议进行数据处理并传输。而问题就出在这里：翻墙工具和远程服务器建立连接时，如果表现的很独特，在一大堆流量里很显眼，就会轻易被GFW识别出从而直接阻断连接，而VPN（尤其是OPENVPN）和SSH这方面的问题尤其严重。 流量监控当一个VPN地址被大量人请求，并保持长时间连接时，就很容易引起关注。SSH接口有大量数据请求。一般会结合其他特征。 深度包检测深度数据包检测（Deep packet inspection，缩写为 DPI），又称完全数据包探测（complete packet inspection）或信息萃取（Information eXtraction，IX），是一种电脑网络数据包过滤技术，用来检查通过检测点之数据包的数据部分（亦可能包含其标头），以搜索不匹配规范之协议、病毒、垃圾邮件、入侵，或以预定之准则来决定数据包是否可通过或需被路由至其他不同目的地，亦或是为了收集统计数据之目的。 比如我们用HTTPS来访问一个网站，TLS/SSL协议在建连过程如下： 很明显的会发送“client hello”和“server hello” 这种特诊很明显的信息。（当然不会根据这个就封掉，否则https没法用了）。而后续会有服务端证书发送，验证，客户端密钥协商等过程。有明显的协议特征。 Socks代理/SSH SocksSOCKS是一种网络传输协议，主要用于客户端与外网服务器之间通讯的中间传递。SOCKS是”SOCKetS”的缩写[1]。 当防火墙后的客户端要访问外部的服务器时，就跟SOCKS代理服务器连接。这个代理服务器控制客户端访问外网的资格，允许的话，就将客户端的请求发往外部的服务器。 根据OSI模型，SOCKS是会话层的协议，位于表示层与传输层之间 与HTTP代理的对比SOCKS工作在比HTTP代理更低的层次：SOCKS使用握手协议来通知代理软件其客户端试图进行的连接SOCKS，然后尽可能透明地进行操作，而常规代理可能会解释和重写报头（例如，使用另一种底层协议，例如FTP；然而，HTTP代理只是将HTTP请求转发到所需的HTTP服务器）。虽然HTTP代理有不同的使用模式，CONNECT方法允许转发TCP连接；然而，SOCKS代理还可以转发UDP流量和反向代理，而HTTP代理不能。HTTP代理通常更了解HTTP协议，执行更高层次的过滤（虽然通常只用于GET和POST方法，而不用于CONNECT方法） Socks代理本身协议是明文传输，虽然相对HTTP有一些优势，但是明文也导致Socks代理很容易被封。所以可以考虑对Socks进行加密。所以出现了SSH Socks，对于MAC和Linux来说，不需要Client就可以进行访问。详细可以看：SSH隧道技术简介：端口转发&amp;SOCKS代理 但是有些地区好像会对一些VPS的SSH进行端口干扰。而且SSH一般是小流量数据，如果数据量特别大，也会被认为是翻墙，进入特别关怀列表。 Shadowsocks认准官网：https://shadowsocks.org/en/index.html Shadowsocks 目前不容易被封杀主要是因为： 建立在socks5协议之上，socks5是运用很广泛的协议，所以没办法直接封杀socks5协议 使用socks5协议建立连接，而没有使用VPN中的服务端身份验证和密钥协商过程。而是在服务端和客户端直接写死密钥和加密算法。所以防火墙很难找到明显的特征，因为这就是个普通的socks5协议。 Shadowsock搭建也比较简单，所以很多人自己架设VPS搭建，个人使用流量也很小，没法通过流量监控方式封杀。 自定义加密方式和密钥。因为加密主要主要是防止被检测，所以要选择安全系数高的加密方式。之前RC4会很容易被破解，而导致被封杀。所以现在推荐使用AES加密。而在客户端和服务端自定义密钥，泄露的风险相对较小。 Shadowsocks-rss前面认为Shadowssocks特征并不是很明细，但是了解协议工作原理后会发现，SS协议本身还有有漏洞，可以被利用来检测特征，具体讨论看：ShadowSocks协议的弱点分析和改进。 我总结了下大致意思是： 协议过于简单，并且格式固定，很容易被发起中间人攻击。先看看协议结构 Address Type Destination Address Destination Port Data 1 Variable 2 Variable Possible values of address type are 1 (IPv4), 4 (IPv6), 3 (hostname). For IPv4 address, it’s packed as a 32-bit (4-byte) big-endian integer. For IPv6 address, a compact representation (16-byte array) is used. For hostname, the first byte of destination address indicates the length, which limits the length of hostname to 255. The destination port is also a big-endian integer. The request is encrypted using the specified cipher with a random IV and the pre-shared key, it then becomes so-called payload. 结构很简单，上面解释也很清楚。Client每一个请求都是这种格式，然后进行加密。Server端解密然后解析。看起来没什么问题，没有密钥你无法模拟中间人攻击，也没什么明显特征。但是看看Server处理逻辑会发现存在一些问题： Client数据在加密目前用的最多的是AES系列，加密后在协议数据前会有16位的IV。而Server段解析后，首先判断请求是否有效，而这个判断很简单： 判断的依据就是Address Type的那个字节，看它是不是在那三个可能取值，如果不是，立即断开连接，如果是，就尝试解析后面的地址和端口进行连接。 如果能发起中间人攻击，模拟Client请求，这个就是一个很明显的特征，如果把Address Type穷举各种情况，其中只有3种情况会连接成功。那么很可能就是一个Shadowsocks 服务器。 所以只需要先劫持一条socks5的请求，因为AES加密后Address Type位置是固定的（第17位），篡改这一位，穷举256种情况（AES-256），然后发送给服务器。如果服务器在3种情况没有关闭连接，就说明这个很可能是Shadowsock服务。你这个IP很快就进入关怀列表了。 这里的关键就是AES加密明文和密文对应关系。 1234567891011121314151617举个例子，现在有一个协议包，共7个字节0x01, 0x08, 0x08, 0x08, 0x08, 0x00, 0x50对照socks5协议，很明显这是一个IPv4包(第一个字节是0x01)，目的地是8.8.8.8的80端口被shadowsocks加密了以后（密码abc，加密方式aes-256-cfb），数据包就变成了这样0xbb, 0x59, 0x1c, 0x4a, 0xb9, 0x0a, 0x91, 0xdc, 0x07, 0xef, 0x72, 0x05, 0x90, 0x42, 0xca, 0x0d, 0x4c, 0x3b, 0x87, 0x8e, 0xca, 0xab, 0x32前16个字节，从0xbb到0x0d，都是iv，根据issue中提到的弱点和之前的总结，只需要修改0x4c，即真正密文中的第一个字节，就可要起到修改明文中的第一个字节的效果。那就把0x4c修改成0x4d吧，解密以后的结果是0x00, 0x08, 0x08, 0x08, 0x08, 0x00, 0x50的确只有第一个字节被改掉了，根据breakwa11的理论，不难推出其他情况，其中合法的是0x4e =&gt; 0x03 (Domain Name)0x49 =&gt; 0x04 (IPv6) 所以目前Shadowsocks应该是比较容易被检测出来。但是为什么没有被封掉，呵呵，就不知道了。所以这个项目目的就是在SS基础上进行一些混淆。因为原有实现确实有漏洞。 不过目前这个项目好像也停止更新了。并且木有开源。 当然如果是自己用完全可以自己修改一个私有协议，这样就没法被检测到了。但是需要同时修改Server段，MAC Client，Windows Client， Android Client。 – -！ GoAgent和GoProxyGoogle App Engine是一个开发、托管网络应用程序的平台，使用Google管理的数据中心 GoAgent的运行原理与其他代理工具基本相同，使用特定的中转服务器完成数据传输。它使用Google App Engine的服务器作为中传，将数据包后发送至Google服务器，再由Google服务器转发至目的服务器，接收数据时方法也类似。由于服务器端软件基本相同，该中转服务器既可以是用户自行架设的服务器，也可以是由其他人架设的开放服务器。 GoAgent其实也是利用GAE作为代理，但是因为他是连接到google的服务器，因为在国内现在google大量被封，所以GoAgent也基本很难使用。目前github上源码也已经删除。 但是GoAgent本身不依赖于GAE，而且使用Python编写，完全可以部署到VPS上进行代理。GoProxy是GoAgent的后续项目https://github.com/phuslu/goproxy还有一个XX-NET：https://github.com/XX-net/XX-Net 有兴趣都可以去了解下。 TorTor（The Onion Router，洋葱路由器）是实现匿名通信的自由软件。Tor是第二代洋葱路由的一种实现，用户通过Tor可以在因特网上进行匿名交流。 The Tor network is a group of volunteer-operated servers that allows people to improve their privacy and security on the Internet. Tor’s users employ this network by connecting through a series of virtual tunnels rather than making a direct connection, thus allowing both organizations and individuals to share information over public networks without compromising their privacy. Along the same line, Tor is an effective censorship circumvention tool, allowing its users to reach otherwise blocked destinations or content. Tor can also be used as a building block for software developers to create new communication tools with built-in privacy features. 简单说和其他翻墙方式不同，简单可以理解为Tor有一群代理服务器，然后要访问远端站点，是通过随机的代理路径来完成的，数据经历了多个代理服务器的传递。它主要作用是隐藏访问者信息，而翻墙只是顺带的功能。 要访问远程站点，Client需要知道Tor nodes，这些nodes就是普通加入的用户，就好像P2P下载一样。获取nodes信息后，会随机选择一条路径访问。 因为这个原因，Tor的速度可能不会很好。 而关于Tor的漏洞和检测看这里：Tor真的十分安全么 其原理以及漏洞详解 目前有结合Tor+Shadowsocks前置代理使用的。 ReferenceVPN翻墙，不安全的加密，不要相信墙内公司GFW的工作原理（1） ————GFW是如何识别并封锁翻墙工具的关于翻墙和匿名与网络安全类科普文大集合为什么不应该用 SSL 翻墙科学上网的一些原理]]></content>
      <tags>
        <tag>GFW, VPN, 翻墙</tag>
      </tags>
  </entry>
</search>
