<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[MySQL-Explain]]></title>
    <url>%2F2019%2F09%2F14%2FMySQL-Explain%2F</url>
    <content type="text"><![CDATA[The ref column shows which columns or constants are compared to the index named in the key column to select rows from the table. The type column of EXPLAIN output describes how tables are joined. The following list describes the join types, ordered from the best type to the worst: system The table has only one row (= system table). This is a special case of the const join type. const The table has at most one matching row, which is read at the start of the query. Because there is only one row, values from the column in this row can be regarded as constants by the rest of the optimizer. const tables are very fast because they are read only once. const is used when you compare all parts of a PRIMARY KEY or UNIQUE index to constant values. In the following queries, tbl_name can be used as a const table: 1234SELECT * FROM tbl_name WHERE primary_key=1;SELECT * FROM tbl_name WHERE primary_key_part1=1 AND primary_key_part2=2; eq_ref One row is read from this table for each combination of rows from the previous tables. Other than the system and const types, this is the best possible join type. It is used when all parts of an index are used by the join and the index is a PRIMARY KEY or UNIQUE NOT NULL index. eq_ref can be used for indexed columns that are compared using the = operator. The comparison value can be a constant or an expression that uses columns from tables that are read before this table. In the following examples, MySQL can use an eq_ref join to process ref_table: 123456SELECT * FROM ref_table,other_table WHERE ref_table.key_column=other_table.column;SELECT * FROM ref_table,other_table WHERE ref_table.key_column_part1=other_table.column AND ref_table.key_column_part2=1; ref All rows with matching index values are read from this table for each combination of rows from the previous tables. ref is used if the join uses only a leftmost prefix of the key or if the key is not a PRIMARY KEY or UNIQUE index (in other words, if the join cannot select a single row based on the key value). If the key that is used matches only a few rows, this is a good join type. ref can be used for indexed columns that are compared using the = or &lt;=&gt; operator. In the following examples, MySQL can use a ref join to process ref_table: 12345678SELECT * FROM ref_table WHERE key_column=expr;SELECT * FROM ref_table,other_table WHERE ref_table.key_column=other_table.column;SELECT * FROM ref_table,other_table WHERE ref_table.key_column_part1=other_table.column AND ref_table.key_column_part2=1; fulltext The join is performed using a FULLTEXT index. range Only rows that are in a given range are retrieved, using an index to select the rows. The key column in the output row indicates which index is used. The key_len contains the longest key part that was used. The ref column is NULL for this type. range can be used when a key column is compared to a constant using any of the =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, LIKE, or IN() operators: 1234567891011SELECT * FROM tbl_name WHERE key_column = 10;SELECT * FROM tbl_name WHERE key_column BETWEEN 10 and 20;SELECT * FROM tbl_name WHERE key_column IN (10,20,30);SELECT * FROM tbl_name WHERE key_part1 = 10 AND key_part2 IN (10,20,30); index The index join type is the same as ALL, except that the index tree is scanned. This occurs two ways: If the index is a covering index for the queries and can be used to satisfy all data required from the table, only the index tree is scanned. In this case, the Extra column says Using index. An index-only scan usually is faster than ALL because the size of the index usually is smaller than the table data. A full table scan is performed using reads from the index to look up data rows in index order. Uses index does not appear in the Extra column. MySQL can use this join type when the query uses only columns that are part of a single index. ALL A full table scan is done for each combination of rows from the previous tables. This is normally not good if the table is the first table not marked const, and usually very bad in all other cases. Normally, you can avoid ALL by adding indexes that enable row retrieval from the table based on constant values or column values from earlier tables. EXPLAIN Extra InformationThe Extra column of EXPLAIN output contains additional information about how MySQL resolves the query. The following list explains the values that can appear in this column. Each item also indicates for JSON-formatted output which property displays the Extra value. For some of these, there is a specific property. The others display as the text of the message property. const row not found For a query such as SELECT … FROM tbl_name, the table was empty. Distinct MySQL is looking for distinct values, so it stops searching for more rows for the current row combination after it has found the first matching row. Impossible HAVING The HAVING clause is always false and cannot select any rows. Impossible WHERE The WHERE clause is always false and cannot select any rows. Impossible WHERE noticed after reading const tables MySQL has read all const (and system) tables and notice that the WHERE clause is always false. no matching row in const table For a query with a join, there was an empty table or a table with no rows satisfying a unique index condition. Not exists MySQL was able to do a LEFT JOIN optimization on the query and does not examine more rows in this table for the previous row combination after it finds one row that matches the LEFT JOIN criteria. Here is an example of the type of query that can be optimized this way: 12SELECT * FROM t1 LEFT JOIN t2 ON t1.id=t2.id WHERE t2.id IS NULL; Assume that t2.id is defined as NOT NULL. In this case, MySQL scans t1 and looks up the rows in t2 using the values of t1.id. If MySQL finds a matching row in t2, it knows that t2.id can never be NULL, and does not scan through the rest of the rows in t2 that have the same id value. In other words, for each row in t1, MySQL needs to do only a single lookup in t2, regardless of how many rows actually match in t2. Using filesort MySQL must do an extra pass to find out how to retrieve the rows in sorted order. The sort is done by going through all rows according to the join type and storing the sort key and pointer to the row for all rows that match the WHERE clause. The keys then are sorted and the rows are retrieved in sorted order. Using index The column information is retrieved from the table using only information in the index tree without having to do an additional seek to read the actual row. This strategy can be used when the query uses only columns that are part of a single index. For InnoDB tables that have a user-defined clustered index, that index can be used even when Using index is absent from the Extra column. This is the case if type is index and key is PRIMARY. Using index condition Tables are read by accessing index tuples and testing them first to determine whether to read full table rows. In this way, index information is used to defer (“push down”) reading full table rows unless it is necessary. Using join buffer (Block Nested Loop), Using join buffer Tables from earlier joins are read in portions into the join buffer, and then their rows are used from the buffer to perform the join with the current table. (Block Nested Loop) indicates use of the Block Nested-Loop algorithm and (Batched Key Access) indicates use of the Batched Key Access algorithm. That is, the keys from the table on the preceding line of the EXPLAIN output will be buffered, and the matching rows will be fetched in batches from the table represented by the line in which Using join buffer appears. Using MRR Tables are read using the Multi-Range Read optimization strategy. Using temporary To resolve the query, MySQL needs to create a temporary table to hold the result. This typically happens if the query contains GROUP BY and ORDER BY clauses that list columns differently. Using where A WHERE clause is used to restrict which rows to match against the next table or send to the client. Unless you specifically intend to fetch or examine all rows from the table, you may have something wrong in your query if the Extra value is not Using where and the table join type is ALL or index. Using where with pushed condition id: SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符. select_type: SELECT 查询的类型. table: 查询的是哪个表 partitions: 匹配的分区 type: join 类型 possible_keys: 此次查询中可能选用的索引 key: 此次查询中确切使用到的索引. ref: 哪个字段或常数与 key 一起被使用 rows: 显示此查询一共扫描了多少行. 这个是一个估计值. filtered: 表示此查询条件所过滤的数据的百分比 extra: 额外的信息 SIMPLE, 表示此查询不包含 UNION 查询或子查询 PRIMARY, 表示此查询是最外层的查询 UNION, 表示此查询是 UNION 的第二或随后的查询 DEPENDENT UNION, UNION 中的第二个或后面的查询语句, 取决于外面的查询 UNION RESULT, UNION 的结果 SUBQUERY, 子查询中的第一个 SELECT DEPENDENT SUBQUERY: 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果. system: 表中只有一条数据. 这个类型是特殊的 const 类型. const: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可. eq_ref: 此类型通常出现在多表的 join 查询, 表示对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询的比较操作通常是 =, 查询效率较高. ref: 此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了 最左前缀 规则索引的查询. range: 表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN() 操作中. index: 表示全索引扫描(full index scan), 和 ALL 类型类似, 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据.index 类型通常出现在: 所要查询的数据直接在索引树中就可以获取到, 而不需要扫描数据. 当是这种情况时, Extra 字段 会显示 Using index. ALL: 表示全表扫描, 这个类型的查询是性能最差的查询之一. 通常来说, 我们的查询不应该出现 ALL 类型的查询, 因为这样的查询在数据量大的情况下, 对数据库的性能是巨大的灾难. 如一个查询是 ALL 类型查询, 那么一般来说可以对相应的字段添加索引来避免. 1ALL &lt; index &lt; range ~ index_merge &lt; ref &lt; eq_ref &lt; const &lt; system Using filesort 当 Extra 中有 Using filesort 时, 表示 MySQL 需额外的排序操作, 不能通过索引顺序达到排序效果. 一般有 Using filesort, 都建议优化去掉, 因为这样的查询 CPU 资源消耗大. Using index“覆盖索引扫描”, 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 往往说明性能不错 Using temporary查询有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 查询效率不高, 建议优化.]]></content>
  </entry>
  <entry>
    <title><![CDATA[分布式锁总结]]></title>
    <url>%2F2019%2F07%2F14%2Fdistributed-lock%2F</url>
    <content type="text"><![CDATA[zookeeper可靠性比redis强太多，只是效率低了点，如果并发量不是特别大，追求可靠性，首选zookeeper。为了效率，则首选redis实现。 使用场景 不同的业务服务器，不同的进程 需要怎样的锁 可重入锁（可以多次加锁）可避免死锁（Thread+引用计数，避免了频繁的加锁解锁，又避免了死锁）同一个class中的synchronized方法可互相调用而不会发生死锁 ReentrantLock和synchronized都是可重入锁（前提是同一个对象） 不可重入锁（自旋锁） 阻塞锁（根据业务需要）可以让线程进入阻塞状态等待唤醒，而不是快速失败返回 公平锁（根据业务需要）加锁时是否根据优先级排队 失效时间（没有失效时间的锁一旦解锁失败，线程们就再也无法获取到锁了） 我加的锁只能由我来释放，或者锁超时自动释放（这时我的业务处理也要停下来） Redlock算法set(key, value, nx=True, ex=xxx) 背景：简单的sentinel集群中，如果master挂了，slave来不及同步数据（主从异步复制）就被选为新的master，那么如果有请求过来申请锁就会直接批准了，那么可以就同一把锁被两个客户端同时持有了 获取当前时间（单位是毫秒）。 轮流用相同的key和随机值在N个节点上请求锁，在这一步里，客户端在每个master上请求锁时，会有一个和总的锁释放时间相比小的多的超时时间。比如如果锁自动释放时间是10秒钟，那每个节点锁请求的超时时间可能是5-50毫秒的范围，这个可以防止一个客户端在某个宕掉的master节点上阻塞过长时间，如果一个master节点不可用了，我们应该尽快尝试下一个master节点。 客户端计算第二步中获取锁所花的时间，只有当客户端在大多数master节点上成功获取了锁（在这里是3个），而且总共消耗的时间不超过锁释放时间，这个锁就认为是获取成功了。 如果锁获取成功了，那现在锁自动释放时间就是最初的锁释放时间减去之前获取锁所消耗的时间。 如果锁获取失败了，不管是因为获取成功的锁不超过一半（N/2+1)还是因为总消耗时间超过了锁释放时间，客户端都会到每个master节点上释放锁，即便是那些他认为没有获取成功的锁。 N个独立的节点，加锁时至少要获取到超过一半的锁时才能算是加锁成功，获取锁超时时间&lt;&lt;锁自动释放时间，锁持有时间（业务执行时间）=锁自动释放时间-获取锁超时时间，redlock在业务方获取到锁时会返回客户端能够占用的时间，业务若是执行超时，需要在锁块过期时进行续租 redis的官方分布式锁redisson就是用的续租的方法 基于redis的分布式锁一直没有解决的问题：如果业务处理超时了，锁自动释放的问题 节点崩溃重启，会出现多个客户端持有锁假设一共有5个Redis节点：A, B, C, D, E。设想发生了如下的事件序列：(1)客户端1成功锁住了A, B, C，获取锁成功（但D和E没有锁住）。(2)节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了。(3)节点C重启后，客户端2锁住了C, D, E，获取锁成功。这样，客户端1和客户端2同时获得了锁（针对同一资源）。 延迟重启等待的时间大于锁的有效时间。采用这种方式，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。 时间跳跃问题(1)假设一共有5个Redis节点：A, B, C, D, E。设想发生了如下的事件序列：(2)客户端1从Redis节点A, B, C成功获取了锁（多数节点）。由于网络问题，与D和E通信失败。(3)节点C上的时钟发生了向前跳跃，导致它上面维护的锁快速过期。客户端2从Redis节点C, D, E成功获取了同一个资源的锁（多数节点）。客户端1和客户端2现在都认为自己持有了锁。 超时导致锁失效问题RedLock算法并没有解决，操作共享资源超时，导致锁失效的问题。 基于Zookeeper实现分布式锁 临时有序节点 在节点上绑定监听器，一旦节点有变化，ZK会通知客户端，客户端检查自己创建的节点是不是所有节点序号中最小的 可重入：客户端在创建节点时把当前IP和ThreadId写到节点中，下次要获取锁的时候直接判断是不是一样 公平锁：ZK的临时节点有序，每次锁被释放时，ZK可以通知最小节点来获取锁，保证了公平 过期时间：如果创建/lock节点的客户端挂了，那么相应的node会被自动删除 ZK弱一致性（每次同步写刚好超过一半的节点） 性能不高：每次都需要动态创建、删除临时节点，而且只能通过leader服务器 参考： https://www.cnblogs.com/rjzheng/p/9310976.html https://redis.io/topics/distlock]]></content>
      <tags>
        <tag>distributed, lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot2-upgrade]]></title>
    <url>%2F2019%2F07%2F13%2Fspringboot2-upgrade%2F</url>
    <content type="text"><![CDATA[SpringBoot2 解决了 ”too many open fd“问题 性能更好：默认 HikariCP 连接池 支持 Spring5 （支持WebFlux） 更强大的Actuator监控组件，SpringBoot2采用micrometer做Metrics统计，性能更强，统计指标项更合理，且支持无缝对接Promethus监控 属性配置方面也更加强大了 SpringBoot2.0新特性：WebMvcConfigurer SpringBoot2 升级的坑 一大堆 Maven 依赖冲突需要解决，有些依赖还不好解决，记得有一个 Velocity 渲染的组件，在 SpringBoot2 中直接被移除了，添加依赖还会冲突，最后没办法上网查了半天解决方案才解决 序列化问题：主要是Date类型，原版本序列化话为long型时间戳，薪版本将会序列化为一个utc时间字符串。为了保持接口兼容、以及对其他解析程序的便捷，我们简单修改一下配置即可：spring.jackson.time-zone=GMT+08:00spring.jackson.serialization.write-dates-as-timestamps=true 数据源 默认 HikariCP 连接池 访问报错，HikariPool-1 - jdbcUrl is required with driverClassName 当然既然是使用了读写分离的数据库，光做这些是不够的，需要进行手动配置 12345678@Bean// 设置为首选的数据源@Primary// 读取配置@ConfigurationProperties(prefix="spring.datasource.readwrite")public DataSource dataSource() &#123; return DataSourceBuilder.create().build();&#125; 底层 tomcat 安全机制变更，导致有个别的get请求无法访问，最终通过安全放行策略解决 Redis - Jedis –&gt; lettuce Lettuce 是 一种可伸缩，线程安全，完全非阻塞的Redis客户端，多个线程可以共享一个RedisConnection,它利用Netty NIO 框架来高效地管理多个连接，从而提供了异步和同步数据访问方式，用于构建非阻塞的反应性应用程序 支持micrometer metrics，对接Promethus补全监控能力 SpringBoot2适配pageHelper Spring 官方迁移文档 最佳实践注解 or XML？spring boot官方是主张完全用注解替代XML的。那么实际生产环境下，我们该用注解还是该用XML，哪里用注解，哪里用XML？ 遇到依赖注入的类时，被依赖的对象应该使用XML配置。这样，当需要修改实现类的时候，能够不修改代码、不重新打包完成更换。 对于生产环境，一般来说很少直接线上切换不同的实现类，换也是线下随着某一个版本的发布，完成替换。]]></content>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高强度学习]]></title>
    <url>%2F2019%2F07%2F11%2Fintensive-learning%2F</url>
    <content type="text"><![CDATA[1. 强大的学习动力2. 不要太计较学习效率该快的时候，就要拼命地快；不该快的时候，就慢慢地“滋养”知识 3. 严格作息4. 犯困了，就睡觉；不犯困，就坚持学习5. 高强运动和“润泽”你运动强度越大、而休息得越好，那么，你的身体越好，你的“狠劲”、“自信心”越强。 最好的休息，是让你重燃生活的热情 我们的疲惫主要来自对现有的一成不变的生活的厌倦。 但可惜，我们缺乏对“休息”的想象力。我们能想出来的休息方法不是痴睡就是傻玩。 基本思路是以“做”来解决“累”，用积极休息取代消极放纵 旅行，而不是换个地方消遣。去一个地方对那个地方本身心存好奇，对自己这趟行程心存美意，感受自己经验范围以外的人生样貌。而不是坐了5小时飞机，只是换个地方打麻将，换个地方游泳，换个地方打球…… 从这个周末起学习一项新的技艺，比如弹电子琴，打鼓……每周末练习1小时以上。 去社交。不要以为它总是令人疲惫的。虽然和看书比起来，它稍有点令人紧张，但也能让你更兴奋，更有认同感。你必须每周有两三天是和工作圈子和亲戚外的人 打交道。它让你在朝九晚五的机械运行中不至失去活泼的天性。女性朋友们尤为需要走出去和朋友聚会，这些时刻你不再是满脸写着“效率”的中性人，而是一个裙裾飞扬的魅力焦点。 做点困难的事，如果你是精神超级紧张的人。心理学家发现解除神经紧张的方法，是去处理需要神经紧张才能解决的问题。 如去一个复杂的机械工厂从学徒干起，或者做一道超级复杂的数学题。 番茄工作法切换任务，交替地学习或者工作午睡适当体育锻炼保证晚上睡眠质量]]></content>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hystrix与Sentinel]]></title>
    <url>%2F2019%2F06%2F14%2FHystrix-Sentinel%2F</url>
    <content type="text"><![CDATA[当某些资源一直出现故障时，将触发断路器。断路器不会继续访问已经发生故障的资源，而是拦截请求并返回故障信号。这听起来类似于断路器模式。但是，Sentinel提供了更多选择，例如流量整形，过载保护和容错。 Sentinel提供了许多处理流量控制的选项。用户可以选择根据QPS，线程池编号，系统负载来调整流量，以及直接使用命令来停止流量或执行冷启动。用户还可以混合和匹配不同的规则。Hystrix并没有真正提供全面的流量整形。 Sentinel提供故障隔离和断路。这与Hystrix类似。但是，他们的方法不同。 Sentinal提供实时监控。它还提供了一个仪表板，用于聚合来自分布式系统的信息。 Sentinel与Hystrix有何不同？两者之间的关键区别在于如何实现隔离。Hystrix通常使用bulkhead 模式来隔离依赖关系。它将每个依赖项放在一个单独的线程池中。这样做的主要好处是它提供了干净的切割。缺点主要包括计算开销和线程池管理。 Sentinel为每个依赖项使用计数器。通过这样做，它不仅可以节省管理线程池的开销，还可以为用户提供更多控制。用户现在可以决定流的退化的粒度。 Hystrix 的关注点在于以 隔离 和 熔断 为主的容错机制，超时或被熔断的调用将会快速失败，并可以提供 fallback 机制。 而 Sentinel 的侧重点在于： 多样化的流量控制 熔断降级 系统负载保护 实时监控和控制台 共同特性资源模型和执行模型上的对比Hystrix 的资源模型设计上采用了命令模式，将对外部资源的调用和 fallback 逻辑封装成一个命令对象（HystrixCommand / HystrixObservableCommand），其底层的执行是基于 RxJava 实现的。每个 Command 创建时都要指定 commandKey 和 groupKey（用于区分资源）以及对应的隔离策略（线程池隔离 or 信号量隔离）。线程池隔离模式下需要配置线程池对应的参数（线程池名称、容量、排队超时等），然后 Command 就会在指定的线程池按照指定的容错策略执行；信号量隔离模式下需要配置最大并发数，执行 Command 时 Hystrix 就会限制其并发调用。 Sentinel 的设计则更为简单。相比 Hystrix Command 强依赖隔离规则，Sentinel 的资源定义与规则配置的耦合度更低。Hystrix 的 Command 强依赖于隔离规则配置的原因是隔离规则会直接影响 Command 的执行。在执行的时候 Hystrix 会解析 Command 的隔离规则来创建 RxJava Scheduler 并在其上调度执行，若是线程池模式则 Scheduler 底层的线程池为配置的线程池，若是信号量模式则简单包装成当前线程执行的 Scheduler。而 Sentinel 并不指定执行模型，也不关注应用是如何执行的。Sentinel 的原则非常简单：根据对应资源配置的规则来为资源执行相应的限流/降级/负载保护策略。在 Sentinel 中资源定义和规则配置是分离的。用户先通过 Sentinel API 给对应的业务逻辑定义资源（埋点），然后可以在需要的时候配置规则。埋点方式有两种： try-catch 方式（通过 SphU.entry(…)），用户在 catch 块中执行异常处理 / fallback if-else 方式（通过 SphO.entry(…)），当返回 false 时执行异常处理 / fallback 从 0.1.1 版本开始，Sentinel 还支持基于注解的资源定义方式，可以通过注解参数指定异常处理函数和 fallback 函数。 从 0.2.0 版本开始，Sentinel 引入异步调用链路支持，可以方便地统计异步调用资源的数据，维护异步调用链路，同时具备了适配异步框架/库的能力。 Sentinel 提供多样化的规则配置方式。除了直接通过 loadRules API 将规则注册到内存态之外，用户还可以注册各种外部数据源来提供动态的规则。用户可以根据系统当前的实时情况去动态地变更规则配置，数据源会将变更推送至 Sentinel 并即时生效。 隔离设计上的对比隔离是 Hystrix 的核心功能之一。Hystrix 提供两种隔离策略：线程池隔离（Bulkhead Pattern）和信号量隔离，其中最推荐也是最常用的是线程池隔离。Hystrix 的线程池隔离针对不同的资源分别创建不同的线程池，不同服务调用都发生在不同的线程池中，在线程池排队、超时等阻塞情况时可以快速失败，并可以提供 fallback 机制。线程池隔离的好处是隔离度比较高，可以针对某个资源的线程池去进行处理而不影响其它资源，但是代价就是线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响。 但是，实际情况下，线程池隔离并没有带来非常多的好处。首先就是过多的线程池会非常影响性能。考虑这样一个场景，在 Tomcat 之类的 Servlet 容器使用 Hystrix，本身 Tomcat 自身的线程数目就非常多了（可能到几十或一百多），如果加上 Hystrix 为各个资源创建的线程池，总共线程数目会非常多（几百个线程），这样上下文切换会有非常大的损耗。另外，线程池模式比较彻底的隔离性使得 Hystrix 可以针对不同资源线程池的排队、超时情况分别进行处理，但这其实是超时熔断和流量控制要解决的问题，如果组件具备了超时熔断和流量控制的能力，线程池隔离就显得没有那么必要了。 Hystrix 的信号量隔离限制对某个资源调用的并发数。这样的隔离非常轻量级，仅限制对某个资源调用的并发数，而不是显式地去创建线程池，所以 overhead 比较小，但是效果不错，也支持超时失败。Sentinel 可以通过并发线程数模式的流量控制来提供信号量隔离的功能。并且结合基于响应时间的熔断降级模式，可以在不稳定资源的平均响应时间比较高的时候自动降级，防止过多的慢调用占满并发数，影响整个系统。 熔断降级对比Sentinel 和 Hystrix 的熔断降级功能本质上都是基于熔断器模式（Circuit Breaker Pattern）。Sentinel 与 Hystrix 都支持基于失败比率（异常比率）的熔断降级，在调用达到一定量级并且失败比率达到设定的阈值时自动进行熔断，此时所有对该资源的调用都会被 block，直到过了指定的时间窗口后才启发性地恢复。上面提到过，Sentinel 还支持基于平均响应时间的熔断降级，可以在服务响应时间持续飙高的时候自动熔断，拒绝掉更多的请求，直到一段时间后才恢复。这样可以防止调用非常慢造成级联阻塞的情况。 实时指标统计实现对比Hystrix 和 Sentinel 的实时指标数据统计实现都是基于滑动窗口的。Hystrix 1.5 之前的版本是通过环形数组实现的滑动窗口，通过锁配合 CAS 的操作对每个桶的统计信息进行更新。Hystrix 1.5 开始对实时指标统计的实现进行了重构，将指标统计数据结构抽象成了响应式流（reactive stream）的形式，方便消费者去利用指标信息。同时底层改造成了基于 RxJava 的事件驱动模式，在服务调用成功/失败/超时的时候发布相应的事件，通过一系列的变换和聚合最终得到实时的指标统计数据流，可以被熔断器或 Dashboard 消费。 Sentinel 目前抽象出了 Metric 指标统计接口，底层可以有不同的实现，目前默认的实现是基于 LeapArray 的高性能滑动窗口，后续根据需要可能会引入 reactive stream 等实现。 Sentinel 的特色除了之前提到的两者的共同特性之外，Sentinel 还提供以下的特色功能： 轻量级、高性能Sentinel 作为一个功能完备的高可用流量管控组件，其核心 sentinel-core 没有任何多余依赖，打包后只有不到 200 KB，非常轻量级。开发者可以放心地引入 sentinel-core 而不需担心依赖问题。同时，Sentinel 提供了多种扩展点，用户可以很方便地根据需求去进行扩展，并且无缝地切合到 Sentinel 中。 引入 Sentinel 带来的性能损耗非常小。只有在业务单机量级超过 25W QPS 的时候才会有一些显著的影响（5% - 10% 左右），单机 QPS 不太大的时候损耗几乎可以忽略不计。 流量控制Sentinel 可以针对不同的调用关系，以不同的运行指标（如 QPS、并发调用数、系统负载等）为基准，对资源调用进行流量控制，将随机的请求调整成合适的形状。 Sentinel 支持多样化的流量整形策略，在 QPS 过高的时候可以自动将流量调整成合适的形状。常用的有： 直接拒绝模式：即超出的请求直接拒绝。 慢启动预热模式：当流量激增的时候，控制流量通过的速率，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。 匀速器模式：利用 Leaky Bucket 算法实现的匀速模式，严格控制了请求通过的时间间隔，同时堆积的请求将会排队，超过超时时长的请求直接被拒绝。 Sentinel 还支持 基于调用关系的限流，包括基于调用方限流、基于调用链入口限流、关联流量限流等，依托于 Sentinel 强大的调用链路统计信息，可以提供精准的不同维度的限流。 Sentinel 0.2.0 开始支持 热点参数限流，能够实时的统计热点参数并针对热点参数的资源调用进行流量控制。 系统负载保护Sentinel 对系统的维度提供保护，负载保护算法借鉴了 TCP BBR 的思想。当系统负载较高的时候，如果仍持续让请求进入，可能会导致系统崩溃，无法响应。在集群环境下，网络负载均衡会把本应这台机器承载的流量转发到其它的机器上去。如果这个时候其它的机器也处在一个边缘状态的时候，这个增加的流量就会导致这台机器也崩溃，最后导致整个集群不可用。针对这个情况，Sentinel 提供了对应的保护机制，让系统的入口流量和系统的负载达到一个平衡，保证系统在能力范围之内处理最多的请求。 实时监控与控制面板Sentinel 提供 HTTP API 用于获取实时的监控信息，如调用链路统计信息、簇点信息、规则信息等。如果用户正在使用 Spring Boot/Spring Cloud 并使用了 Sentinel Spring Cloud Starter，还可以方便地通过其暴露的 Actuator Endpoint 来获取运行时的一些信息，如动态规则等。未来 Sentinel 还会支持标准化的指标监控 API，可以方便地整合各种监控系统和可视化系统，如 Prometheus、Grafana 等。 Sentinel 控制台（Dashboard）提供了机器发现、配置规则、查看实时监控、查看调用链路信息等功能，使得用户可以非常方便地去查看监控和进行配置。 总结]]></content>
      <tags>
        <tag>Hystrix,Sentinel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[限流总结]]></title>
    <url>%2F2019%2F06%2F13%2Frate-limiter%2F</url>
    <content type="text"><![CDATA[限流背景高并发神器 缓存 降级：低价值的服务、影响到核心流程，暂时屏蔽掉 限流：限制并发/请求量，比如稀缺资源(秒杀、抢购)、写服务(评论、下单)、频繁的复杂查询(评论的后几页) 限流目的通过对请求的频率(一定时间窗口内的请求数)进行限制来保护系统，一旦达到临界值，就可以拒绝服务(跳转到错误页、告知资源没有了)、排队等待(秒杀、评论、下单)、降级(返回兜底数据，如库存默认有货) 限流算法计数器令牌桶算法 令牌桶算法是一个存放固定容量令牌的桶，按照固定速率往桶里添加令牌。令牌桶算法的描述如下： 假设限制2r/s，则按照500毫秒的固定速率往桶中添加令牌； 桶中最多存放b个令牌，当桶满时，新添加的令牌被丢弃或拒绝； 当一个n个字节大小的数据包到达，将从桶中删除n个令牌，接着数据包被发送到网络上； 如果桶中的令牌不足n个，则不会删除令牌，且该数据包将被限流（要么丢弃，要么缓冲区等待）。 漏桶算法 漏桶作为计量工具（The Leaky Bucket Algorithm as a Meter）时，可以用于流量整形（Traffic Shaping）和流量控制（TrafficPolicing），漏桶算法的描述如下： 一个固定容量的漏桶，按照常量固定速率流出水滴； 如果桶是空的，则不需流出水滴； 可以以任意速率流入水滴到漏桶； 如果流入水滴超出了桶的容量，则流入的水滴溢出了（被丢弃），而漏桶容量是不变的。 应用级限流限制总并发/连接/请求数限制极限并发/请求数，即TPS/QPS阀值。如Tomcat的maxConnections、maxThread，MySQL的max_connections、Redis的tcp-backlog 限制总资源数稀缺资源，有多个系统使用，可采用池化技术(数据库连接、线程) 限制某个接口的总并发/请求数防止某接口因突发访问量太大，造成系统崩溃(抢购业务) 开放平台使用AtomicLong、Semaphore进行限流 12345678try &#123; if(atomic.incrementAndGet() &gt; 限流数) &#123; //拒绝请求 &#125; //处理请求&#125; finally &#123; atomic.decrementAndGet();&#125; 限制某接口的时间窗请求数一些基础服务可能会被很多其他系统调用，比如商品详情页更新时会调用基础商品服务 12345678910111213141516171819LoadingCache&lt;Long, AtomicLong&gt; counter = CacheBuilder.newBuilder() .expireAfterWrite(2, TimeUnit.SECONDS) .build(new CacheLoader&lt;Long, AtomicLong&gt;() &#123; @Override public AtomicLong load(Long seconds) throws Exception &#123; return new AtomicLong(0); &#125; &#125;);long limit = 1000;while(true) &#123; //得到当前秒 long currentSeconds = System.currentTimeMillis() / 1000; if(counter.get(currentSeconds).incrementAndGet() &gt; limit) &#123; System.out.println("限流了:" + currentSeconds); continue; &#125; //业务处理&#125; 可使用Guava的LodingCache来存储计数器，过期时间设置为2秒（保证1秒内的计数器是有的），然后我们获取当前时间戳然后取秒数来作为KEY进行计数统计和限流，这种方式也是简单粗暴 平滑限流某个接口的请求数之前的限流方式都不能很好地应对突发情况，因此需要进行流量整型，有两种算法满足我们的场景：令牌桶和漏桶算法。Guava RateLimiter提供了令牌桶算法实现：平滑突发限流(SmoothBursty) 和 平滑预热限流(SmoothWarmingUp) 实现。 假设将应用部署到多台机器，应用级限流方式只是单应用内的请求限流，不能进行全局限流。因此我们需要分布式限流和接入层限流来解决这个问题。 分布式限流最关键的是要将限流服务做成原子化，而解决方案可以使使用redis+lua或者nginx+lua技术进行实现，通过这两种技术可以实现的高并发和高性能 Lua本身就是一种编程语言，也可以使用它实现复杂的令牌桶或漏桶算法。 Redis + Lua 限流123456789local key = KEYS[1] --限流KEY（一秒一个）local limit = tonumber(ARGV[1]) --限流大小local current = tonumber(redis.call("INCRBY", key, "1")) --请求数+1if current &gt; limit then --如果超出限流大小 return 0elseif current == 1 then --只有第一次访问需要设置2秒的过期时间 redis.call("expire", key,"2")endreturn 1 如上方式有一个缺点就是当达到限流大小后还是会递增的，可以改造成如下方式实现： 12345678910local key = KEYS[1] --限流KEY（一秒一个）local limit = tonumber(ARGV[1]) --限流大小local current = tonumber(redis.call('get', key) or "0")if current + 1 &gt; limit then --如果超出限流大小 return 0else --请求数+1，并设置2秒过期 redis.call("INCRBY", key,"1") redis.call("expire", key,"2") return 1end 如下是Java中判断是否需要限流的代码： 1234567public static boolean acquire() throws Exception &#123;String luaScript = Files.toString(new File("limit.lua"), Charset.defaultCharset());Jedis jedis = new Jedis("192.168.147.52", 6379);String key = "ip:" + System.currentTimeMillis()/ 1000; //此处将当前时间戳取秒数Stringlimit = "3"; //限流大小return (Long)jedis.eval(luaScript,Lists.newArrayList(key), Lists.newArrayList(limit)) == 1;&#125; 因为Redis的限制（Lua中有写操作不能使用带随机性质的读操作，如TIME）不能在Redis Lua中使用TIME获取时间戳，因此只好从应用获取然后传入，在某些极端情况下（机器时钟不准的情况下），限流会存在一些小问题。 Nginx + Lua 限流12345678910111213141516171819202122local locks = require "resty.lock"local function acquire() local lock =locks:new("locks") local elapsed, err =lock:lock("limit_key") --互斥锁 local limit_counter =ngx.shared.limit_counter --计数器 local key = "ip:" ..os.time() local limit = 5 --限流大小 local current =limit_counter:get(key) if current ~= nil and current + 1&gt; limit then --如果超出限流大小 lock:unlock() return 0 end if current == nil then limit_counter:set(key, 1, 1) --第一次需要设置过期时间，设置key的值为1，过期时间为1秒 else limit_counter:incr(key, 1) --第二次开始加1即可 end lock:unlock() return 1endngx.print(acquire()) 实现中我们需要使用lua-resty-lock互斥锁模块来解决原子性问题(在实际工程中使用时请考虑获取锁的超时问题)，并使用ngx.shared.DICT共享字典来实现计数器。如果需要限流则返回0，否则返回1。使用时需要先定义两个共享字典（分别用来存放锁和计数器数据）： 12345http &#123; …… lua_shared_dict locks 10m; lua_shared_dict limit_counter 10m; &#125; 有人会纠结如果应用并发量非常大那么redis或者nginx是不是能抗得住；不过这个问题要从多方面考虑：你的流量是不是真的有这么大，是不是可以通过一致性哈希将分布式限流进行分片，是不是可以当并发量太大降级为应用级限流；对策非常多，可以根据实际情况调节；像在京东使用Redis+Lua来限流抢购流量，一般流量是没有问题的。 对于分布式限流目前遇到的场景是业务上的限流，而不是流量入口的限流；流量入口限流应该在接入层完成，而接入层笔者一般使用Nginx。 接入层限流接入层通常指请求流量的入口，该层的主要目的有：负载均衡、非法请求过滤、请求聚合、缓存、降级、限流、A/B测试、服务质量监控等等，可以参考笔者写的《使用Nginx+Lua(OpenResty)开发高性能Web应用》。 对于Nginx接入层限流可以使用Nginx自带了两个模块：连接数限流模块ngx_http_limit_conn_module和漏桶算法实现的请求限流模块ngx_http_limit_req_module。还可以使用OpenResty提供的Lua限流模块lua-resty-limit-traffic进行更复杂的限流场景。 limit_conn用来对某个KEY对应的总的网络连接数进行限流，可以按照如IP、域名维度进行限流。limit_req用来对某个KEY对应的请求的平均速率进行限流，并有两种用法：平滑模式（delay）和允许突发模式(nodelay)。 ngx_http_limit_conn_module limit_conn是对某个KEY对应的总的网络连接数进行限流。可以按照IP来限制IP维度的总连接数，或者按照服务域名来限制某个域名的总连接数。但是记住不是每一个请求连接都会被计数器统计，只有那些被Nginx处理的且已经读取了整个请求头的请求连接才会被计数器统计。 12345678910http &#123; limit_conn_zone$binary_remote_addr zone=addr:10m; limit_conn_log_level error; limit_conn_status 503; ... server &#123; ... location /limit &#123; limit_conn addr 1; &#125; limit_conn：要配置存放KEY和计数器的共享内存区域和指定KEY的最大连接数；此处指定的最大连接数是1，表示Nginx最多同时并发处理1个连接； limit_conn_zone：用来配置限流KEY、及存放KEY对应信息的共享内存区域大小；此处的KEY是“$binary_remote_addr”其表示IP地址，也可以使用如$server_name作为KEY来限制域名级别的最大连接数； limit_conn_status：配置被限流后返回的状态码，默认返回503； limit_conn_log_level：配置记录被限流后的日志级别，默认error级别。]]></content>
      <tags>
        <tag>rate-limiter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[整洁代码随想]]></title>
    <url>%2F2019%2F06%2F06%2Fclean-code%2F</url>
    <content type="text"><![CDATA[感想代码大部分时候是用来维护的，一定要清晰好看自描述的代码胜过文档和注释比较适合写注释的两种场景： public interface，向别人明确发布你功能的语义，输入输出，且不需要关注实现。 功能容易有歧义的点，或者涉及比较深层专业知识的时候。比如，如果你写一个客户端，各种config参数的含义等。 设计模式只是手段，代码清晰才是目的一些所谓“高手”的代码都比较抽象，各种工厂、各种继承。想找到一个实现总是要山路十八弯，一个工程里大部分的类是抽象类或者接口，找不到一两句实现的代码，整个读起代码来很不顺畅 当你的系统内大部分抽象只有一个实现的时候，要好好思考一下，是不是设计有点过度了，清晰永远是第一准则。 code review用git的pull request机制来做code review 重点应该review什么？ 凡是能通过机器检查出来的事情，无需通过人。比如换行、注释、方法长度、代码重复等。除了基本功能需求的逻辑合理没有bug外，我们更应该关注代码的设计与风格。比如，一段功能是不是应该属于一个类、是不是有很多相似的功能可以抽取出来复用、代码太过冗长难懂等等。 勤于重构 掌握一些常见的“无痛”重构技巧 小步快跑，不要企图一口吃成个胖子 建立自动化测试机制 熟练掌握IDE的自动重构功能 静态检查可以与发布系统做集成，强制把主要问题修复掉才可以上线 通用技巧单一职责优先定义整体框架我写代码的时候，比较喜欢先去定义整体的框架，就是写很多空实现，来把整体的业务流程穿起来。良好的方法签名，用入参和出参来控制流程。这样能够避免陷入业务细节无法自拔。在脑海中先定义清楚流程的几个阶段，并为每个阶段找到合适的方法／类归属。 清晰的命名避免过长参数避免过长方法和类 横向拆分 根据业务，把建立／更新／修改／通知等逻辑拆到不同的类里去 纵向拆分 把数据库操作/MQ操作/Cache操作/对象校验等，拆到不同的对象里去，让主流程尽量简单可控，让同一个类，表达尽量同一个维度的东西。 让相同长度的代码段表示相同粒度的逻辑面向对象设计技巧贫血与领域驱动大部分公司采用的三层/四层贫血模型，已经让我们的编码习惯，变成了面向DAO而不是面向对象。 缺少了必要的模型抽象和设计环节，使得代码冗长，复用程度比较差。每次撸代码的时候，从mapper撸起，好像已经成为不成文的规范。 一个好的系统，一定离不开一套好的模型定义。梳理清楚系统中的核心模型，清楚的定义每个方法的类归属，无论对于代码的可读性、可交流性，还是和产品的沟通，都是有莫大好处的。 为每个方法找到合适的类归属，数据和行为尽量要在一起如果一个类的所有方法，都是在操作另一个类的对象。这时候就要仔细想一想类的设计是否合理了。理论上讲，面向对象的设计，主张数据和行为在一起。这样，对象之间的结构才是清晰的，也能减少很多不必要的参数传递。 但是，如果操作一个对象数据的所有方法都建立在对象内部，可能使对象承载了很多并不属于它本身职能的方法。 例如，我定义一个类，叫做person，。这个类有很多行为，比如：吃饭、睡觉、上厕所、生孩子；也有很多字段，比如：姓名、年龄、性格。 很明显，字段从更大程度上来讲，是定义和描述我这个人的，但很多行为和我的字段并不相关。上厕所的时候是不会关心我是几岁的。如果把所有关于人的行为全部在person内部承载，这个类一定会膨胀的不行。 这时候就体现了service方法的价值，如果一个行为，无法明确属于哪个领域对象，牵强地融入领域对象里，会显得很不自然。这时候，无状态的service可以发挥出它的作用。但一定要把握好这个度，回归本质，我们要把属于每个模型的行为合理的去划定归属。 警惕staticstatic方法，本质上来讲是面向过程的，无法清晰地反馈对象之间的关系。虽然有一些代码实例（自己实现单例或者Spring托管等）的无状态方法可以用static来表示，但这种抽象是浅层次的。说白了，如果我们所有调用static的地方，都写上import static，那么所有的功能就由类自己在承载了。 而单例的膨胀，很大程度上也是贫血模型带来的副作用。如果对象本身有血有肉，就不需要这么多无状态方法。 static真正适用的场景：工具方法，而不是业务方法。 巧用method objectmethod object是大型重构的常用技巧。当一段逻辑特别复杂的代码，充斥着各种参数传递和是非因果判断的时候，我首先想到的重构手段是提取method object。所谓method object，是一个有数据有行为的对象。依赖的数据会成为这个对象的变量，所有的行为会成为这个对象的内部方法。利用成员变量代替参数传递，会让代码简洁清爽很多。并且，把一段过程式的代码转换成对象代码，为很多面向对象编程才可以使用的继承／封装／多态等提供了基础。 面向接口编程正确使用继承和组合protected abstract 这种是最值得使用继承的，父类保留扩展点，子类扩展 继承更多的是为扩展提供便利，为复用而存在的方法最好使用组合的方式 代码复用技巧模板方法这是我用得最多的设计模式了。每当有两个行为类似但又不完全相同的代码段时，我总是会想到模板方法。提取公共流程和可复用的方法到父类，保留不同的地方作为abstract方法，由不同的子类去实现。 最后，把不属于流程的、但可复用的方法，判断是不是属于基类的领域职责，再使用继承或者组合的方法，为这些方法找到合适的安家之处。 extract method责任链经常看到这样的代码，一连串类似的行为，只是数据或者行为不一样。如一堆校验器，如果成功怎么样、失败怎么样；或者一堆对象构建器，各去构造一部分数据。碰到这种场景，我总是喜欢定义一个通用接口，入参是完整的要校验／构造的参数， 出参是成功/失败的标示或者是void。然后有很多实现器分别实现这个接口，再用一个集合把这堆行为串起来。最后，遍历这个集合，串行或者并行的执行每一部分的逻辑。 这样做的好处是： ① 很多通用的代码可以在责任链原子对象的基类里实现； ② 代码清晰，开闭原则，每当有新的行为产生的时候，只需要定义行的实现类并添加到集合里即可； ③ 为并行提供了基础。 为集合显式定义它的行为例如一个Map，它可能表示一个配制、一个缓存等等。如果所有的操作都是直接操作Map，那么它的行为就没有任何语义。第一，读起来就必须要深入细节；第二，如果想从获取配置读取缓存的地方加个通用的逻辑，例如打个log什么的，你可以想象是多么的崩溃。 个人提倡的做法是，对于有明确语义的集合的一些操作，尤其是全局的集合或者被经常使用的集合，做一些封装和抽象，如把Map封装成一个Cache类或者一个config类，再提供GetFromCache这样的方法。]]></content>
      <tags>
        <tag>design, clean code</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[精力管理]]></title>
    <url>%2F2019%2F06%2F03%2Fenergy-manage%2F</url>
    <content type="text"><![CDATA[第一部分：如何全情投入1、目标 2、事实 3、行动，这三个方面缺一不可。 人生目标是一种独特的精力源。目标会带来专注、满足感和激情。 第二步就是要面对现实，查找自己的工作和生活习惯，分析出来导致精力下降的核心原因。 第三步是行动，用实际行动缩小“现实和理想差距。建立和养成良好仪式习惯。 每天早晨上班时你的兴奋度是多少？ 享受做事有多大程度是因为事情本身而非它带来的回报？ 你认为自己对价值取向负有多大的责任？ 大家可以测试一下3个问题，每个问题满分10分。 如果3道问题的总分达到27分以上，说明你已经带着强烈的人生目标生活了。如果总分在22分以下，说明你的生活只是走过场。 关键不是于生活赋予你怎样的意义，而在于你是否主动将生活变成自己价值取向的载体。 当目标感从消极流向积极、从外部流向内部、从自己流向他人，它就成为生活中最强大而且也最持久的精力来源。 从心理学上看，人们会在一定程度上，会被外部的激励或者物质奖励驱动； 但是，要发挥出更多的热情，前提还是要自己本身就是享受事物，也才能从中获得长久的乐趣。 判断自己日常做的事情，要思考一下，这件事情，是基于外部刺激呢？还是内心深处自己的价值取向。 我们经常会把这两点混淆，单纯为了某种利益刺激，很难得到长久的满足感，也就不容易全情投入。 要怎么去寻找价值取向呢？ 几个问题，帮助我们去寻找，大家也可以试着在回答一下，最好是能写下来： 如果你现在得知自己只有一个月的生命了，你回想走过的一生，学到的最重要的3件事是什么？为什么如此重要呢？ 你最敬重的一个人是谁？描述一下他身上最让你钦佩的3种品质分别是哪些？ 如果有机会让你重生一次，你最希望自己是一个什么样的人？ 你希望你的墓志铭上怎么总结你的一生？ 你要是发现自己的每天的行为和自己的价值很多不相符，那就要来重新审视一下，到底是我的价值找错了，还是我的行为错了。 要面对现实，可以把自己当成研究的对象， 从1到10，你给自己工作中投入程度打几分？是什么障碍了你的表现？ 你的日常行为有多少符合你的价值观？脱节的地方在哪里？ 你的工作表现多大程度上反映了你的价值观、符合自己的构想？在家的表现呢？哪里做得不足？ 身体方面的日常习惯——饮食、锻炼、睡眠、平衡压力——对你核心价值关有助于你的核心价值观？ 你的情感回应在那些情况下符合你的价值观？在工作中和家里是不是有不同？ 你是否明智并且很高效地投资了你的精力？ 第二部分 精力的四个来源 精力不足的罪魁祸首是体能不足 间歇性训练 第二方面要关注的是呼吸 从生理学的角度看，精力来源于，氧气和血糖的化学反应。 三次一组吸气、也就是，把一次吸气分为三次，把呼气分成六次，这样通过深度、平静、有节奏地呼吸会激发精力，带来放松、精力不够的时候可以尝试做一下这个动作。 呼吸很自然也很复杂，如果你有一天不记得这些所谓的呼吸要领，也没有10分钟时间来练习呼吸。没关系，只要记得直立行走的人在面对自己，面对他人，面对环境的任何时候都应该脚往地下深处扎，头往天上高处顶，脊椎自然拉直，呼吸自然通畅，一切执着都是假，平平凡凡才见奇。 第三方面要关注的就是食物了，这也是精力的重要来源。 一天内吃五至六餐，有营养低热量的食物能够提供稳定的精力，很多公司会提供下午茶，也是为了给大家补充精力。 再有就是每天最少要喝水1.8升水，也就不多是一个大瓶可乐的水量。肌肉要是缺水3%就会失去10%的力量和8%的速度。长期饮水不足会严重的损害大脑的注意力和协调能力。 第四是睡眠，充足的睡眠是最重要的精力恢复来源。 晚上阅读点高深的书籍，会比较容易疲倦，产生困意，还有戒掉把手机带到床上的习惯。把手机放远一点，这样呢，还有个好处是，第二天早上闹铃响了，要起床走几步才能把它关掉。 早上7点前起床，到户外快走，晚上11点睡觉。四周以后，作息习惯就能彻底改了过来。 哈佛大学一项研究发现，中午小睡一会，能快速恢复精力。不要认为自己在中午睡一会儿就会耽误工作，其实呢，小睡一会，你能处理的工作往往超过你的想像。 第四方面要关注的是情绪 满足和安全感的活动都能够激发正面情感、能够恢复精力 要去多做一些能够有社交性的活动，比如骑自行车、参加读书会、听音乐会等等，因为可以和其它人交流，这样满足感会时间会持续的长一些。 思维精力恢复的关键呢，就是让大脑能有间歇地休息 我们的左半脑负责逻辑分析能力，右脑负责灵感，创造力呢，需要调动左右半脑交替思考。 创造性需要投入和抽离、思考和放松、活跃与休息之间有节奏的交替进行 学习新的软件、新课程、每天记几个新单词都能帮助我们锻炼思维肌肉，更好地为效能表现服务。 第三部分是 精力管理的训练系统要想成好习惯，一个实用的方法是，给习惯赋予仪式感。 将时间和行为精准化和具体化，会在很大程度上增加精力的回复 我们面对的压力和挑战越大，就越需要细致的仪式习惯。 精确化和具体性能够让我们在一到两个月的周期里养成良好的习惯。 为了让改变能持久，不要一上来就改变很多，每一次只做一项重大改变，固化了以后在进行下一个。 总结 第一、就是要明确自己人生目标，找出价值取向。 第二、保持良好的饮食习惯、保障每天有7个小时的睡眠，中午可以小睡一会儿。 第三、要加强锻炼、至少要每天有几分钟间歇性的有氧运动。 第四、保持良好的心态、积极乐观，多做一些左右脑交替思考的训练。 第五：用仪式习惯来规范生活中的行为，重视和家人以及朋友的交流、改善人际关系。 第六：不要让惰性障碍我们的改变，通过刻意训练，几周以后你会发现，糟糕的精力情况会得到大幅改善。 过度使用或使用不足都会削弱精力储备，我们必须学会在精力消耗和再生之间找到平衡。 为了扩充精力的容量，我们必须超越习以为常的极限，按照运动员的方式进行系统训练。 积极的精力仪式习惯，即高度细化的精力管理日程，是全情投入和维持高效表现的关键。 长期处于压力之下得不到恢复，或长期处于脱离状态不承担压力，都会削弱精力的容量。 将工作时间分成90～120分钟的片段并加入短暂的休息时间，能够使人们发挥出最优水平 最重要的体能精力管理方法 早睡早起 坚持在同样的时间睡觉和起床 每天5～6次少量进食 每天吃早餐 饮食健康，营养均衡 尽量减少单糖化合物摄入 每天饮用1360～1800克的水 工作时每90分钟休息片刻 每天进行适量身体活动 每周至少两次心血管功能间断训练、两次力量训练 我的生活预想（反映出我的价值观）： 我的工作构想（反映出我的价值观）： 障碍工作表 期望成果： 责任自查日志 姓名： 第 周 说明：每天为自己在以下条目从5到1进行打分（5表示“非常成功”， 1表示“不成功”）。可随后进行备注，并在适当时机记录下完成次数与影响。]]></content>
      <tags>
        <tag>energy-manage</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo 异步调用]]></title>
    <url>%2F2019%2F05%2F29%2Fdubbo-asynchronous-call%2F</url>
    <content type="text"><![CDATA[Dubbo 默认采用单一长连接，底层实现是 Netty 的 NIO 异步通讯机制；基于这种机制，Dubbo 实现了以下几种调用方式： 同步调用 异步调用 参数回调 事件通知 同步调用同步调用是一种阻塞式的调用方式，即 Consumer 端代码一直阻塞等待，直到 Provider 端返回为止； Consumer 业务线程调用远程接口，向 Provider 发送请求，同时当前线程处于阻塞状态； Provider 接到 Consumer 的请求后，开始处理请求，将结果返回给 Consumer； Consumer 收到结果后，当前线程继续往后执行。 这里有 2 个问题： Consumer 业务线程是怎么进入阻塞状态的？ Consumer 收到结果后，如何唤醒业务线程往后执行的？ 其实，Dubbo 的底层 IO 操作都是异步的。Consumer 端发起调用后，得到一个 Future 对象。对于同步调用，业务线程通过Future#get(timeout)，阻塞等待 Provider 端将结果返回；timeout则是 Consumer 端定义的超时时间。当结果返回后，会设置到此 Future，并唤醒阻塞的业务线程；当超时时间到结果还未返回时，业务线程将会异常返回。 异步调用基于 Dubbo 底层的异步 NIO 实现异步调用，对于 Provider 响应时间较长的场景是必须的，它能有效利用 Consumer 端的资源，相对于 Consumer 端使用多线程来说开销较小。 异步调用，对于 Provider 端不需要做特别的配置。下面的例子中，Provider 端接口定义如下： 123&lt;dubbo:reference id="asyncService" interface="com.alibaba.dubbo.samples.async.api.AsyncService"&gt; &lt;dubbo:method name="goodbye" async="true"/&gt;&lt;/dubbo:reference&gt; 需要异步调用的方法，均需要使用 \dubbo:method/标签进行描述。 Consumer 端发起调用12345AsyncService service = ...;String result = service.goodbye("samples");// 这里的返回值为空，请不要使用Future&lt;String&gt; future = RpcContext.getContext().getFuture();... // 业务线程可以开始做其他事情result = future.get(); // 阻塞需要获取异步结果时，也可以使用 get(timeout, unit) 设置超时时间 Dubbo Consumer 端发起调用后，同时通过RpcContext.getContext().getFuture()获取跟返回结果关联的Future对象，然后就可以开始处理其他任务；当需要这次异步调用的结果时，可以在任意时刻通过future.get(timeout)来获取。 一些特殊场景下，为了尽快调用返回，可以设置是否等待消息发出： sent=”true” 等待消息发出，消息发送失败将抛出异常； sent=”false” 不等待消息发出，将消息放入 IO 队列，即刻返回。 默认为false。配置方式如下： 1&lt;dubbo:method name="goodbye" async="true" sent="true" /&gt; 如果你只是想异步，完全忽略返回值，可以配置 return=”false”，以减少 Future 对象的创建和管理成本： 1&lt;dubbo:method name="goodbye" async="true" return="false"/&gt; 此时，RpcContext.getContext().getFuture()将返回null。 整个异步调用的时序图如下： 参数回调参数回调有点类似于本地 Callback 机制，但 Callback 并不是 Dubbo 内部的类或接口，而是由 Provider 端自定义的；Dubbo 将基于长连接生成反向代理，从而实现从 Provider 端调用 Consumer 端的逻辑。 Provider 端定义 Service 和 Callback1234567public interface CallbackService &#123; void addListener(String key, CallbackListener listener);&#125;public interface CallbackListener &#123; void changed(String msg);&#125; Provider 端 Service 实现123456789101112131415161718192021222324252627282930313233343536public class CallbackServiceImpl implements CallbackService &#123; private final Map&lt;String, CallbackListener&gt; listeners = new ConcurrentHashMap&lt;String, CallbackListener&gt;(); public CallbackServiceImpl() &#123; Thread t = new Thread(new Runnable() &#123; public void run() &#123; while (true) &#123; try &#123; for (Map.Entry&lt;String, CallbackListener&gt; entry : listeners.entrySet()) &#123; try &#123; entry.getValue().changed(getChanged(entry.getKey())); &#125; catch (Throwable t) &#123; listeners.remove(entry.getKey()); &#125; &#125; Thread.sleep(5000); // timely trigger change event &#125; catch (Throwable t) &#123; t.printStackTrace(); &#125; &#125; &#125; &#125;); t.setDaemon(true); t.start(); &#125; public void addListener(String key, CallbackListener listener) &#123; listeners.put(key, listener); listener.changed(getChanged(key)); // send notification for change &#125; private String getChanged(String key) &#123; return "Changed: " + new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()); &#125;&#125; Provider 端暴露服务12345678&lt;bean id="callbackService" class="com.alibaba.dubbo.samples.callback.impl.CallbackServiceImpl"/&gt;&lt;dubbo:service interface="com.alibaba.dubbo.samples.callback.api.CallbackService" ref="callbackService" connections="1" callbacks="1000"&gt; &lt;dubbo:method name="addListener"&gt; &lt;dubbo:argument index="1" callback="true"/&gt; &lt;!--&lt;dubbo:argument type="com.demo.CallbackListener" callback="true" /&gt;--&gt; &lt;/dubbo:method&gt;&lt;/dubbo:service&gt; 这里，Provider 需要在方法中声明哪个参数是 Callback 参数。 Consumer 端实现 Callback 接口123456CallbackService callbackService = ...;callbackService.addListener("foo.bar", new CallbackListener() &#123; public void changed(String msg) &#123; System.out.println("callback1:" + msg); &#125;&#125;); Callback 接口的实现类在 Consumer 端，当方法发生调用时，Consumer 端会自动 export 一个 Callback 服务。而 Provider 端在处理调用时，判断如果参数是 Callback，则生成了一个 proxy，因此服务实现类里在调用 Callback 方法的时候，会被传递到 Consumer 端执行 Callback 实现类的代码。 上述示例代码位于：https://github.com/dubbo/dubbo-samples/tree/master/dubbo-samples-callback 这种调用方式有点像消息的发布和订阅，但又有区别。比如当 Consumer 端 完成了Callback 服务的 export 后，如果后续重启了，这时 Provider 端就会调不通；同时 Provider 端如何清理掉这个 proxy 也是一个问题。 事件通知事件通知允许 Consumer 端在调用之前、调用之后或出现异常时，触发 oninvoke、onreturn、onthrow 三个事件。 12345&lt;bean id="demoCallback" class="com.alibaba.dubbo.samples.notify.impl.NotifyImpl" /&gt;&lt;dubbo:reference id="demoService" check="false" interface="com.alibaba.dubbo.samples.notify.api.DemoService" version="1.0.0" group="cn"&gt; &lt;dubbo:method name="sayHello" onreturn="demoCallback.onreturn" onthrow="demoCallback.onthrow"/&gt;&lt;/dubbo:reference&gt; 其中，NotifyImpl 的代码如下： 12345678910111213public class NotifyImpl implements Notify&#123; public Map&lt;Integer, String&gt; ret = new HashMap&lt;Integer, String&gt;(); public void onreturn(String name, int id) &#123; ret.put(id, name); System.out.println("onreturn: " + name); &#125; public void onthrow(Throwable ex, String name, int id) &#123; System.out.println("onthrow: " + name); &#125;&#125; oninvoke 方法参数与调用方法的参数相同； onreturn方法第一个参数为调用方法的返回值，其余为调用方法的参数； onthrow方法第一个参数为调用异常，其余为调用方法的参数。 上述配置中，sayHello方法为同步调用，因此事件通知方法的执行也是同步执行。可以配置 async=true让方法调用为异步，这时事件通知的方法也是异步执行的。特别强调一下，oninvoke方法不管是否异步调用，都是同步执行的。 事件通知的示例代码请参考：https://github.com/dubbo/dubbo-samples/tree/master/dubbo-samples-notify]]></content>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[API接口安全性设计]]></title>
    <url>%2F2019%2F05%2F18%2Fapi-security-specification%2F</url>
    <content type="text"><![CDATA[Token、Timestamp和Sign，保证接口的数据不被篡改和重复调用： Token授权机制：用户使用用户名密码登录后服务器给客户端返回一个Token（通常是UUID），并将Token-UserId以键值对的形式存放在缓存服务器中。服务端接收到请求后进行Token验证，如果Token不存在，说明请求无效。Token是客户端访问服务端的凭证。 时间戳超时机制：用户每次请求都带上当前时间的时间戳timestamp，服务端接收到timestamp后跟当前时间进行比对，如果时间差大于一定时间（比如5分钟），则认为该请求失效。时间戳超时机制是防御DOS攻击的有效手段。 签名机制：将 Token 和 时间戳 加上其他请求参数再用MD5或SHA-1算法（可根据情况加点盐）加密，加密后的数据就是本次请求的签名sign，服务端接收到请求后以同样的算法得到签名，并跟当前的签名进行比对，如果不一样，说明参数被更改过，直接返回错误标识。签名机制保证了请求参数不会被篡改。 拒绝重复调用（非必须）：客户端第一次访问时，将签名sign存放到缓存服务器中，超时时间设定为跟时间戳的超时时间一致，二者时间一致可以保证无论在timestamp限定时间内还是外 URL都只能访问一次。如果有人使用同一个URL再次访问，如果发现缓存服务器中已经存在了本次签名，则拒绝服务。如果在缓存中的签名失效的情况下，有人使用同一个URL再次访问，则会被时间戳超时机制拦截。这就是为什么要求时间戳的超时时间要设定为跟时间戳的超时时间一致。拒绝重复调用机制确保URL被别人截获了也无法使用（如抓取数据）。 1、客户端通过用户名密码登录服务器并获取Token2、客户端生成时间戳timestamp，并将timestamp作为其中一个参数3、客户端将所有的参数，包括Token和timestamp按照自己的算法进行排序加密得到签名sign4、将token、timestamp和sign作为请求时必须携带的参数加在每个请求的URL后边（http://url/request?token=123&amp;timestamp=123&amp;sign=123123123）5、服务端写一个过滤器对token、timestamp和sign进行验证，只有在token有效、timestamp未超时、缓存服务器中不存在sign三种情况同时满足，本次请求才有效]]></content>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[性能优化模式]]></title>
    <url>%2F2019%2F05%2F15%2Fperformance-tuning-pattern%2F</url>
    <content type="text"><![CDATA[在某些情况下，降低响应时间、提高系统吞吐量和提高服务可用性三者相互矛盾，不可兼得。例如：增加缓存可以降低平均响应时间，但是处理线程数量会因为缓存过大而有所限制，从而降低系统吞吐量；为了提高服务可用性，对异常请求重复调用是一个常用的做法，但是这会提高响应时间并降低系统吞吐量。 系统面临如下三个挑战：1. 日益增长的用户数量，2. 日渐复杂的业务，3. 急剧膨胀的数据。 设计原则最小可用原则两个关注点：1. 强调快速接入，快速完成；2. 实现核心功能可用。这是一个被普遍运用的原则，其目标是缩短测试周期，增加试错机会，避免过度设计。为了快速接入就必须最大限度地利用已有的解决方案或系统。从另外一个角度讲，一个解决方案或系统只要能够满足基本需求，就满足最小可用原则的应用需求。过度强调快速接入原则会导致重构风险的增加，原则上讲，基于该原则去设计系统需要为重构做好准备。 经济原则经济原则关注的是成本问题，看起来很像最小可用原则，但是它们之间关注点不同。最小可用原则的目标是通过降低开发周期，快速接入而实现风险可控，而快速接入并不意味着成本降低，有时候为了实现快速接入可能需要付出巨大的成本。软件项目的生命周期包括：预研、设计、开发、测试、运行、维护等阶段。最小可用原则主要运用在预研阶段，而经济原则可以运用在整个软件生命周期里，也可以只关注某一个或者几个阶段。例如：运行时经济原则需要考虑的系统成本包括单次请求的CPU、内存、网络、磁盘消耗等；设计阶段的经济原则要求避免过度设计；开发阶段的经济原则可能关注代码复用，工程师资源复用等。 代码复用原则代码复用原则分为两个层次：第一个层次使用已有的解决方案或调用已存在的共享库（Shared Library），也称为方案复用；第二个层次是直接在现有的代码库中开发，也称之为共用代码库。 方案复用是一个非常实用主义的原则，它的出发点就是最大限度地利用手头已有的解决方案，即使这个方案并不好。方案的形式可以是共享库，也可以是已存在的服务。方案复用的例子参见避免蚊子大炮模式的具体案例。用搜索引擎服务来解决查找附近商家的问题是一个性能很差的方案，但仍被很多工程师使用。方案复用原则的一个显著优点就是提高生产效率，例如：Java之所以能够得到如此广泛应用，原因之一就是有大量可以重复利用的开源库。实际上“Write once, run anywhere”是Java语言最核心的设计理念之一。基于Java语言开发的代码库因此得以在不同硬件平台、不同操作系统上更广泛地使用。 共用代码库要求在同一套代码库中完成所有功能开发。采用这个原则，代码库中的所有功能编译时可见，新功能代码可以无边界的调用老代码。另外，原代码库已存在的各种运行、编译、测试、配置环境可复用。主要有两个方面地好处：1. 充分利用代码库中已有的基础设施，快速接入新业务；2. 直接调用原代码中的基础功能或原語，避免网络或进程间调用开销，性能更佳。共用代码库的例子参见垂直分割模式的具体案例。 从设计的角度上讲，方案复用类似于微服务架构，而共用代码库和Monolithic Architecture很接近。总的来说，微服务倾向于面向接口编程，要求设计出可重用性的组件（Library或Service），通过分层组织各层组件来实现良好的架构。与之相对应，Monolith Architecture则希望尽可能在一套代码库中开发，通过直接调用代码中的基础功能或原語而实现性能的优化和快速迭代。使用Monolith Architecture有很大的争议，被认为不符合“设计模式”的理念。参考文献[4]，Monolithic Design主要的缺点包括：1. 缺乏美感；2. 很难重构；3. 过早优化（参见文献[6]Optimize judiciously）; 4. 不可重用；5. 限制眼界。微服务架构是很多互联网公司的主流架构。Monolithic Architecture也有其忠实的粉丝，例如：Tripadvisor的全球网站就共用一套代码库；基于性能的考虑，Linux最终选择的也是Monolithic kernel的模式。 奥卡姆剃刀原则一般而言，一个系统的代码量会随着其功能增加而变多。系统的健壮性有时候也需要通过编写异常处理代码来实现。异常考虑越周全，异常处理代码量越大。但是随着代码量的增大，引入Bug的概率也就越大，系统也就越不健壮。从另外一个角度来讲，异常流程处理代码也要考虑健壮性问题，这就形成了无限循环。所以在系统设计和代码编写过程中，奥卡姆剃刀原则要求：一个功能模块如非必要，就不要；一段代码如非必写，就不写。 奥卡姆剃刀原则和最小可用原则有所区别。最小可用原则主要运用于产品MVP阶段，本文所指的奥卡姆剃刀原则主要指系统设计和代码编写两个方面，这是完全不同的两个概念。MVP包含系统设计和代码编写，但同时，系统设计和代码编写也可以发生在成熟系统的迭代阶段。 性能恶化模式长请求拥塞反模式（High Latency Invocating AntiPattern）这是一种单次请求时延变长而导致系统性能恶化甚至崩溃的恶化模式。对于多线程服务，大量请求时间变长会使线程堆积、内存使用增加，最终可能会通过如下三种方式之一恶化系统性能： 1. 线程数目变多导致线程之间CPU资源使用冲突，反过来进一步延长了单次请求时间； 2. 线程数量增多以及线程中缓存变大，内存消耗随之剧增，对于基于Java语言的服务而言，又会更频繁地full GC，反过来单次请求时间会变得更长； 3. 内存使用增多，会使操作系统内存不足，必须使用Swap，可能导致服务彻底崩溃。 长请求拥塞反模式所导致的性能恶化现象非常普遍，所以识别该模式非常重要。典型的场景如下：某复杂业务系统依赖于多个服务，其中某个服务的响应时间变长，随之系统整体响应时间变长，进而出现CPU、内存、Swap报警。系统进入长请求拥塞反模式的典型标识包括：被依赖服务可用性变低、响应时间变长、服务的某段计算逻辑时间变长等。 多次请求杠杆反模式（Levered Multilayer Invocating AntiPattern）客户端一次用户点击行为往往会触发多次服务端请求，这是一次请求杠杆；每个服务端请求进而触发多个更底层服务的请求，这是第二次请求杠杆。每一层请求可能导致一次请求杠杆，请求层级越多，杠杆效应就越大。在多次请求杠杆反模式下运行的分布式系统，处于深层次的服务需要处理大量请求，容易会成为系统瓶颈。与此同时，大量请求也会给网络带来巨大压力，特别是对于单次请求数据量很大的情况，网络可能会成为系统彻底崩溃的导火索。典型恶化流程图如下图： 多次请求杠杆所导致的性能恶化现象非常常见，例如：对于美团推荐系统，一个用户列表请求会有多个算法参与，每个算法会召回多个列表单元（商家或者团购），每个列表单元有多种属性和特征，而这些属性和特征数据服务又分布在不同服务和机器上面，所以客户端的一次用户展现可能导致了成千上万的最底层服务调用。对于存在多次请求杠杆反模式的分布式系统，性能恶化与流量之间往往遵循指数曲线关系。这意味着，在平常流量下正常运行服务系统，在流量高峰时通过线性增加机器解决不了可用性问题。所以，识别并避免系统进入多次请求杠杆反模式对于提高系统可用性而言非常关键。 反复缓存反模式（Recurrent Caching AntiPattern）为了降低响应时间，系统往往在本地内存中缓存很多数据。缓存数据越多，命中率就越高，平均响应时间就越快。为了降低平均响应时间，有些开发者会不加限制地缓存各种数据，在正常流量情况下，系统响应时间和吞吐量都有很大改进。但是当流量高峰来临时，系统内存使用开始增多，触发了JVM进行full GC，进而导致大量缓存被释放（因为主流Java内存缓存都采用SoftReference和WeakReference所导致的），而大量请求又使得缓存被迅速填满，这就是反复缓存。反复缓存导致了频繁的full GC，而频繁full GC往往会导致系统性能急剧恶化。典型恶化流程图如下图： 性能优化模式水平分割模式（Horizontal partitioning Pattern）原理和动机一次请求总耗时=解析请求耗时 + ∑(获取数据耗时+处理数据耗时) + 组装返回结果耗时 大部分耗时长的服务主要时间都花在中间两个环节，即获取数据和处理数据环节。对于非计算密集性的系统，主要耗时都用在获取数据上面。获取数据主要有三个来源：本地缓存，远程缓存或者数据库，远程服务。三者之中，进行远程数据库访问或远程服务调用相对耗时较长，特别是对于需要进行多次远程调用的系统，串行调用所带来的累加效应会极大地延长单次请求响应时间，这就增大了系统进入长请求拥塞反模式的概率。如果能够对不同的业务请求并行处理，请求总耗时就会大大降低。 水平分割模式首先将整个请求流程切分为必须相互依赖的多个Stage，而每个Stage包含相互独立的多种业务处理（包括计算和数据获取）。完成切分之后，水平分割模式串行处理多个Stage，但是在Stage内部并行处理。如此，一次请求总耗时等于各个Stage耗时总和，每个Stage所耗时间等于该Stage内部最长的业务处理时间。 水平分割模式有两个关键优化点：减少Stage数量和降低每个Stage耗时。为了减少Stage数量，需要对一个请求中不同业务之间的依赖关系进行深入分析并进行解耦，将能够并行处理的业务尽可能地放在同一个Stage中，最终将流程分解成无法独立运行的多个Stage。降低单个Stage耗时一般有两种思路：1. 在Stage内部再尝试水平分割（即递归水平分割)，2. 对于一些可以放在任意Stage中进行并行处理的流程，将其放在耗时最长的Stage内部进行并行处理，避免耗时较短的Stage被拉长。 水平分割模式不仅可以降低系统平均响应时间，而且可以降低TP95响应时间（这两者有时候相互矛盾，不可兼得）。通过降低平均响应时间和TP95响应时间，水平分割模式往往能够大幅度提高系统吞吐量以及高峰时期系统可用性，并大大降低系统进入长请求拥塞反模式的概率。 具体案例伴随着算法工程师的持续迭代，算法数量越来越多，随之而来的结果就是客户端响应时间越来越长，系统很容易进入长请求拥塞反模式。曾经有一段时间，一旦流量高峰来临，出现整条服务链路的机器CPU、内存报警。在对系统进行分析之后，我们采取了如下三个优化措施，最终使得系统TP95时间降低了一半： 算法之间并行计算； 每个算法内部，多次特征获取进行了并行处理； 在调度线程对工作线程进行调度的时候，耗时最长的线程最先调度，最后处理。 缺点和优点对成熟系统进行水平切割，意味着对原系统的重大重构，工程师必须对业务和系统非常熟悉，所以要谨慎使用。水平切割主要有两方面的难点： 并行计算将原本单一线程的工作分配给多线程处理，提高了系统的复杂度。而多线程所引入的安全问题让系统变得脆弱。与此同时，多线程程序测试很难，因此重构后系统很难与原系统在业务上保持一致。 对于一开始就基于单线程处理模式编写的系统，有些流程在逻辑上能够并行处理，但是在代码层次上由于相互引用已经难以分解。所以并行重构意味着对共用代码进行重复撰写，增大系统的整体代码量，违背奥卡姆剃刀原则。 对于上面提到的第二点，举例如下：A和B是逻辑可以并行处理的两个流程，基于单线程设计的代码，假定处理完A后再处理B。在编写处理B逻辑代码时候，如果B需要的资源已经在处理A的过程中产生，工程师往往会直接使用A所产生的数据，A和B之间因此出现了紧耦合。并行化需要对它们之间的公共代码进行拆解，这往往需要引入新的抽象，更改原数据结构的可见域。 在如下两种情况，水平切割所带来的好处不明显： 一个请求中每个处理流程需要获取和缓存的数据量很大，而不同流程之间存在大量共享的数据，但是请求之间数据共享却很少。在这种情况下，流程处理完之后，数据和缓存都会清空。采用顺序处理模式，数据可以被缓存在线程局部存储（ThreadLocal）中而减少重复获取数据的成本；如果采用水平切割的模式，在一次请求中，不同流程会多次获取并缓存的同一类型数据，对于内存原本就很紧张的系统，可能会导致频繁full GC，进入反复缓存反模式。 某一个处理流程所需时间远远大于其他所有流程所需时间的总和。这种情况下，水平切割不能实质性地降低请求响应时间。 采用水平切割的模式可以降低系统的平均响应时间和TP95响应时间，以及流量高峰时系统崩溃的概率。虽然进行代码重构比较复杂，但是水平切割模式非常容易理解，只要熟悉系统的业务，识别出可以并行处理的流程，就能够进行水平切割。有时候，即使少量的并行化也可以显著提高整体性能。对于新系统而言，如果存在可预见的性能问题，把水平分割模式作为一个重要的设计理念将会大大地提高系统的可用性、降低系统的重构风险。总的来说，虽然存在一些具体实施的难点，水平分割模式是一个非常有效、容易识别和理解的模式。 垂直分割模式（Vertical partitioning Pattern）原理和动机对于移动互联网节奏的公司，新需求往往是一波接一波。基于代码复用原则，工程师们往往会在一个系统实现大量相似却完全不相干的功能。伴随着功能的增强，系统实际上变得越来越脆弱。这种脆弱可能表现在系统响应时间变长、吞吐量降低或者可用性降低。导致系统脆弱原因主要来自两方面的冲突：资源使用冲突和可用性不一致冲突。 资源使用冲突是导致系统脆弱的一个重要原因。不同业务功能并存于同一个运行系统里面意味着资源共享，同时也意味着资源使用冲突。可能产生冲突的资源包括：CPU、内存、网络、I/O等。例如：一种业务功能，无论其调用量多么小，都有一些内存开销。对于存在大量缓存的业务功能，业务功能数量的增加会极大地提高内存消耗，从而增大系统进入反复缓存反模式的概率。对于CPU密集型业务，当产生冲突的时候，响应时间会变慢，从而增大了系统进入长请求拥塞反模式的可能性。 不加区别地将不同可用性要求的业务功能放入一个系统里，会导致系统整体可用性变低。当不同业务功能糅合在同一运行系统里面的时候，在运维和机器层面对不同业务的可用性、可靠性进行调配将会变得很困难。但是，在高峰流量导致系统濒临崩溃的时候，最有效的解决手段往往是运维，而最有效手段的失效也就意味着核心业务的可用性降低。 垂直分割思路就是将系统按照不同的业务功能进行分割，主要有两种分割模式：部署垂直分割和代码垂直分割。部署垂直分割主要是按照可用性要求将系统进行等价分类，不同可用性业务部署在不同机器上，高可用业务单独部署；代码垂直分割就是让不同业务系统不共享代码，彻底解决系统资源使用冲突问题。 具体案例我们的挑战来自于美团推荐系统，美团客户端的多个页面都有推荐列表。虽然不同的推荐产品需求来源不同，但是为了实现快速的接入，基于共用代码库原则，所有的推荐业务共享同一套推荐代码，同一套部署。在一段时间内，我们发现push推荐和首页“猜你喜欢推荐”的资源消耗巨大。特别是在push推荐的高峰时刻，CPU和内存频繁报警，系统不停地full GC，造成美团用户进入客户端时，首页出现大片空白。 在对系统进行分析之后，得出两个结论： 首页“猜你喜欢”对用户体验影响更大，应该给予最高可用性保障，而push推荐给予较低可用性保障； 首页“猜你喜欢”和push推荐都需要很大的本地缓存，有较大的内存使用冲突，并且响应时间都很长，有严重的CPU使用冲突。 因此我们采取了如下措施，一方面，解决了首页“猜你喜欢”的可用性低问题，减少了未来出现可用性问题的概率，最终将其TP95响应时间降低了40%；另一方面也提高了其他推荐产品的服务可用性和高峰吞吐量。 将首页“猜你喜欢”推荐进行单独部署，而将push推荐和其他对系统资源要求不高的推荐部署在另一个集群上面； 对于新承接的推荐业务，新建一套代码，避免影响首页推荐这种最高可用性的业务。 缺点和优点 增加了维护成本。一方面代码库数量增多提高了开发工程师的维护成本，另一方面，部署集群的变多会增加运维工程师的工作量； 代码不共享所导致的重复编码工作。 解决重复编码工作问题的一个思路就是为不同的系统提供共享库（Shared Library），但是这种耦合反过来可能导致部署机器中引入未部署业务的开销。所以在共享库中要减少静态代码的初始化开销，并将类似缓存初始化等工作交给上层系统。总的来说，通过共享库的方式引入的开销可以得到控制。但是对于业务密集型的系统，由于业务往往是高度定制化的，共用一套代码库的好处是开发工程师可以采用Copy-on-write的模式进行开发，需要修改的时候随时拷贝并修改。共享库中应该存放不容易变化的代码，避免使用者频繁升级，所以并不适合这种场景。因此，对于业务密集型的系统，分代码所导致的重复编码量是需要权衡的一个因素。 垂直分割是一个非常简单而又有效的性能优化模式，特别适用于系统已经出现问题而又需要快速解决的场景。部署层次的分割既安全又有效。需要说明的是部署分割和简单意义上的加机器不是一回事，在大部分情况下，即使不增加机器，仅通过部署分割，系统整体吞吐量和可用性都有可能提升。所以就短期而言，这几乎是一个零成本方案。对于代码层次的分割，开发工程师需要在业务承接效率和系统可用性上面做一些折衷考虑。 恒变分离模式（Runtime 3NF Pattern）原理和动机基于性能的设计要求变化的数据和不变的数据分开，这一点和基于面向对象的设计原则相悖。在面向对象的设计中，为了便于对一个对象有整体的把握，紧密相关的数据集合往往被组装进一个类，存储在一个数据库表，即使有部分数据冗余（关于面向对象与性能冲突的讨论网上有很多文章，本文不细讲）。很多系统的主要工作是处理变化的数据，如果变化的数据和不变的数据被紧密组装在一起，系统对变化数据的操作将引入额外的开销。而如果易变数据占总数据比例非常小，这种额外开销将会通过杠杆效应恶化系统性能。分离易变和恒定不变的数据在对象创建、内存管理、网络传输等方面都有助于性能提高。 恒变分离模式的原理非常类似与数据库设计中的第三范式（3NF）：第三范式主要解决的是静态存储中重复存储的问题，而恒变分离模式解决的是系统动态运行时候恒定数据重复创建、传输、存储和处理的问题。按照3NF，如果一个数据表的每一记录都依赖于一些非主属性集合，而这些非主属性集合大量重复出现，那么应该考虑对被依赖的非主属性集合定义一个新的实体（构建一个新的数据表），原数据库的记录依赖于新实体的ID。如此一来数据库重复存储数据量将大大降低。类似的，按照恒变分离模式，对于一个实体，如果系统处理的只是这个实体的少量变化属性，应该将不变的属性定义为一个新实体（运行时的另一个类，数据库中的另一个表），原来实体通过ID来引用新实体，那么原有实体在运行系统中的数据传输、创建、网络开销都会大大降低。 案例分析我们的挑战是提供一个高性能、高一致性要求的团购服务（DealService）。系统存在一些多次请求杠杆反模式问题，客户端一次请求会导致几十次DealService读取请求，每次获取上百个团购详情信息，服务端单机需要支持每秒万次级别的吞吐量。基于需求，系统大体框架设计如下： 每个DealService定期从持久层同步所有发生变化的deal信息，所有的deal信息保存在内存里面。在最初的设计里面，数据库只有一个数据表DealModelTable，程序里面也只有一个实体类DealModel。由于销量、价格、用户评价等信息的频发变化，为了达到高一致性要求，服务系统每分钟需要从数据库同步几万条记录。随着美团团购数量的增多和用户活跃度的增加，系统出现了三个问题： 团购服务网卡频繁报警，由于这是高性能低延时服务，又导致了大量的客户端超时异常； 频繁的full GC，这是由于每条数据库记录更新都会导致运行系统里面老的DealModel实体被销毁，新的DealModels实体被创建； 数据库从库滞后主库，使得服务数据一致性降低，原因是数据库系统写数据量巨大。 在对系统进行分析之后，我们采用了如下措施，大大降低了网络传输的数据量，缓解了主从数据库同步压力，使得客户端的超时异常从高峰时候的9%降低到了小于0.01%（低于万分之一）： 将DealModelTable中的销量、价格、用户评价等常变的信息单独构建一张数据表VariableDealModel； 同时在代码中为销量、价格、用户评价等常变数据创建一个单独的类VariableDealModel； DealService对两张表进行分别同步； 如果DealModelTable的记录产生了更新，运行系统销毁老的DealModel实体并创建新的DealModel实体； 如果只是VariableDealModel的记录产生了更新，只对VariableDealModel的属性进行更改。 缺点和优点 不符合面向对象的设计原则。原本概念上统一的实体被切分成多个实体，会给开发工程师带来一些理解上的困难，因此增加维护成本。进一步而言，这会增加引入额外Bug的概率（实际上面向对象之所以如此受欢迎的一个重要原因就是容易理解）。 增加了类不变量（Class invariant）的维护难度。很多情况下，Class invariant是通过语言所提供的封装（Encapsulation）特性来维护的。当一个类变成多个类，Class invariant可能会被破坏。如果必须维护Class invariant，而这种Class invariant又发生在不同实体之间，那么往往是把不变的属性从不变实体移到易变的实体中去。 一张数据库表变成多张，也会增加维护成本。 在如下两种场景下，恒变分离模式所带来的好处有限： 易变数据导致的操作和传输并不频繁，不是系统主要操作； 易变数据占整体数据的比例很高，杠杆效应不显著，通过恒变分离模式不能根本性地解决系统性能问题。 总的来说，恒变分离模式非常容易理解，其应用往往需要满足两个条件：易变数据占整体数据比例很低（比例越低，杠杆效应越大）和易变数据所导致的操作又是系统的主要操作。在该场景下，如果系统性能已经出现问题，牺牲一些可维护性就显得物有所值。 大部分系统都是由多种类型的数据构成，大多数数据类型的都包含易变、少变和不变的属性。盲目地进行恒变分离会导致系统的复杂度指数级别的增加，系统变得很难维护，所以系统设计者必须在高性能和高维护性之间找到一个平衡点。作者的建议是：对于复杂的业务系统，尽量按照面向对象的原则进行设计，只有在性能出现问题的时候才开始考虑恒变分离模式；而对于高性能，业务简单的基础数据服务，恒变分离模式应该是设计之初的一个重要原则。 数据局部性模式（Locality Pattern）原理和动机数据局部性模式是多次请求杠杆反模式的针对性解决方案。在大数据和强调个性化服务的时代，一个服务消费几十种不同类型数据的现象非常常见，同时每一种类型的数据服务都有可能需要一个大的集群（多台机器）提供服务。这就意味着客户端的一次请求有可能会导致服务端成千上万次调用操作，很容易使系统进入多次请求杠杆反模式。在具体开发过程中，导致数据服务数量暴增的主要原因有两个：1. 缓存滥用以及缺乏规划，2. 数据量太大以至于无法在一台机器上提供全量数据服务。数据局部性模的核心思想是合理组织数据服务，减少服务调用次数。具体而言，可以从服务端和客户端两个方面进行优化。 服务端优化方案的手段是对服务进行重新规划。对于数据量太大以至于无法在一台机器上存储全量数据的场景，建议采用Bigtable或类似的解决方案提供数据服务。典型的Bigtable的实现包括Hbase、Google Cloud Bigtable等。实际上数据局部性是Bigtable的一个重要设计原则，其原理是通过Row key和Column key两个主键来对数据进行索引，并确保同一个Row key索引的所有数据都在一台服务器上面。通过这种数据组织方式，一次网络请求可以获取同一个Row key对应的多个Column key索引的数据。缺乏规划也是造成服务数量剧增的一个重要原因。很多通过统计和挖掘出来的特征数据往往是在漫长的时间里由不同team独立产生的。而对于每种类型数据，在其产生之初，由于不确定其实际效果以及生命周期，基于快速接入原则，服务提供者往往会用手头最容易实施的方案，例如采用Redis Cache（不加选择地使用缓存会导致缓存滥用）。数据服务之间缺乏联动以及缺乏标准接入规划流程就会导致数据服务数量膨胀。数据局部性原则对规划的要求，具体而言是指：1. 数据由尽可能少的服务器来提供，2. 经常被一起使用的数据尽可能放在同一台服务器上。 客户端优化有如下几个手段： 本地缓存，对于一致性要求不高且缓存命中率较高的数据服务，本地缓存可以减少服务端调用次数； 批处理，对于单机或者由等价的机器集群提供的数据服务，尽可能采用批处理方式，将多个请求合成在一个请求中； 客户端Hash，对于需要通过Hash将请求分配到不同数据服务机器的服务，尽量在客户端进行Hash，对于落入同一等价集群的请求采用批处理方式进行调用。 案例分析我们的挑战来自于美团的推荐、个性化列表和个性化搜索服务。这些个性化系统需要获取各种用户、商家和团购信息。信息类型包括基本属性和统计属性。最初，不同属性数据由不同的服务提供，有些是RPC服务，有些是Redis服务，有些是HBase或者数据库，参见下图： 通常而言，客户端每个用户请求都会触发多个算法。一方面，每个算法都会召回几十甚至几百个团购或者商家ID，团购和商家基础属性被均匀地分配到几十台Redis里面（如下图），产生了大量的Redis请求，极端情况下，一次客户端请求所触发的团购基础数据请求就超过了上千次；另一方面，用户特征属性信息有十几种，每种属性也由单独的服务提供，服务端网络调用次数暴增。在一段时间里，很多系统都进入了多次请求杠杆反模式，Redis服务器的网卡经常被打死，多次进行扩容，提高线程池线程数量，丝毫没有改善。 在对系统进行分析之后，按照数据局部性模式的原则，我们采用了如下手段，彻底解决了系统多次请求杠杆反模式的问题： 采用大内存服务器存储所有的团购和商家基础信息，每个算法只要一次网络请求就可以获取所有的信息； 服务端采用多线程方式提供服务，避免了Redis单一线程模式下单个请求慢所带来的连锁效应； 借鉴类似Bigtable的数据组织方式，将用户的多种特征采用两个维度（用户维度和特征类型）进行索引，确保同一用户的信息只存放在一台机器上面，减少网络调用数量。 缺点和优点数据局部性模式并不适用于系统初级阶段。在初级阶段，最小可用原则往往是主要设计原则之一，出于两方面的考虑：一方面，在初级阶段，很难预测所要提供服务的数据是否有效而且能够长期使用，以及未来的调用量；另一方面，在初级阶段，工程师可能无法预测最终的调用模式，而不同的调用模式会导致数据局部性方案的设计不同。对于已经大量使用的数据服务，采用数据局部性模式进行重构必然要改变老的调用模式，这一方面会引入新的Bug，另一方面也意味着巨大的工作量。需要特别强调的是，数据处于系统的最底层，对于结构复杂而又重要的数据，重构所带来可靠性、一致性和工作量都是需要权衡的因素。对于请求量比较小的数据服务，即使一次请求会触发严重的请求杠杆效应，但是如果原始触发请求数量在可预见的时间内没有明显变多的迹象，进行数据服务重构可能得不偿失。 数据局部性模式能够解决多次请求杠杆反模式所导致的问题，但它并非大数据的产物，CPU、编译器的设计理念里早就融入了该模式，所以很容易被工程师理解。虽然过度设计在系统初级阶段是一个要尽量避免的事情，但是理解和掌握数据局部性模式对于设计出一个可扩展、可重用的系统有很大帮助。很多成熟的系统因为多次请求杠杆反模式而导致系统频繁崩溃，理解数据局部性模式的原则有助于提高工程师分析解决问题的能力，而在确认了系统存在请求杠杆问题后，数据局部性原则是一件非常锐利的武器。 避免蚊子大炮模式（Avoiding Over-generalized Solution Pattern）原理和动机“用大炮打蚊子”本来是大材小用的意思，但是细致想一想，用大炮打蚊子，成功率不高。对于开发工程师而言，一方面为了快速承接业务，按照方案复用原则，总是尽可能地利用现有系统，这使得系统功能越来越强大；另一方面，提高系统的通用性或可重用性也是工程师们在设计系统的一个重要目标。随着这两个过程的相互独立演化，采用通用方案解决特定问题的现象随处可见，形象地说，这就像大炮打蚊子。大炮成本很高，蚊子的数量众多，最终的结局往往是蚊子战胜了大炮。 “避免蚊子大炮模式”是经济原则在运行时系统的运用，它要求采用最节省资源（CPU、内存等）的方法来解决所面临的问题，资源浪费会带来未来潜在的风险。工程师接到一个需求的时候，需要思考的不仅仅是如何复用现有的系统，减少开发时间，还需要考虑现有系统为处理每个新需求访问所需运行时成本，以及新需求的预期访问量。否则，不加辨别地利用现有系统，不仅仅增大了重构风险，还有可能交叉影响，对现有系统所支持的服务造成影响。从另外一个角度讲，工程师在构建一个可重用系统的时候，要明确其所不能解决和不建议解决的问题，而对于不建议解决的问题，在文档中标明潜在的风险。 案例分析我们的挑战是为移动用户寻找其所在位置附近的商家信息。美团有非常完善的搜索系统，也有资深的搜索工程师，所以一个系统需要查找附近的商家的时候，往往第一方案就是调用搜索服务。但是在美团，太多的服务有基于LBS的查询需求，导致搜索请求量直线上升，这本来不属于搜索的主营业务，在一段时间里面反倒成了搜索的最多请求来源。而搜索引擎在如何从几十万商家里面找最近的几百商家方面的性能非常差，因此一段时间里，搜索服务频繁报警。不仅仅搜索服务可用性受到了影响，所有依赖于LBS的服务的可用性都大大降低。 在对系统分析之后，我们认为更适合解决最短直线距离的算法应该是k-d tree，在快速实现了基于k-d tree的LBS Search解决方案之后，我们用4台服务器轻松解决了30多台搜索服务器无法解决的问题，平均响应时间从高峰时的100ms降低到300ns，性能取得了几百倍的提高。 缺点和优点避免蚊子大炮模式的问题和数据局部性模式类似，都与最小可用原则相冲突。在系统设计初级阶段，寻求最优方案往往意味着过度设计，整个项目在时间和成本变得不可控，而为每个问题去找最优秀的解决方案是不现实的奢求。最优化原则的要求是全面的，不仅仅要考虑的运行时资源，还需要考虑工程师资源和时间成本等，而这些点往往相互矛盾。在如下情况下，避免蚊子大炮模式所带来的好处有限：在可预见的未来，某个业务请求量非常小，这时候花大量精力去找最优技术方案效果不明显。 在设计阶段，避免蚊子大炮模式是一个需要工程师去权衡的选择，需要在开发成本和系统运行成本之间保持一个平衡点。当很多功能融入到一个通用系统里而出现性能问题的时候，要拆分出来每一个功能点所造成的影响也不是件轻易的事情，所以采用分开部署而共用代码库的原则可以快速定位问题，然后有针对性地解决“蚊子大炮”问题。总的来说，在设计阶段，避免蚊子大炮模式是工程师们进行分析和设计的一个重要准则，工程师可以暂时不解决潜在的问题，但是一定要清楚潜在的危害。构建可重用系统或方案，一定要明确其所不能解决和不建议解决的问题，避免过度使用。 实时离线分离模式（Sandbox Pattern）原理和动机本模式的极端要求是：离线服务永远不要调用实时服务。该模式比较简单也容易理解，但是，严格地讲它不是一种系统设计模式，而是一种管理规范。离线服务和在线服务从可用性、可靠性、一致性的要求上完全不同。原则上，工程师在编写离线服务代码的时候，应该遵循的就是离线服务编程规范，按照在线服务编程规范要求，成本就会大大提高，不符合经济原则；从另外一方面讲，按照离线服务的需求去写在线服务代码，可用性、可靠性、一致性等往往得不到满足。 具体而言，实时离线分离模式建议如下几种规范： 如果离线程序需要访问在线服务，应该给离线程序单独部署一套服务； 类似于MapReduce的云端多进程离线程序禁止直接访问在线服务； 分布式系统永远不要直接写传统的DBMS。 案例分析因为违反实时离线分离模式而导致的事故非常常见。有一次，因为一个离线程序频繁的向Tair集群写数据，每一次写10M数据，使得整个Tair集群宕机。另一次，因为Storm系统直接写MySQL数据库导致数据库连接数耗尽，从而使在线系统无法连接数据库。 缺点和优点为了实现实时在线分离，可能需要为在线环境和离线环境单独部署，维护多套环境所带来运维成本是工程师需要考虑的问题。另一方面，在线环境的数据在离线环境中可能很难获取，这也是很多离线系统直接访问在线系统的原因。但是，遵从实时离线分离模式是一个非常重要的安全管理准则，任何违背这个准则的行为都意味着系统性安全漏洞，都会增大线上故障概率。 降级模式（Degradation Pattern）原理和动机降级模式是系统性能保障的最后一道防线。理论上讲，不存在绝对没有漏洞的系统，或者说，最好的安全措施就是为处于崩溃状态的系统提供预案。从系统性能优化的角度来讲，不管系统设计地多么完善，总会有一些意料之外的情况会导致系统性能恶化，最终可能导致崩溃，所以对于要求高可用性的服务，在系统设计之初，就必须做好降级设计。根据作者的经验，良好的降级方案应该包含如下措施： 在设计阶段，确定系统的开始恶化数值指标（例如：响应时间，内存使用量）； 当系统开始恶化时，需要第一时间报警； 在收到报警后，或者人工手动控制系统进入降级状态，或者编写一个智能程序让系统自动降级； 区分系统所依赖服务的必要性，一般分为：必要服务和可选服务。必要服务在降级状态下需要提供一个快速返回结果的权宜方案（缓存是常见的一种方案），而对于可选服务，在降级时系统果断不调用； 在系统远离恶化情况时，需要人工恢复，或者智能程序自动升级。 典型的降级策略有三种：流量降级、效果降级和功能性降级。流量降级是指当通过主动拒绝处理部分流量的方式让系统正常服务未降级的流量，这会造成部分用户服务不可用；效果降级表现为服务质量的降级，即在流量高峰时期用相对低质量、低延时的服务来替换高质量、高延时的服务，保障所有用户的服务可用性；功能性降级也表现为服务质量的降级，指的是通过减少功能的方式来提高用户的服务可用性。效果降级和功能性降级比较接近，效果降级强调的是主功能服务质量的下降，功能性降级更多强调的是辅助性功能的缺失。做一个类比如下：计划将100个工程师从北京送到夏威夷度假，但是预算不够。采用流量降级策略，只有50工程师做头等舱去了夏威夷度假，其余工程师继续编写程序（这可不好）；效果降级策略下，100个工程师都坐经济舱去夏威夷；采用功能性降级策略，100个工程师都坐头等舱去夏威夷，但是飞机上不提供食品和饮料。 案例分析我们的系统大量使用了智能降级程序。在系统恶化的时候，智能降级程序自动降级部分流量，当系统恢复的时候，智能降级程序自动升级为正常状态。在采用智能降级程序之前，因为系统降级问题，整体系统不可用的情况偶尔发生。采用智能降级程序之后，基本上没有因为性能问题而导致的系统整体不可用。我们的智能降级程序的主要判定策略是服务响应时间，如果出现大量长时间的响应异常或超时异常，系统就会走降级流程，如果异常数量变少，系统就会自动恢复。 缺点和优点为了使系统具备降级功能，需要撰写大量的代码，而降级代码往往比正常业务代码更难写，更容易出错，所以并不符合奥卡姆剃刀原则。在确定使用降级模式的前提下，工程师需要权衡这三种降级策略的利弊。大多数面向C端的系统倾向于采用效果降级和功能性降级策略，但是有些功能性模块（比如下单功能）是不能进行效果和功能性降级的，只能采用流量降级策略。对于不能接受降级后果的系统，必须要通过其他方式来提高系统的可用性。 总的来说，降级模式是一种设计安全准则，任何高可用性要求的服务，必须要按照降级模式的准则去设计。对于违背这条设计原则的系统，或早或晚，系统总会因为某些问题导致崩溃而降低可用性。不过，降级模式并非不需要成本，也不符合最小可用原则，所以对于处于MVP阶段的系统，或者对于可用性要求不高的系统，降级模式并非必须采纳的原则。 其他性能优化建议对于无法采用系统性的模式方式讲解的性能优化手段，作者也给出一些总结性的建议： 1. 删除无用代码有时候可以解决性能问题，例如：有些代码已经不再被调用但是可能被初始化，甚至占有大量内存；有些代码虽然在调用但是对于业务而言已经无用，这种调用占用CPU资源。 2. 避免跨机房调用，跨机房调用经常成为系统的性能瓶颈，特别是那些伪batch调用（在使用者看起来是一次性调用，但是内部实现采用的是顺序单个调用模式）对系统性能影响往往非常巨大 。 总结Christopher Alexander曾说过：”Each pattern describes a problem which occurs over and over again in our environment, and then describes the core of the solution to that problem, in such a way that you can use this solution a million times over, without ever doing it the same way twice” 。 尽管Christopher Alexander指的是建筑模式，软件设计模式适用，基于同样的原因，性能优化模式也适用。每个性能优化模式描述的都是工程师们日常工作中经常出现的问题，一个性能优化模式可以解决确定场景下的某一类型的问题。所以要理解一个性能优化模式不仅仅要了解性能模式的所能解决的问题以及解决手段，还需要清楚该问题所发生的场景和需要付出的代价。 参考文献 Chang F, Dean J, Ghemawat S, et al. Bigtable: A Distributed Storage System for Structured Data Gamma E, Helm R, Johnson R, et al. Design Patterns-Elements of Reusable Object-Oriented Software. Machinery Industry, 2003 Motlik F. Monolithic Core Versus Full Microservice Architecture Monolithic Design WikiWikiWeb. Bovet D P, Cesati M. Understanding the Linux Kernel. 3rd ed. O’Reilly Media, 2005. Bloch J. Effective Java. 2nd ed. Addison-Wesley, 2008. Alexander C, Ishikawa S, Silverstein M. A Pattern Language: Towns, Buildings, Construction. Oxford University Press, 1977.]]></content>
      <tags>
        <tag>performance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何减少团队的低质量代码？]]></title>
    <url>%2F2019%2F05%2F06%2Fcode-quality%2F</url>
    <content type="text"><![CDATA[第二个方向，就是降低员工编写高质量代码的难度。第三个方向，是要确保由最专业的人员做自己最专业的事情。他们只需要提交这样的代码，然后你的框架自动为他们做好任务调度器、错误捕捉和处理、日志记录和处理、dry-run、重试、API、相关的 UI 界面等等各种逻辑，执行好相关的单元测试：主程每天应该看完所有的提交记录强制上静态检测。制定编码规范或者使用现成的规范强制 code review保证一定的单元测试覆盖率通过培训、技术分享、招聘等手段提升程序员素质。 代码结构是真实业务场景的写照，如果业务规划和前景不够清晰，代码是好不了的，不论我们采取多么灵活的处理方案。虽然我们可以通过技术手段，让这种复杂性更容易被理解，但是复杂性的程度却本质上没有改变。因此，工程师们就不得不提高自己在业务上的话语权，对问题域有更深入的理解。 能力+态度 &gt; 经验 + 学历 自动化运行你的产品 自动化运行以上各种检测工具 这些工具只能提高产品的下限，不能提升产品的上限]]></content>
      <tags>
        <tag>code-quality</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[后台token防重复提交]]></title>
    <url>%2F2019%2F04%2F12%2Frepeat-submit-interceptor%2F</url>
    <content type="text"><![CDATA[思路 添加拦截器，拦截需要防重复提交的请求 通过注解@Token来添加token/移除token 前端页面表单添加（如果是Ajax请求则需要在请求的json数据中添加token值） 核心代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394/** * com.xxx.interceptor.TokenInterceptor.java * Copyright 2018 Lifangyu, Inc. All rights reserved. */package com.xxx.common.interceptor;import org.apache.log4j.Logger;import org.springframework.web.method.HandlerMethod;import org.springframework.web.servlet.handler.HandlerInterceptorAdapter;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.lang.reflect.Method;import java.util.Random;import java.util.UUID;/** * Desc:防重复提交的拦截器 * &lt;p&gt; * Created by lifangyu on 2018/02/27. */public class TokenInterceptor extends HandlerInterceptorAdapter &#123; Logger logger = Logger.getLogger(TokenInterceptor.class); static String splitFlag = "_"; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if (handler instanceof HandlerMethod) &#123; HandlerMethod handlerMethod = (HandlerMethod) handler; Method method = handlerMethod.getMethod(); Token annotation = method.getAnnotation(Token.class); if (annotation == null) &#123; return true; &#125; boolean needSaveSession = annotation.add(); if (needSaveSession) &#123; Random random = new Random(); String uuid = UUID.randomUUID().toString().replace(splitFlag, String.valueOf(random.nextInt(100000))); String tokenValue = String.valueOf(System.currentTimeMillis()); request.setAttribute("token", uuid + splitFlag + tokenValue); // session 中 token 的key 每次都是变化的[适应浏览器 打开多个带有token的页面不会有覆盖session的key] request.getSession(true).setAttribute(uuid, tokenValue); &#125; boolean needRemoveSession = annotation.remove(); if (needRemoveSession) &#123; if (isRepeatSubmit(request)) &#123; logger.warn("please don't repeat submit,url:" + request.getServletPath()); return false; &#125; String clinetToken = request.getParameter("token"); if (clinetToken != null &amp;&amp; clinetToken.indexOf(splitFlag) &gt; -1) &#123; request.getSession(true).removeAttribute(clinetToken.split("_")[0]); &#125; &#125; return true; &#125; else &#123; return super.preHandle(request, response, handler); &#125; &#125; /** * 判断是否是重复提交 * * @param request * @return */ private boolean isRepeatSubmit(HttpServletRequest request) &#123; String clinetToken = request.getParameter("token"); if (clinetToken == null) &#123; return true; &#125; if (clinetToken.indexOf(splitFlag) &lt;= -1) &#123; return false; &#125; String uuid = clinetToken.split("_")[0]; String token = clinetToken.split("_")[1]; String serverToken = (String) request.getSession(true).getAttribute(uuid); if (serverToken == null) &#123; return true; &#125; if (!serverToken.equals(token)) &#123; return true; &#125; return false; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435/** * com.xxx.interceptor.Token.java * Copyright 2018 Lifangyu, Inc. All rights reserved. */package com.xxx.common.interceptor;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * Desc:Token 注解 * &lt;p&gt; * Created by lifangyu on 2018/02/27. */@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface Token &#123; /** * 添加token的开关[true：添加；false:不添加，default：false] * * @return */ boolean add() default false; /** * 移除token的开关[true：删除；false:不删除，default：false] * * @return */ boolean remove() default false;&#125; 12345678&lt;!-- 拦截器配置 --&gt;&lt;mvc:interceptors&gt; &lt;!-- 配置Token拦截器，防止用户重复提交数据 --&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/**"/&gt; &lt;bean class="com.xxx.interceptor.TokenInterceptor"/&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 123456@Token(add = true)@RequestMapping("toXxxHtml")public String toXxxHtml(Model mv) &#123; ...... return "xxx/xxxHtml";&#125; 123456&lt;form id="xxx_submit_form" class="form-horizontal" action="$&#123;ctx&#125;/xxx/addXxx.do" method="post"&gt; ...... &lt;!-- 注：name必须是token --&gt; &lt;input type="hidden" name="token" value="$&#123;token!''&#125;"/&gt; ......&lt;/form&gt; 123456@Token(remove = true)@RequestMapping("addXxx")public String addXxx() throws Exception &#123; ...... return "redirect:toXxxHtml.do";&#125;]]></content>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作中如何学好技术]]></title>
    <url>%2F2019%2F04%2F01%2Flearning-at-work%2F</url>
    <content type="text"><![CDATA[引言古人云：“活到老，学到老。”互联网算是最辛苦的行业之一，“加班”对工程师来说已是“家常便饭”，同时互联网技术又日新月异，很多工程师都疲于应付，叫苦不堪。以至于长期以来流传一个很广的误解：35岁是程序员工作的终点。 如何在繁忙的工作中做好技术积累，构建个人核心竞争力，相信是很多工程师同行都在思考的问题。本文是我自己的一些总结，试图从三个方面来解答： 第一部分阐述了一些学习的原则。任何时候，遵循一些经过检验的原则，都是影响效率的重要因素，正确的方法是成功的秘诀。 提升工作和学习效率的另一个重要因素是释惑和良好心态。第二部分分析了我在工作中碰到和看到的一些典型困惑。 成为优秀的架构师是大部分初中级工程师的阶段性目标。第三部分剖析架构师的能力模型，让大家对目标所需能力有一个比较清晰的认知。 如何学习在繁忙的工作中，持之以恒、不断学习和进步是一件艰巨的任务，需要坚强的毅力和坚定的决心。如果方法不得当，更是事倍功半。幸好我们的古人和现在哲人已经总结了很多优秀的学习方法论，这里汇总了一些重要原则。遵循这些方法必会对大家的工作学习大有裨益。 贵在坚持有报道指出，过去几十年的知识量超过之前人类几千年的知识量总和。而计算机领域绝对是当代知识更新最快的领域之一，因此，工程师必须要接受这样一个现实，现在所掌握的深厚知识体系很快就会被淘汰。要想在计算机领域持续做优秀架构师，就必须不停的学习，掌握最新技术。总之，学不可以已。 所谓“冰冻三尺，非一日之寒，水滴石穿，非一日之功”，通往架构师的道路漫长而又艰巨，轻易放弃，则所有付出瞬间付之东流。要想成为优秀的架构师，贵在坚持！ 虽然知识更新很快，但是基础理论的变化却非常缓慢。这就是“道”和“象”关系，纵是世间万象，道却万变不离其宗。对于那些非常基础的理论知识，我们需要经常复习，也就是“学而时习之”。 重视实践古人云：“纸上得来终觉浅，绝知此事要躬行。” 学习领域有所谓721模型：个人的成长70%来自于岗位实践，20%来自向他人学习，10%来自于培训。虽然这种理论存在争议，但对于工程师们来说，按照实践、学习和培训的方式进行重要性排序，大致是不错的。所以重视实践，在实践中成长是最重要的学习原则。 人类的认知有两种：感性认知和理性认知。这两种认知互相不可替代性。实践很大程度来自于感性学习，看书更像是理性学习。以学开汽车做例子，很难想象什么人能够仅仅通过学习书本知识就会开汽车。 书本知识主要是传道——讲述抽象原型，而对其具体应用场景的讲述往往含糊其辞，对抽象原型之间的关系也是浅尝辄止。采用同样精确的语言去描述应用场景和关联关系将会失去重点，让人摸不着头脑。所以，仅仅通过看书来获得成长就像是用一条腿走路。 重视实践，充分运用感性认知潜能，在项目中磨炼自己，才是正确的学习之道。在实践中，在某些关键动作上刻意练习，也会取得事半功倍的效果。 重视交流牛顿说：“如果说我看得比别人远一些，那是因为我站在巨人的肩膀上。”我们需要从别人身上学习。从老师、领导、同事、下属甚至对手身上学习，是快速成长的重要手段。 向老师和领导学习已经是人们生活习惯的一部分了。但是从同事甚至对手那里学习也很重要，因为这些人和我们自身更相似。所以要多多观察，取其所长，弃其所短。对于团队的小兄弟和下属，也要“不耻下问”。 此外，在项目中积极参与具体方案讨论也非常重要。参与者先验感知了相关背景，并且讨论的观点和建议也是综合了发言者多种知识和技能。所以，讨论让参与者能够非常全面，立体地理解书本知识。同时，和高手讨论，他们的观点就会像修剪机剪树枝一样，快速的剪掉自己知识领域里面的疑惑点。 重视总结和输出工程师在实践中会掌握大量细节，但是，即使掌握了所有细节，却没有深刻的总结和思考，也会陷入到“学而不思则罔”的境地。成长的“量变”来自于对细节的逐渐深入地把控，而真正的“质变”来自于对“道”的更深层次的理解。 将经验输出，接受别人的检验是高层次的总结。这种输出不仅帮助了别人，对自身更是大有裨益。总结的方式有很多，包括组织分享，撰写技术文章等等。当然“日三省吾身”也是不错的总结方式。总之，多多总结，多多分享，善莫大焉！ 解答别人的问题也是个人成长的重要手段。有时候，某个问题自己本来不太懂，但是在给别人讲解的时候却豁然开朗。所以，“诲人不倦”利人惠己。 重视规划凡事预则立，不预则废。对于漫长的学习生涯而言，好的计划是成功的一半。 长期规划长期规划的实施需要毅力和决心，但是做正确的长期规划还需要高瞻远瞩的眼界、超级敏感的神经和中大奖的运气。对于大部分人来说，长期规划定主要是“定方向”。但遵循如下原则能够减少犯方向性错误的概率： 远离日暮西山的行业。 做自己感兴趣的事情。 做有积累的事情。 一边走一边看，切勿一条道走到黑。 短期规划良好的短期规划应该在生活、成长、绩效和晋升之间取得平衡。大部分公司都会制定一个考核周期——少则一个月，多则一年。所以不妨以考核周期作为短期学习规划周期。本质上，规划是一个多目标优化问题，它有一系列的理论方案，这里不一一细说。基于相关理论，我给出一个简单易行的方案： 确定目标优先级。比如：成长、生活、绩效。 确定每个目标的下限。从优化理论的角度来看，这被称为约束。比如绩效必须在一般以上，之前已经规划好的旅行不能更改，必须读完《Effective Java》等等。 优先为下限目标分配足够的资源。比如，事先规划好的旅行需要10天，这10天就必须预算出去。 按照各主目标的顺序依次分配资源。比如，最终分配给学习的时间是10天。 在给定的学习预算下，制定学习目标，要激进。然后给出执行方案。比如，学习目标是掌握基本的统计学知识，并成为Java专家。具体方案为：完成《Effective Java》、《Java Performance》、《Design Pattern》、《Head First Statistics》四本书的阅读。 对规划中的各学习任务按目标优先级进行排序，并最先启动优先级最高的任务。比如，最高优先级是掌握统计理论，那么就要先看《Head First Statistics》。 对于该方案，要注意以下几点： 最低目标必须能够轻松达成的目标，否则，从优化理论的角度来讲，该命题无解。比如，类似“半年内完成晋级两次、绩效全部S、从菜鸟成为Java专家”就不太合适作为最低目标。总之，要区分理想和梦想。 主要目标规划必须具备一定的挑战性，需要规划出不可能完成的目标。过度规划本质上是一种贪婪算法，目的是目标价值最大化。因为一切皆有变数，如果其他目标能够提前完成，就不妨利用这些时间去完成更多的学习目标。总之，前途必须光明，道路必须坎坷。 各目标之间不一定共享资源，规划不一定互有冲突。 此外，短期规划还可以从如下几个方面进行优化： 学习计划最好能结合工作计划，理论联系实际结合，快速学以致用。比如，本季度规划去做一些数据分析工作，那么不妨把学习目标设置为学习统计知识。 要灵活对待规划的目标和具体执行步骤，需要避免“郑人买履”式的笑话。面临新的挑战和变化，规划需要不断地调整。 那些令人纠结的困惑人生是一场马拉松，在漫长的征途中，难免有很多困惑。困惑就像枷锁，使我们步履蹒跚，困惑就像死锁，让我们停滞不前。 接下来我将总结自己在工作中碰到和看到的一些典型困惑。这些困惑或者长期困扰作者本人，或者困扰我身边的同事和朋友。当这些困惑被释然之后，大家都感觉如重获释，为下一阶段的征程提供满满的正能量。人生就像一场旅途，不必在乎目的地，在乎的，应该是沿途的风景，以及看风景的心情。良好的心态是技术之旅最好的伴侣。期望通过这个解惑之旅，让大家拥有一个愉快的心情去感受漫长的学习旅途。 学无止境吗必须要承认一个残酷的现实：人的生命是有限的，知识却是无限的。用有限的生命去学习无限的知识是不可能完成的任务。一想到此，有些工程师不免产生一些悲观情绪。如果方法得当并且足够勤奋，悲伤大可不必。 虽然，人类的整体知识体系一直在扩张。但是就很多重要的工程细分领域，基础理论并不高深。计算机的很多重要领域，工程师有能力在有限时间内抓住核心要害。 比如，密码学被认为是门非常高深的学科，但是一大类密码技术的基础是数论中一个非常简单的理论——素因数分解：给出两个素数，很容易算出它们的积，然而反过来给定两个素数的积，分解的计算量却非常惊人。 “一致性”算得上是计算机领域里面最经典的难题，它是所有分布式系统的基础，从多核多CPU到多线程，从跨机器到跨机房，无所不在，几乎所有的计算机从业人员都在解决这个问题，但是Paxos给出了一个很优雅的解决方案。 权限管理是很多工程师的噩梦，但如果你能搞定“Attribute Based Access Control(ABAC)”和“Role-Based Access Control(RBAC)”，也能达到相当高度。 另外，技术学习是一场对抗赛，虽然学无止境，超越大部分对手就是一种胜利。所以，以正确的学习方式，长时间投入就会形成核心竞争力。 没有绝对高明的技术，只有真正的高手致力于在技术上有所成就的工程师，都梦想有朝一日成为技术高手。但技术高手的标准却存在很大的争议。这是一个有着悠久历史的误解：以某种技术的掌握作为技术高手的评判标准。我经常碰到这样一些情景：因为掌握了某些技术，比如Spring、Kafka、Elasticsearch等，一些工程师就自封为高手。有些工程师非常仰慕别的团队，原因竟是那个团队使用了某种技术。 这种误解的产生有几个原因：首先，技多不压身，技术自然是掌握的越多越好，掌握很多技术的人自然不是菜鸟。其次，在互联网时代来临之前，信息获取是非常昂贵的事情。这就导致一项技能的掌握可以给个人甚至整个公司带来优势地位。互联网时代，各种框架的出现以及开源的普及快速淘汰或者降低了很多技能的价值，同时降低了很多技术的学习门槛。所以，在当前，掌握某项技能知识只能是一个短期目标。怀揣某些技能就沾沾自喜的人需要记住：骄傲使人退步。 所谓“麻雀虽小，五脏俱全”。如果让你来做造物主，设计麻雀和设计大象的复杂度并没有明显区别。一个看起来很小的业务需求，为了达到极致，所需要的技术和能力是非常综合和高深的。真正的高手不是拿着所掌握的技术去卡客户需求，而是倾听客户的需求，给出精益求精的方案。完成客户的需求是一场擂台赛，真正的高手，是会见招拆招的。 不做项目就无法成长吗在项目中学习是最快的成长方式之一，很多工程师非常享受这个过程。但是一年到头都做项目，你可能是在一家外包公司。对于一个做产品的公司，如果年头到年尾都在做项目，要不然就是在初步创业阶段，要不然就是做了大量失败的项目，总之不算是特别理想的状态。正常情况，在项目之间都会有一些非项目时间。在这段时间，有些同学会产生迷茫，成长很慢。 项目真的是越多越好吗？答案显然是否定的。重复的项目不会给工程师们带来新的成长。不停的做项目，从而缺乏学习新知识的时间，会导致“做而不学则殆”。真正让工程师出类拔萃的是项目的深度，而不是不停地做项目。所以，在项目之间的空档期，工程师们应该珍惜难得的喘息之机，深入思考，把项目做深、做精。 如何提高项目的深度呢？一般而言，任何项目都有一个目标，当项目完成后，目标就算基本达成了。但是，客户真的满意了吗？系统的可用性、可靠性、可扩展性、可维护性已经做到极致了吗？这几个问题的答案永远是否定的。所以，任何一个有价值的项目，都可以一直深挖。深挖项目，深度思考还可以锻炼工程师的创造力。期望不停地做项目的人，就像一个致力于训练更多千里马的人是发明不出汽车的。锻炼创造力也不是一蹴而就的事情，需要长时间地思考。总之，工程师们应该总是觉得时间不够用，毕竟时间是最宝贵的资源。 职责真的很小吗很多时候，一个工程师所负责系统的数量和团队规模与其“江湖地位”正相关。但是，江湖地位与技术成长没有必然关联。提升技术能力的关键是项目深度以及客户的挑剔程度。项目越多，在单个项目中投入的时间就越少，容易陷入肤浅。特别需要避免的是“ 在其位不谋其政”的情况。团队越大，在管理方面需要投入的精力就越多。在管理技巧不成熟，技术眼界不够高的前提强行负责大团队，可能会导致个人疲于应付，团队毫无建树。最终“ 一将无能，累死三军”，效果可能适得其反。 从技术发展的角度来说，技术管理者应该关注自己所能把控的活跃项目的数量，并致力于提高活跃项目的影响力和技术深度。团队人数要与个人管理能力、规划能力和需求把控能力相适应。一份工作让多个人来干，每个人的成长都受限。每个人都做简单重复的工作，对技术成长没有任何好处。团队管理和项目管理需要循序渐进，忌“拔苗助长”。 一定要当老大吗有一些工程师的人生理想是做团队里的技术老大，这当然是一个值得称赞的理想。可是，如果整个团队技术能力一般，发展潜力一般，而你是技术最强者，这与其说是幸运，不如说是悲哀。这种场景被称之为“武大郎开店”。 团队里的技术顶尖高手不是不能做，但为了能够持续成长，需要满足如下几个条件： 首先你得是行业里面的顶尖专家了——实在很难找到比你更强的人了！ 其次，你经常需要承担对你自己的能力有挑战的任务，但同时你拥有一批聪明能干的队友。虽然你的技术能力最高，但是在你不熟悉的领域，你的队友能够进行探索并扩展整个团队的知识。 最后，你必须要敏而好学，不耻下问。 否则，加入更强的技术团队或许是更好的选择，最少不是什么值得骄傲的事情。 平台化的传说平台化算得上是“高大上”的代名词了，很多工程师挤破头就为了和“平台化”沾点边。然而和其他业务需求相比，平台化需求并没有本质上的区别。无论是平台化需求还是普通业务需求，它的价值都来自于客户价值。不同点如下： 很多平台化需求的客户来自于技术团队，普通需求的客户来自于业务方。 产品经理不同。普通业务需求来自于产品经理，平台化需求的产品经理可能就是工程师自己。长期被产品经理“压迫”的工程师们，在平台化上终于找到“翻身农奴把歌唱”的感觉。 很多平台化的关注点是接入能力和可扩展性，而普通业务的关注点更多。 归根结底，平台化就是一种普通需求。在实施平台化之前，一定要避免下面两个误区： 平台化绝对不是诸如“统一”、“全面”之类形容词的堆砌。是否需要平台化，应该综合考虑：客户数量，为客户解决的问题，以及客户价值是否值得平台化的投入。 平台化不是你做平台，让客户来服务你。一些平台化设计者的规划设计里面，把大量的平台接入工作、脏活累活交给了客户，然后自己专注于所谓“最高大上”的功能。恰恰相反，平台化应该是客户什么都不做，所有的脏活累活都由平台方来做。本质上讲，平台化的价值来自于技术深度。真正体现技术深度的恰恰是设计者能够很轻松的把所有的脏活累活搞定。 所以平台化的最佳实践是：投入最少的资源，解决最多的问题。平台解决一切，客户坐享其成。 搞基础技术就一定很牛吗经常听到同学们表达对基础技术部同学的敬仰之情，而对搞业务技术的同学表现出很轻视，认为存储、消息队列、服务治理框架（比如美团点评内部使用的OCTO）、Hadoop等才能被称为真正的技术。事实并非如此，更基础的并不一定更高深。 比如下面这个流传很久的段子：越高级的语言就越没有技术含量。但真是这样吗，就拿Java和C来说，这是完全不同的两种语言，所需要的技能完全不同。C或许跟操作系统更加接近一点，和CPU、内存打交道的机会更多一点。但是为了用好Java，程序员在面向对象、设计模式、框架技术方面必须要非常精通。Java工程师转到C方向确实不容易，但作者也见过很多转到Java语言的C工程师水土不服。 基础技术和业务应用技术必然会有不同的关注点，没有高低之分。之所以产生这种误解，有两个原因： 基础技术相对成熟，有比较完整的体系，这给人一个高大上的感觉。业务应用技术相对来说，由于每个团队使用的不一样，所以成熟度参差不齐，影响力没有那么大。 基础技术的门槛相对来说高一点，考虑到影响面，对可靠性、可用性等有比较高的最低要求。但是门槛高不代表技术含量高，另外成熟技术相对来说在创新方面会受到很大的约束。但是最先进的技术都来自活跃的创新。 对比下来，业务技术和基础技术各有千秋。但真正的高手关注的是解决问题，所有的技术都是技能而已。 可行性调研的那些坑工作中开展可行性调研时有发生。做可行性调研要避免如下情况： 把可行性调研做成不可行性调研。这真的非常糟糕。不可行性的结论往往是：因为这样或者那样的原因，所以不可行。 避免“老鼠给猫挂铃铛”式的高风险可行性方案。“天下大事必作于细”，可行性调研一定要细致入微，避免粗枝大叶。 避免调研时间过长。如果发现调研进展进入到指数级复杂度，也就是每前进一步需要之前两倍的时间投入，就应该果断的停止调研。 可行性调研的结论应该是收益与成本的折衷，格式一般如下： 首先明确预期的结果，并按照高中低收益进行分级。 阐述达成每种预期结果需要采取的措施和方案。 给出实施各方案需要付出的成本。 工程师天生不善沟通吗实际工作中，沟通所导致的问题层出不穷。工程师有不少是比较内向的，总是被贴上“不善沟通”的标签。实际上，沟通能力是工程师最重要的能力之一，良好的沟通是高效工作学习的基础，也是通过学习可以掌握的。下面我按工程师的语言说说沟通方面的经验。 第一类常见的问题是沟通的可靠性。从可靠性的角度来讲，沟通分为TCP模式和UDP模式。TCP模式的形象表述是：我知道你知道。UDP模式的形象表述是：希望你知道。TCP模式当然比较可靠，不过成本比较高，UDP模式成本低，但是不可靠。在沟通可靠性方面，常见错误有如下两种： 经常听到的这样的争论。一方说：“我已经告诉他了”，另一方说：“我不知道这个事情呀”。把UDP模式被当作TCP模式来使用容易产生扯皮。 过度沟通。有些同学对沟通的可靠性产生了过度焦虑，不断的重复讨论已有结论问题。把TCP模式当成UDP来使用，效率会比较低。 第二类沟通问题是时效性问题。从时效性讲，沟通分为：同步模式和异步模式。同步沟通形象地说就是：你现在给我听好了。异步沟通的形象表述是：记得给我做好了。在沟通时效性方面，有如下两种常见错误： 已经出现线上事故，紧急万分。大家你一言，我一语，感觉事故可能和某几个人有关，但是也不能完全确定，所以没有通知相关人员。最终，一个普通的事故变成了严重事故。对于紧急的事情，必须要同步沟通。 半夜三点你正在熟睡，或者周末正在逛街，接到一个电话：“现在有个需求，能否立刻帮忙做完。”这会非常令人郁闷，因为那并不是紧急的事情。不是所有的需求都需要立刻解决。 有效沟通的一个重要原则是提前沟通。沟通本质是信息交流和处理，可以把被沟通对象形象地比喻成串行信息处理的CPU。提前沟通，意味着将处理请求尽早放入处理队列里面。下面的例子让很多工程师深恶痛绝：一个需求策划了1个月，产品设计了2周。当开发工程是第一次听说该需求的时候，发现开发的时间是2天。工程师据理力争，加班加点1周搞定。最后的结论是工程师非常不给力，不配合。就像工程师讨厌类似需求一样。要协调一个大项目，希望获得别人的配合，也需要尽早沟通。 有效沟通的另外一个重点是“不要跑题”。很多看起来很接近的问题，本质上是完全不同的问题。比如：一个会议的主题是“如何实施一个方案”，有人却可能提出“是否应该实施该方案”。 “如何实施”和“是否应该实施”是完全不同的两个问题，很多看起来相关的问题实际上跑题很远。“跑题”是导致无效沟通的重要原因。 良好沟通的奥秘在于能掌握TCP模式和UDP模式精髓，正确判断问题的紧急性，尽量提前沟通，避免跑题。 带人之道有些初为导师的工程师由于担心毕业生的能力太弱，安排任务时候谆谆教诲，最后感觉还是有所顾虑，干脆自己写代码。同样的事情发生在很多刚刚管理小团队的工程师身上。最终的结果他们：写完所有的代码，让下属无代码可写。“ 事必躬亲”当然非常糟糕，最终的往往是团队的整体绩效不高，团队成员的成长很慢，而自己却很累。 古人说：“用人不疑，疑人不用。”这句话并非“放之四海而皆准”。在古代，受限于通信技术，反馈延迟显著，而且信息在传递过程中有大量噪音，变形严重。在这种情况下，如果根据短期内收集的少量变形的信息做快速决断，容易陷于草率。在公司里，这句话用于选人环节更为恰当，应该改为：录用不疑，疑人不录。 考虑到招聘成本，就算是在录用层面，有时候也无法做到。作为一个小团队的管理者，能够快速准确的获取团队成员的各种反馈信息，完全不需要“用人不疑，疑人不用”。用人的真正理论基础来自于“探索和利用”(Exploration and Exploitation )。不能因为下属能做什么就只让他做什么，更不能因为下属一次失败就不给机会。 根据经典的“探索和利用”(Exploration and Exploitation )理论，良好的用人方式应该如下： 首选选择相信，在面临失败后，收缩信任度。 查找失败的原因，提供改进意见，提升下属的能力。 总是给下属机会，在恰当地时机给下属更高的挑战。 总之，苍天大树来自一颗小种子，要相信成长的力量。 效率、效率、效率经常看到有些同学给自己的绩效评分是100分——满分，原因是在过去一段时间太辛苦了，但最终的绩效却一般般。天道酬勤不错，但是天道更酬巧。工程师们都学过数据结构，不同算法的时间复杂度的差距，仅仅通过更长的工作时间是难以弥补的。为了提升工作学习效率，我们需要注意以下几点： 主要关注效率提升。很多时候，与效率提升所带来的收益相比，延长时间所带来的成果往往不值得一提。 要有清晰的结果导向思维。功劳和苦劳不是一回事。 做正确的事情，而不仅仅正确地做事情。这是一个被不断提起的话题，但是错误每天都上演。为了在规定的时间内完成一个大项目，总是要有所取舍。如果没有重点，均匀发力，容易事倍功半。如果“南辕北辙”，更是可悲可叹。 架构师能力模型前面我们已经讲完了原则和一些困惑，那么工程师到底应该怎么提升自己呢？ 成为优秀的架构师是大部分初中级工程师的阶段性目标。优秀的架构师往往具备八种核心能力：编程能力、调试能力、编译部署能力、性能优化能力、业务架构能力、在线运维能力、项目管理能力和规划能力。 这几种能力之间的关系大概如下图。编程能力、调试能力和编译部署能力属于最基础的能力。不能精通掌握这三种能力，很难在性能优化能力和业务架构能力方面有所成就。具备了一定的性能优化能力和业务架构能力之后，才能在线运维能力和项目管理能力方面表现优越。团队管理能力是最高能力，它对项目管理能力的依赖度更大。 编程能力对工程师而言，编程是最基础的能力，必备技能。其本质是一个翻译能力，将业务需求翻译成机器能懂的语言。 提升编程能力的书籍有很多。精通面向对象和设计模式是高效编程的基础。初级工程师应该多写代码、多看代码。找高手做Code Review，也是提升编程水平的捷径。 调试能力程序代码是系统的静态形式，调试的目的是通过查看程序的运行时状态来验证和优化系统。本质上讲，工程师们通过不断调试可以持续强化其通过静态代码去预测运行状态的能力。所以调试能力也是工程师编程能力提升的关键手段。很早之前有个传说：“调试能力有多强，编程能力就有多强。”不过现在很多编辑器的功能很强大，调试能力的门槛已经大大降低。 调试能力是项目能否按时、高质量提交的关键。即使一个稍具复杂度的项目，大部分工程师也无法一次性准确无误的完成。大项目都是通过不断地调试进行优化和纠错的。所以调试能力是不可或缺的能力。 多写程序，解决Bug，多请教高手是提升调试能力的重要手段。 编译部署能力编译并在线上部署运行程序是系统上线的最后一个环节。随着SOA架构的普及以及业务复杂度的增加，大部分系统只是一个完整业务的一个环节，因此，本地编译和运行并不能完全模拟系统在线运行。为了快速验证所编写程序的正确性，编译并在线上部署就成了必要环节。所以编译部署能力是一个必备技能。 让盘根错节的众多子系统运行起来是个不小的挑战。得益于SOA架构的普及以及大量编译、部署工具的发展，编译部署的门槛已经大大降低。基于应用层进行开发的公司，已经很少有“编译工程师”的角色了。但是对于初级工程师而言，编译部署仍然不是一个轻松的事情。 性能优化能力衡量一个系统成功的一个重要指标是使用量。随着使用量的增加和业务复杂度的增加，大部分系统最终都会碰到性能问题。 性能优化能力是一个综合能力。因为： 影响系统性能的因素众多，包括：数据结构、操作系统、虚拟机、CPU、存储、网络等。为了对系统性能进行调优，架构师需要掌握所有相关的技术。 精通性能优化意味着深刻理解可用性、可靠性、一致性、可维护性、可扩展性等的本质。 性能优化与业务强耦合，最终所采取的手段是往往折衷的结果。所以，性能优化要深谙妥协的艺术。 可以说，性能优化能力是工程师们成长过程中各种技能开始融会贯通的一个标志。这方面可以参考之前的博客文章“常见性能优化策略的总结”。市场上还有很多与性能优化相关的书籍，大家可以参考。多多阅读开源框架中关于性能优化方面的文档和代码也不失为好的提升手段。动手解决线上性能问题也是提升性能优化能力的关键。如果有机会，跟着高手学习，分析性能优化解决方案案例（我们技术博客之前也发表了很多这方面的文章），也是快速提升性能优化能力的手段。 在线运维能力如果说性能优化能力体现的是架构师的静态思考能力，在线运维能力考验的就是动态反应能力。残酷的现实是，无论程序多么完美，Bug永远存在。与此同时，职位越高、责任越大，很多架构师需要负责非常重要的在线系统。对于线上故障，如果不能提前预防以及快速解决，损失可能不堪设想，所以在线运维能力是优秀架构师的必备技能。 为了对线上故障进行快速处理，标准化的监控、上报、升级，以及基本应对机制当然很重要。通过所观察到的现象，快速定位、缓解以及解决相关症状也相当关键。这要求架构师对故障系统的业务、技术具备通盘解读能力。解决线上故障的架构师就好比一个在参加比赛F1的车手。赛车手必须要了解自身、赛车、对手、同伴、天气、场地等所有因素，快速决策，不断调整。架构师必须要了解所有技术细节、业务细节、处理规范、同伴等众多因素，快速决断，迅速调整。 在线运维本质上是一个强化学习的过程。很多能力都可以通过看书、查资料来完成，但在线运维能力往往需要大量的实践来提升。 业务架构能力工程师抱怨产品经理的故事屡见不鲜，抱怨最多的主要原因来自于需求的频繁变更。需求变更主要有两个来源：第一个原因是市场改变或战略调整，第二个原因是伪需求。对于第一个原因，无论是工程师还是产品经理，都只能无奈的接受。优秀的架构师应该具备减少第二种原因所导致的需求变更的概率。 伪需求的产生有两个原因： 第一个原因是需求传递变形。从信息论的角度来讲，任何沟通都是一个编码和解码的过程。典型的需求从需求方到产品经理，最终到开发工程师，最少需要经历三次编码和解码过程。而信息的每一次传递都存在一些损失并带来一些噪音，这导致有些时候开发出来的产品完全对不上需求。此外，需求方和产品经理在需求可行性、系统可靠性，开发成本控制方面的把控比较弱，也会导致需求变形。 第二个原因就是需求方完全没有想好自己的需求。 优秀的架构师应该具备辨别真伪需求的能力。应该花时间去了解客户的真实业务场景，具备较强的业务抽象能力，洞悉客户的真实需求。系统的真正实施方是工程师，在明确客户真实需求后，高明的架构师应该具备准确判断项目对可行性、可靠性、可用性等方面的要求，并能具备成本意识。最后，由于需求与在线系统的紧耦合关系，掌握在线系统的各种细节也是成功的业务架构的关键。随着级别的提升，工程师所面对的需求会越来越抽象。承接抽象需求，提供抽象架构是架构师走向卓越的必经之途。 市场上有一些关于如何成为架构师的书，大家可以参考。但是架构能力的提升，实践可能是更重要的方式。业务架构师应该关注客户的痛点而不是PRD文档，应该深入关注真实业务。掌握现存系统的大量技术和业务细节也是业务架构师的必备知识。 项目管理能力作为工业时代的产物，分工合作融入在互联网项目基因里面。架构师也需要负责几个重大项目才能给自己正名。以架构师角色去管理项目，业务架构能力当然是必备技能。此外，人员管理和成本控制意识也非常重要。 项目管理还意味着要有一个大心脏。重大项目涉及技术攻关、人员变动、需求更改等众多可变因素。面临各种变化，还要在确保目标顺利达成，需要较强的抗压能力。 人员管理需要注意的方面包括：知人善用，优化关系，简化沟通，坚持真理。 知人善用意味着架构师需要了解每个参与者的硬技能和软素质。同时，关注团队成员在项目过程中的表现，按能分配 优化关系意味着管理团队的情绪，毕竟项目的核心是团队，有士气的团队才能高效达成目标。 简化沟通意味着快速决策，该妥协的时候妥协，权责分明。 坚持真理意味着顶住压力，在原则性问题上绝不退步。 成本控制意味着对项目进行精细化管理，需要遵循如下几个原则： 以终为始、确定里程碑。为了达成目标，所有的计划必须以终为始来制定。将大项目分解成几个小阶段，控制每个阶段的里程碑可以大大降低项目失败的风险。 把控关键路径和关键项目。按照关键路径管理理论（CPM）的要求，架构师需要确定每个子项目的关键路径，确定其最早和最晚启动时间。同时，架构师需要关注那些可能会导致项目整体延期的关键节点，并集中力量攻破。 掌控团队成员的张弛度。大项目持续时间会比较长，也包含不同工种。项目实施是一个不断变化的动态过程，在这个过程中不是整个周期都很紧张，不是所有的工种都一样忙。优秀的架构师必须要具备精细阅读整体项目以及快速反应和实时调整的能力。这不仅仅可以大大降低项目成本，还可以提高产出质量和团队满意度。总体来说，“前紧后松”是项目管理的一个重要原则。 项目管理方面的书籍很多。但是，提高业务架构能力同样重要。积极参与大项目并观察别人管理项目的方式也是非常重要的提升手段。 团队管理能力不想做CTO的工程师不是一个好的架构师。走向技术管理应该是工程师的一个主流职业规划。团队管理的一个核心能力就是规划能力，这包括项目规划和人员规划。良好的规划需要遵循如下原则： 规划是利益的博弈。良好的规划上面对得起老板，中间对得起自己，下面对得起团队。在三者利益者寻找平衡点，实现多方共赢考验着管理者的智慧和精细拿捏的能力。 任何规划都比没有规划好。没有规划的团队就是没头的苍蝇，不符合所有人的利益。 规划不是本本主义。市场在变，团队在变，规划也不应该一成不变。 客户至上的是项目规划的出发点。 就人员规划而言，规划需要考量团队成员的能力、绩效、成长等多方面的因素。 市场上有很多规划管理方面的书籍，值得阅读。最优化理论虽然是技术书籍，但它是规划的理论基础，所以不妨多看看翻阅一下。从自我规划开始，多多学习别人的规划也是规划能力提升的重要手段。 总结因为受邀去做一个关于“一边工作，一边学习”的分享，作者花了一段时间去思考和汇总学习方法论，接着每天不断地采集谣言并尝试解惑，再根据个人经验绘制出优秀架构师的能力模型，最后汇集成文。 文章系统性地阐述了学习原则、分析了常见困惑，并制定明确学习目标，期望对工程师们的工作学习有所帮助。需要申明的是，文章内容挂一漏万，所谓的架构师能力模型也是作者的个人观点。欢迎大家在评论中分享自己在学习成长方面的心得。]]></content>
      <tags>
        <tag>learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis开发规范]]></title>
    <url>%2F2019%2F03%2F18%2Fredis-specification%2F</url>
    <content type="text"><![CDATA[一、键值设计1. key名设计 (1)【建议】: 可读性和可管理性 以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id 1ugc:video:1 (2)【建议】：简洁性 保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如： 1user:&#123;uid&#125;:friends:messages:&#123;mid&#125;简化为u:&#123;uid&#125;:fr:m:&#123;mid&#125;。 (3)【强制】：不要包含特殊字符 反例：包含空格、换行、单双引号以及其他转义字符 2. value设计 (1)【强制】：拒绝bigkey(防止网卡流量、慢查询) string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。 反例：一个包含200万个元素的list。 非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞，而且该操作不会不出现在慢查询中(latency可查))，查找方法和删除方法 (2)【推荐】：选择适合的数据类型。 例如：实体类型(要合理控制和使用数据结构内存编码优化配置,例如ziplist，但也要注意节省内存和性能之间的平衡) 反例： 123set user:1:name tomset user:1:age 19set user:1:favor football 正例: 1hmset user:1 name tom age 19 favor football 3.【推荐】：控制key的生命周期，redis不是垃圾桶。建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)，不过期的数据重点关注idletime。 二、命令使用1.【推荐】 O(N)命令关注N的数量例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。 2.【推荐】：禁用命令禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。 3.【推荐】合理使用selectredis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。 4.【推荐】使用批量操作提高效率12原生命令：例如mget、mset。非原生命令：可以使用pipeline提高效率。 但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。 注意两者不同： 1231. 原生是原子操作，pipeline是非原子操作。2. pipeline可以打包不同的命令，原生做不到3. pipeline需要客户端和服务端同时支持。 5.【建议】Redis事务功能较弱，不建议过多使用Redis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot上(可以使用hashtag功能解决) 6.【建议】Redis集群版本在使用Lua上有特殊要求： 1.所有key都应该由 KEYS 数组来传递，redis.call/pcall 里面调用的redis命令，key的位置，必须是KEYS array, 否则直接返回error，”-ERR bad lua script for redis cluster, all the keys that the script uses should be passed using the KEYS array” 2.所有key，必须在1个slot上，否则直接返回error, “-ERR eval/evalsha command keys must in same slot” 7.【建议】必要情况下使用monitor命令时，要注意不要长时间使用。三、客户端使用1.【推荐】避免多个应用使用一个Redis实例 正例：不相干的业务拆分，公共数据做服务化。 2.【推荐】使用带有连接池的数据库，可以有效控制连接，同时提高效率，标准使用方式： 12345678910111213执行命令如下：Jedis jedis = null;try &#123; jedis = jedisPool.getResource(); //具体的命令 jedis.executeCommand()&#125; catch (Exception e) &#123; logger.error("op key &#123;&#125; error: " + e.getMessage(), key, e);&#125; finally &#123; //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。 if (jedis != null) jedis.close();&#125; 下面是JedisPool优化方法的文章: Jedis常见异常汇总 JedisPool资源池优化 3.【建议】高并发下建议客户端添加熔断功能(例如netflix hystrix) 4.【推荐】设置合理的密码，如有必要可以使用SSL加密访问（阿里云Redis支持） 5.【建议】根据自身业务类型，选好maxmemory-policy(最大内存淘汰策略)，设置好过期时间。 默认策略是volatile-lru，即超过最大内存后，在过期键中使用lru算法进行key的剔除，保证不过期数据不被删除，但是可能会出现OOM问题。 其他策略如下： allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。 allkeys-random：随机删除所有键，直到腾出足够空间为止。 volatile-random:随机删除过期键，直到腾出足够空间为止。 volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。 noeviction：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息”(error) OOM command not allowed when used memory”，此时Redis只响应读操作。 四、相关工具1.【推荐】：数据同步redis间数据同步可以使用：redis-port 2.【推荐】：big key搜索redis大key搜索工具 3.【推荐】：热点key寻找(内部实现使用monitor，所以建议短时间使用)facebook的redis-faina 1阿里云Redis已经在内核层面解决热点key问题，欢迎使用。 五 附录：删除bigkey121. 下面操作可以使用pipeline加速。2. redis 4.0已经支持key的异步删除，欢迎使用。 1. Hash删除: hscan + hdel123456789101112131415161718192021public void delBigHash(String host, int port, String password, String bigHashKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; ScanParams scanParams = new ScanParams().count(100); String cursor = "0"; do &#123; ScanResult&lt;Entry&lt;String, String&gt;&gt; scanResult = jedis.hscan(bigHashKey, cursor, scanParams); List&lt;Entry&lt;String, String&gt;&gt; entryList = scanResult.getResult(); if (entryList != null &amp;&amp; !entryList.isEmpty()) &#123; for (Entry&lt;String, String&gt; entry : entryList) &#123; jedis.hdel(bigHashKey, entry.getKey()); &#125; &#125; cursor = scanResult.getStringCursor(); &#125; while (!"0".equals(cursor)); //删除bigkey jedis.del(bigHashKey);&#125; 2. List删除: ltrim12345678910111213141516public void delBigList(String host, int port, String password, String bigListKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; long llen = jedis.llen(bigListKey); int counter = 0; int left = 100; while (counter &lt; llen) &#123; //每次从左侧截掉100个 jedis.ltrim(bigListKey, left, llen); counter += left; &#125; //最终删除key jedis.del(bigListKey);&#125; 3. Set删除: sscan + srem123456789101112131415161718192021public void delBigSet(String host, int port, String password, String bigSetKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; ScanParams scanParams = new ScanParams().count(100); String cursor = "0"; do &#123; ScanResult&lt;String&gt; scanResult = jedis.sscan(bigSetKey, cursor, scanParams); List&lt;String&gt; memberList = scanResult.getResult(); if (memberList != null &amp;&amp; !memberList.isEmpty()) &#123; for (String member : memberList) &#123; jedis.srem(bigSetKey, member); &#125; &#125; cursor = scanResult.getStringCursor(); &#125; while (!"0".equals(cursor)); //删除bigkey jedis.del(bigSetKey);&#125; 4. SortedSet删除: zscan + zrem123456789101112131415161718192021public void delBigZset(String host, int port, String password, String bigZsetKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; ScanParams scanParams = new ScanParams().count(100); String cursor = "0"; do &#123; ScanResult&lt;Tuple&gt; scanResult = jedis.zscan(bigZsetKey, cursor, scanParams); List&lt;Tuple&gt; tupleList = scanResult.getResult(); if (tupleList != null &amp;&amp; !tupleList.isEmpty()) &#123; for (Tuple tuple : tupleList) &#123; jedis.zrem(bigZsetKey, tuple.getElement()); &#125; &#125; cursor = scanResult.getStringCursor(); &#125; while (!"0".equals(cursor)); //删除bigkey jedis.del(bigZsetKey);&#125;]]></content>
      <tags>
        <tag>Redis, specification</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据同步机制设计]]></title>
    <url>%2F2019%2F03%2F17%2Fdata-sync-design%2F</url>
    <content type="text"><![CDATA[数据同步是异地多活的基础，所有具备数据存储能力的组件如：数据库、缓存、MQ等，数据都可以进行同步，形成一个庞大而复杂的数据同步拓扑。 1. 什么是单元化可以理解为将数据划分到多个单元进行存储。”单元”是一个抽象的概念，通常与数据中心(IDC)概念相关，一个单元可以包含多个IDC，也可以只包含一个IDC。本文假设一个单元只对应一个IDC。 考虑一开始只有一个IDC的情况，所有用户的数据都会写入同一份底层存储中，如下图所示： 存在以下几个问题： 不同地区的用户体验不同。一个IDC必然只能部署在一个地区，例如部署在北京，那么北京的用户访问将会得到快速响应；但是对于上海的用户，访问延迟一般就会大一点，上海到北京的一个RTT可能有20ms左右。 容灾问题。这里容灾不是单台机器故障，而是指机房断电，自然灾害，或者光纤被挖断等重大灾害。一旦出现这种问题，将无法正常为用户提供访问，甚至出现数据丢失的情况。 为了解决这些问题，我们可以将服务部署到多个不同的IDC中，不同IDC之间的数据互相进行同步。如下图： 当一个机房挂了之后，我们可以将这个机房用户的流量调度到另外一个正常的机房，由于不同机房之间的数据是实时同步的，用户流量调度过去后，也可以正常访问数据 (故障发生那一刻的少部分数据可能会丢失)。 机房容灾 —— 两地三中心 上面的案例中，我们使用了2个IDC，但是2个IDC并不能具备机房容灾能力。至少需要3个IDC，例如，一些基于多数派协议的一致性组件，如zookeeper，redis、etcd、consul等，需要得到大部分节点的同意。例如我们部署了3个节点，在只有2个机房的情况下， 必然是一个机房部署2个节点，一个机房部署一个节点。当部署了2个节点的机房挂了之后，只剩下一个节点，无法形成多数派。在3机房的情况下，每个机房部署一个节点，任意一个机房挂了，还剩2个节点，还是可以形成多数派。 城市级容灾 —— 三地五中心 在发生重大自然灾害的情况下，可能整个城市的机房都无法访问。一些组件，例如蚂蚁的ocean base，为了达到城市级容灾的能力，使用的是”三地五中心”的方案。这种情况下，3个城市分别拥有2、2、1个机房。当整个城市发生灾难时，其他两个城市依然至少可以保证有3个机房依然是存活的，同样可以形成多数派。 实现单元化，技术层面我们要解决的事情很多，例如：流量调度，即如何让用户就近访问附近的IDC；数据互通，如何实现不同机房之间数据的相互同步。 如何进行数据同步我们就可以考虑自己编写一个组件，其作用类似与mysql slave，也是去主库上拉取binlog，只不过binlog不是保存到本地，而是将binlog转换成sql插入到目标mysql集群中，实现数据的同步。 阿里巴巴开源的canal 美团开源的puma linkedin开源的databus 这些组件都要完成最基本的2件事：从源库拉取binlog并进行解析，我们把这部分功能称之为binlog syncer；将获取到的binlog转换成SQL插入目标库，这个功能称之为sql writer。 为什么划分成两块独立的功能？因为binlog订阅解析的实际应用场景并不仅仅是数据同步 因此，通常我们把binlog syncer单独作为一个模块，其只负责解析从数据库中拉取并解析binlog，并在内存中缓存(或持久化存储)。另外，binlog syncer另外提一个sdk，业务方通过这个sdk从binlog syncer中获取解析后的binlog信息，然后完成自己的特定业务逻辑处理。 显然，在数据同步的场景下，我们可以基于这个sdk，编写一个组件专门用于将binlog转换为sql，插入目标库，实现数据同步，如下图所示： 北京用户的数据不断写入离自己最近的机房的DB，通过binlog syncer订阅这个库binlog，然后下游的binlog writer将binlog转换成SQL，插入到目标库。上海用户类似，只不过方向相反，不再赘述。通过这种方式，我们可以实时的将两个库的数据同步到对端。当然事情并非这么简单，我们有一些重要的事情需要考虑。 如何获取全量+增量的历史数据？通常，mysql不会保存所有的历史binlog。 expire_logs_days = 0，默认不清空 通常，如果binlog如果从来没被清理过，那么binlog文件名字后缀通常是000001，如果不是这个值，则说明可能已经被清理过。当然，这也不是绝对，例如执行”reset master”命令，可以将所有的binlog清空，然后从000001重新开始计数。 反正! 我们知道了，binlog可能不会一直保留，所以直接同步binlog，可能只能获取到部分数据。因此，通常的策略是，由DBA先dump一份源库的完整数据快照，增量部分，再通过binlog订阅解析进行同步。 如何解决重复插入？考虑以下情况下，源库中的一条记录没有唯一索引。对于这个记录的binlog，通过sql writer将binlog转换成sql插入目标库时，抛出了异常，此时我们并不知道知道是否插入成功了，则需要进行重试。如果之前已经是插入目标库成功，只是目标库响应时网络超时(socket timeout)了，导致的异常，这个时候重试插入，就会存在多条记录，造成数据不一致。 因此，通常，在数据同步时，通常会限制记录必须有要有主键或者唯一索引。 如何解决唯一索引冲突？由于两边的库都存在数据插入，如果都使用了同一个唯一索引，那么在同步到对端时，将会产生唯一索引冲突。对于这种情况，通常建议是使用一个全局唯一的分布式ID生成器来生成唯一索引，保证不会产生冲突。 另外，如果真的产生冲突了，同步组件应该将冲突的记录保存下来，以便之后的问题排查。 对于DDL语句如何处理？如果数据库表中已经有大量数据，例如千万级别、或者上亿，这个时候对于这个表的DDL变更，将会变得非常慢，可能会需要几分钟甚至更长时间，而DDL操作是会锁表的，这必然会对业务造成极大的影响。 因此，同步组件通常会对DDL语句进行过滤，不进行同步。DBA在不同的数据库集群上，通过一些在线DDL工具(如gh-ost)，进行表结构变更。 如何解决数据回环问题？INSERT操作假设在A库插入数据，A库产生binlog，之后同步到B库，B库同样也会产生binlog。由于是双向同步，这条记录，又会被重新同步回A库。由于A库应存在这条记录了，产生冲突。 UPDATE操作先考虑针对A库某条记录R只有一次更新的情况，将R更新成R1，之后R1这个binlog会被同步到B库，B库又将R1同步会A库。对于这种情况下，A库将不会产生binlog。因为A库记录当前是R1，B库同步回来的还是R1，意味着值没有变。 在一个更新操作并没有改变某条记录值的情况下，mysql是不会产生binlog，相当于同步终止。下图演示了当更新的值没有变时，mysql实际上不会做任何操作： 然而，这并不意味UPDATE 操作没有问题，事实上，其比INSERT更加危险。 考虑A库的记录R被连续更新了2次，第一次更新成R1，第二次被更新成R2；这两条记录变更信息都被同步到B库，B也产生了R1和R2。由于B的数据也在往A同步，B的R1会被先同步到A，而A现在的值是R2，由于值不一样，将会被更新成R1，并产生新的binlog；此时B的R2再同步会A，发现A的值是R1，又更新成R2，也产生binlog。由于B同步回A的操作，让A又产生了新的binlog，A又要同步到B，如此反复，陷入无限循环中。 DELETE操作同样存在先后顺序问题。例如先插入一条记录，再删除。B在A删除后，又将插入的数据同步回A，接着再将A的删除操作也同步回A，每次都会产生binlog，陷入无限回环。 数据同步架构设计前面的架构中，只涉及到2个DB的数据同步，如果有多个DB数据需要相互同步的情况下，架构将会变得非常复杂。例如： 这个图演示的是四个DB之间数据需要相互同步，这种拓扑结构非常复杂。为了解决这种问题，我们可以将数据写入到一个数据中转站，例如MQ中进行保存，如下： 我们在不同的机房各部署一套MQ集群，这个机房的binlog syncer将需要同步的DB binlog数据写入MQ对应的Topic中。对端机房如果需要同步这个数据，只需要通过binlog writer订阅这个topic，消费topic中的binlog数据，插入到目标库中即可。一些MQ支持consumer group的概念，不同的consumer group的消费位置offset相互隔离，从而达到一份数据，同时供多个消费者进行订阅的能力。 当然，一些binlog订阅解析组件，可能实现了类似于MQ的功能，此时，则不需要独立部署MQ。 数据同步回环问题解决方案1. 往目标库插入不生成binlog在mysql中，我们可以设置session变量，来控制当前会话上的更新操作，不产生binlog。这样当往目标库插入数据时，由于不产生binlog，也就不会被同步会源库了。为了演示这个效果，笔者清空了本机上的所有binlog(执行reset master)]]></content>
      <tags>
        <tag>数据同步, design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo最佳实践]]></title>
    <url>%2F2019%2F03%2F12%2Fdubbo-best-practice%2F</url>
    <content type="text"><![CDATA[1. 分包 将自定义异常也放在API包里，它也是API的一部分 可以在API包中放置一份Spring的引用配置文件，方便使用方 2. 粒度 尽可能大一点，每个方法代表一个完整的功能，否则会出现分布式事务 3. 版本号 定义3位的版本号，第3位表示兼容性升级 当不兼容时，先升级一半的 provider 为新版本，再将消费者全升级为新版本，然后将剩下的一半 provider 升级为新版本 4. 兼容性与枚举值 如果是业务类别，以后明显会有类型增加的，不建议使用Enum，可以用String代替 如果在返回值中用了Enum，并增加了新类型，建议先升级 Consumer 相反，如果在传入参数中新增了类型，建议先升级 Provider 5. 异常 使用异常而不是错误码 如果担心性能问题，可通过 override 掉异常的 fillInStackTrace()方法为空 查询方法里不建议抛出 checked 异常，否则调用方需要 try..catch 且不能有效滴处理 6. 在Provider上尽量多配置Consumer端属性 provider 比服务使用方更清楚服务的性能指标，如调用的超时时间、合理的重试次数等等 Consumer 可使用 Provoider 端的默认配置 12345678&lt;dubbo:service interface="com.alibaba.hello.api.HelloService" version="1.0.0" ref="helloService" timeout="300" retry="2" loadbalance="random" actives="0"/&gt; &lt;dubbo:service interface="com.alibaba.hello.api.WorldService" version="1.0.0" ref="helloService" timeout="300" retry="2" loadbalance="random" actives="0" &gt; &lt;dubbo:method name="findAllPerson" timeout="10000" retries="9" loadbalance="leastactive" actives="5" /&gt;&lt;dubbo:service/&gt; 7. 在Provider上配置合理的Provider参数123456&lt;dubbo:protocol threads="200" /&gt; &lt;dubbo:service interface="com.alibaba.hello.api.HelloService" version="1.0.0" ref="helloService" executes="200" &gt; &lt;dubbo:method name="findAllPerson" executes="50" /&gt;&lt;/dubbo:service&gt; threads，服务线程池大小 executes，一个服务提供者并行执行请求上限，即当Provider对一个服务的并发调用到上限后，新调用会Wait（Consumer可能到超时）。在方法上配置（dubbo:method ）则并发限制针对方法，在接口上配置（dubbo:service），则并发限制针对服务。 8. Dubbo 通讯协议默认采用单一长连接和 NIO 异步通讯，hessian2 序列化，netty 通信，适合小数据量、大并发的服务调用，不适合传送大数据量的服务，比如传文件，传视频等，除非请求量很低。 Dubbo 的设计目的是为了满足高并发小数据量的 rpc 调用，在大数据量下的性能表现并不好，建议使用 rmi 或 http 协议。 9. 多连接配置Dubbo 协议缺省每服务每提供者每消费者使用单一长连接，如果数据量较大，可以使用多个连接。 &lt;dubbo:service connections=”0”&gt; 或 &lt;dubbo:reference connections=”0”&gt; 表示该服务使用 JVM 共享长连接。缺省 &lt;dubbo:service connections=”1”&gt; 或 &lt;dubbo:reference connections=”1”&gt; 表示该服务使用独立长连接。 &lt;dubbo:service connections=”2”&gt; 或&lt;dubbo:reference connections=”2”&gt; 表示该服务使用独立两条长连接。 为防止被大量连接撑挂，可在服务提供方限制大接收连接数，以实现服务提供方自我保护。 &lt;dubbo:protocol name=”dubbo” accepts=”1000” /&gt; 10. 尽快失败11. 防御性编程，但不忽略异常比如：获取程序的版本号，会通过扫描 Manifest 和 jar 包名称抓取版本号，这个逻辑是辅助性的，但代码却不少，初步测试也没啥问题，但应该在整个 getVersion() 中加上一个全函数的 try-catch 打印错误日志，并返回基本版本，因为 getVersion() 可能存在未知特定场景异常，或被其他的开发人员误修改逻辑(但一般人员不会去掉 try-catch)，而如果它抛出异常会导致主流程异常，这是我们不希望看到的。但这里要控制个度，不要随意 try-catch，更不要无声无息的吃掉异常。 12. 配置上管理者信息有问题时便于的找到服务的负责人，至少写两个人以便备份。负责人和组织的信息可以在注册中心的上看到。示例：应用配置负责人、组织&lt;dubbo:application owner=”ding.lid,william.liangf” organization=”intl” /&gt;service配置负责人&lt;dubbo:service owner=”ding.lid,william.liangf” /&gt;reference配置负责人&lt;dubbo:reference owner=”ding.lid,william.liangf” /&gt;]]></content>
      <tags>
        <tag>dubbo, 最佳实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo 服务暴露消费过程解析]]></title>
    <url>%2F2019%2F03%2F11%2Fdubbo-service-implement%2F</url>
    <content type="text"><![CDATA[Dubbo 调用流程 Provider start 启动服务 register 服务到服务中心 Consumer subscribe 向注册中心订阅服务。只订阅使用到的服务，首次会拉取订阅的服务列表，缓存在本地 [异步] notify 当服务发生变化，获取最新的服务列表，更新本地缓存 invoke 调用 Conusmer 直接发起对 Provider 的调用，无需注册中心。而对多个 Provider 的负载均衡，Consumer 通过 cluster 组件实现 count 监控 [异步] Conusmer 和 Provider 都异步通知监控中心 服务暴露和服务引用解析服务 基于 dubbo.jar 内的 META-INF/spring.handles 配置，Spring 在遇到 dubbo 名称空间时，会回调 DubboNamespaceHandler 所有的 dubbo 标签，都会统一用 DubboBeanDefinitionParser 进行解析，将 XML 标签解析成 Bean 对象 在 ServiceConfig#export() 或 ReferenceConfig#get() 初始化时，将 Bean 对象转换成 URL 格式，所有 Bean 属性转成 URL 参数 将 URL 传给 Dubbo SPI，基于 SPI 自适应机制，根据 URL 协议进行不同服务的暴露或引用。 服务暴露官方文开发者指南 - 实现细节给出服务提供者暴露一个服务的详细过程： 远程暴露 在有注册中心，需要注册提供者地址的情况下，ServiceConfig 解析出的 URL 格式为：registry:// registry-host/org.apache.dubbo.registry.RegistryService?export=URL.encode(“dubbo://service-host/{服务名}/{版本号}”) 基于 Dubbo SPI 的自适应机制，通过 URL registry:// 协议头识别，就调用 RegistryProtocol#export() 方法 将具体的服务类名，比如 DubboServiceRegistryImpl，通过 ProxyFactory 包装成 Invoker 实例 调用 doLocalExport 方法，使用 DubboProtocol 将 Invoker 转化为 Exporter 实例，并打开 Netty 服务端监听客户请求 创建 Registry 实例，连接 Zookeeper，并在服务节点下写入提供者的 URL 地址，注册服务 向注册中心订阅 override 数据，并返回一个 Exporter 实例 根据 URL 格式中的 “dubbo://service-host/{服务名}/{版本号}”中协议头 dubbo:// 识别，调用 DubboProtocol#export() 方法，开发服务端口 RegistryProtocol#export() 返回的 Exporter 实例存放到 ServiceConfig 的 List exporters 中 服务引用官方文开发者指南 - 实现细节给出服务提供者暴露一个服务的详细过程： 从注册中心发现引用服务：ReferenceConfig 解析出的 URL 格式为：registry://registry-host:/org.apache.registry.RegistryService?refer=URL.encode(“conumer-host/com.foo.FooService?version=1.0.0”)。 通过 URL 的 registry:// 协议头识别，就会调用 RegistryProtocol#refer() 方法 查询提供者 URL，如 dubbo://service-host/com.foo.FooService?version=1.0.0 ，来获取注册中心 创建一个 RegistryDirectory 实例并设置注册中心和协议 生成 conusmer 连接，在 consumer 目录下创建节点，向注册中心注册 注册完毕后，订阅 providers，configurators，routers 等节点的数据 通过 URL 的 dubbo:// 协议头识别，调用 DubboProtocol#refer() 方法，创建一个 ExchangeClient 客户端并返回 DubboInvoker 实例 由于一个服务可能会部署在多台服务器上，这样就会在 providers 产生多个节点，这样也就会得到多个 DubboInvoker 实例，就需要 RegistryProtocol 调用 Cluster 将多个服务提供者节点伪装成一个节点，并返回一个 Invoker Invoker 创建完毕后，调用 ProxyFactory 为服务接口生成代理对象，返回提供者引用]]></content>
  </entry>
  <entry>
    <title><![CDATA[MySQL全面优化]]></title>
    <url>%2F2019%2F03%2F06%2FMySQL-overall-turning%2F</url>
    <content type="text"><![CDATA[阶段一：数据库表设计对于数据库来说，表结构设计很重要，如果设计不当，会直接影响到网站速度！例如慢查询、数据库死锁等。当然，有测试部门的团队，会做产品测试，找Bug。 阶段二：数据库部署项目初期访问量一般是寥寥无几，此阶段Web+数据库单台部署足以应对在1000左右的QPS（每秒查询率）。考虑到单点故障，应做到高可用性，可采用MySQL主从复制+Keepalived实现双机热备。主流HA软件有：Keepalived（推荐）、Heartbeat。 阶段三：数据库性能优化如果将MySQL部署到普通的X86服务器上，在不经过任何优化情况下，MySQL理论值正常可以处理1500左右QPS，经过优化后，有可能会提升到2000左右QPS。否则，访问量当达到1500左右并发连接时，数据库处理性能可能响应就会慢。那么怎样能让数据库发挥最大性能呢？主要从硬件配置、数据库配置、架构方面着手，具体分为以下： 3.1 硬件配置如果有条件一定要SSD固态硬盘代替机械硬盘，将RAID级别调整为RAID1+0，相对于RAID1和RAID5有更好的读写性能，毕竟数据库的压力主要来自磁盘I/O方面。 Linux内核有一个特性，会从物理内存中划分出缓存区（系统缓存和数据缓存）来存放热数据，通过文件系统延迟写入机制，等满足条件时（如缓存区大小到达一定百分比或者执行sync命令）才会同步到磁盘。也就是说物理内存越大，分配缓存区越大，缓存数据越多。当然，服务器故障会丢失一定的缓存数据。建议物理内存至少富余50%以上。 3.2 数据库配置优化MySQL应用最广泛的有两种存储引擎：一个是MyISAM，不支持事务处理，读性能处理快，表级别锁。另一个是InnoDB，支持事务处理（ACID属性），设计目标是为大数据处理，行级别锁。表锁：开销小，锁定粒度大，发生死锁概率高，相对并发也低。行锁：开销大，锁定粒度小，发生死锁概率低，相对并发也高。为什么会出现表锁和行锁呢？主要为保证数据完整性。举个例子，一个用户在操作一张表，其他用户也想操作这张表，那么就要等第一个用户操作完，其他用户才能操作，表锁和行锁就是这个作用。否则多个用户同时操作一张表，肯定会数据产生冲突或者异常。根据这些方面看，使用InnoDB存储引擎是最好的选择，也是MySQL5.5+版本默认存储引擎。每个存储引擎相关运行参数比较多，以下列出可能影响数据库性能的参数。 公共参数默认值： 123456max_connections = 151# 同时处理最大连接数，建议设置最大连接数是上限连接数的80%左右sort_buffer_size = 2M# 查询排序时缓冲区大小，只对order by和group by起作用，建议增大为16Mopen_files_limit = 1024 # 打开文件数限制，如果show global status like &apos;open_files&apos;查看的值等于或者大于open_files_limit值时，程序会无法连接数据库或卡死 MyISAM参数默认值： 12345678910key_buffer_size = 16M# 索引缓存区大小，一般设置物理内存的30-40%read_buffer_size = 128K # 读操作缓冲区大小，建议设置16M或32Mquery_cache_type = ON# 打开查询缓存功能query_cache_limit = 1M # 查询缓存限制，只有1M以下查询结果才会被缓存，以免结果数据较大把缓存池覆盖query_cache_size = 16M # 查看缓冲区大小，用于缓存SELECT查询结果，下一次有同样SELECT查询将直接从缓存池返回结果，可适当成倍增加此值 InnoDB参数默认值： 12345678910innodb_buffer_pool_size = 128M# 索引和数据缓冲区大小，建议设置物理内存的70%左右innodb_buffer_pool_instances = 1 # 缓冲池实例个数，推荐设置4个或8个innodb_flush_log_at_trx_commit = 1 # 关键参数，0代表大约每秒写入到日志并同步到磁盘，数据库故障会丢失1秒左右事务数据。1为每执行一条SQL后写入到日志并同步到磁盘，I/O开销大，执行完SQL要等待日志读写，效率低。2代表只把日志写入到系统缓存区，再每秒同步到磁盘，效率很高，如果服务器故障，才会丢失事务数据。对数据安全性要求不是很高的推荐设置2，性能高，修改后效果明显。innodb_file_per_table = OFF # 是否共享表空间，5.7+版本默认ON，共享表空间idbdata文件不断增大，影响一定的I/O性能。建议开启独立表空间模式，每个表的索引和数据都存在自己独立的表空间中，可以实现单表在不同数据库中移动。innodb_log_buffer_size = 8M # 日志缓冲区大小，由于日志最长每秒钟刷新一次，所以一般不用超过16M 3.3 系统内核参数优化大多数MySQL都部署在linux系统上，所以操作系统的一些参数也会影响到MySQL性能，以下对Linux内核参数进行适当优化 1234567891011121314151617net.ipv4.tcp_fin_timeout = 30# TIME_WAIT超时时间，默认是60snet.ipv4.tcp_tw_reuse = 1 # 1表示开启复用，允许TIME_WAIT socket重新用于新的TCP连接，0表示关闭net.ipv4.tcp_tw_recycle = 1 # 1表示开启TIME_WAIT socket快速回收，0表示关闭net.ipv4.tcp_max_tw_buckets = 4096 # 系统保持TIME_WAIT socket最大数量，如果超出这个数，系统将随机清除一些TIME_WAIT并打印警告信息net.ipv4.tcp_max_syn_backlog = 4096# 进入SYN队列最大长度，加大队列长度可容纳更多的等待连接在Linux系统中，如果进程打开的文件句柄数量超过系统默认值1024，就会提示“too many files open”信息，所以要调整打开文件句柄限制。重启永久生效：# vi /etc/security/limits.conf * soft nofile 65535* hard nofile 65535当前用户立即生效：# ulimit -SHn 65535 阶段四：数据库架构扩展随着业务量越来越大，单台数据库服务器性能已无法满足业务需求，该考虑增加服务器扩展架构了。主要思想是分解单台数据库负载，突破磁盘I/O性能，热数据存放缓存中，降低磁盘I/O访问频率。 4.1 增加缓存给数据库增加缓存系统，把热数据缓存到内存中，如果缓存中有请求的数据就不再去请求MySQL，减少数据库负载。缓存实现有本地缓存和分布式缓存，本地缓存是将数据缓存到本地服务器内存中或者文件中。分布式缓存可以缓存海量数据，扩展性好，主流的分布式缓存系统：memcached、redis，memcached性能稳定，数据缓存在内存中，速度很快，QPS理论可达8w左右。如果想数据持久化就选择用redis，性能不低于memcached。 4.2 主从复制与读写分离在生产环境中，业务系统通常读多写少，可部署一主多从架构，主数据库负责写操作，并做双机热备，多台从数据库做负载均衡，负责读操作。主流的负载均衡器：LVS、HAProxy、Nginx。怎么来实现读写分离呢？大多数企业是在代码层面实现读写分离，效率高。另一个种方式通过代理程序实现读写分离，企业中应用较少，会增加中间件消耗。主流中间件代理系统有MyCat、Atlas等。在这种MySQL主从复制拓扑架构中，分散单台负载，大大提高数据库并发能力。如果一台从服务器能处理1500 QPS，那么3台就能处理4500 QPS，而且容易横向扩展。有时，面对大量写操作的应用时，单台写性能达不到业务需求。就可以做双向复制（双主），但有个问题得注意：两台主服务器如果都对外提供读写操作，就可能遇到数据不一致现象，产生这个原因是程序有同时操作两台数据库几率，同时的更新操作会造成两台数据库数据发生冲突或者不一致。可设置每个表ID字段自增唯一：auto_increment_increment和auto_increment_offset，也可以写算法生成随机唯一。官方近两年推出的MGR（多主复制）集群也可以考虑下。 4.3 分库分库是根据业务将数据库中相关的表分离到不同的数据库中，例如web、bbs、blog等库。如果业务量很大，还可将分离后的数据库做主从复制架构，进一步避免单库压力过大。 4.4 分表数据量的日剧增加，数据库中某个表有几百万条数据，导致查询和插入耗时太长，怎么能解决单表压力呢？你应该考虑把这个表拆分成多个小表，来减轻单个表的压力，提高处理效率，此方式称为分表。分表技术比较麻烦，要修改程序代码里的SQL语句，还要手动去创建其他表，也可以用merge存储引擎实现分表，相对简单许多。分表后，程序是对一个总表进行操作，这个总表不存放数据，只有一些分表的关系，以及更新数据的方式，总表会根据不同的查询，将压力分到不同的小表上，因此提高并发能力和磁盘I/O性能。分表分为垂直拆分和水平拆分：垂直拆分：把原来的一个很多字段的表拆分多个表，解决表的宽度问题。你可以把不常用的字段单独放到一个表中，也可以把大字段独立放一个表中，或者把关联密切的字段放一个表中。水平拆分：把原来一个表拆分成多个表，每个表的结构都一样，解决单表数据量大的问题。 4.5 分区分区就是把一张表的数据根据表结构中的字段（如range、list、hash等）分成多个区块，这些区块可以在一个磁盘上，也可以在不同的磁盘上，分区后，表面上还是一张表，但数据散列在多个位置，这样一来，多块硬盘同时处理不同的请求，从而提高磁盘I/O读写性能。注：增加缓存、分库、分表和分区主要由程序猿或DBA来实现。 阶段五：数据库维护数据库维护是数据库工程师或运维工程师的工作，包括系统监控、性能分析、性能调优、数据库备份和恢复等主要工作。 5.1 性能状态关键指标专业术语：QPS（Queries Per Second，每秒查询书）和TPS（Transactions Per Second）通过show status查看运行状态，会有300多条状态信息记录，其中有几个值帮可以我们计算出QPS和TPS，如下： 12345678Uptime：服务器已经运行的实际，单位秒Questions：已经发送给数据库查询数Com_select：查询次数，实际操作数据库的Com_insert：插入次数Com_delete：删除次数Com_update：更新次数Com_commit：事务次数Com_rollback：回滚次数 那么，计算方法来了，基于Questions计算出QPS 123mysql&gt; show global status like 'Questions';mysql&gt; show global status like 'Uptime';QPS = Questions / Uptime 基于Com_commit和Com_rollback计算出TPS： 1234mysql&gt; show global status like 'Com_commit';mysql&gt; show global status like 'Com_rollback';mysql&gt; show global status like 'Uptime';TPS = (Com_commit + Com_rollback) / Uptime 另一计算方式： 123基于Com_select、Com_insert、Com_delete、Com_update计算出QPS： mysql&gt; show global status where Variable_name in(&apos;com_select&apos;,&apos;com_insert&apos;,&apos;com_delete&apos;,&apos;com_update&apos;);等待1秒再执行，获取间隔差值，第二次每个变量值减去第一次对应的变量值，就是QPS。 TPS计算方法： 12mysql&gt; show global status where Variable_name in(&apos;com_insert&apos;,&apos;com_delete&apos;,&apos;com_update&apos;);计算TPS，就不算查询操作了，计算出插入、删除、更新四个值即可。 经网友对这两个计算方式的测试得出，当数据库中myisam表比较多时，使用Questions计算比较准确。当数据库中innodb表比较多时，则以Com_* 计算比较准确。 5.2 开启慢查询日志MySQL开启慢查询日志，分析出哪条SQL语句比较慢，支持动态开启： 12345678910111213141516mysql&gt; set global slow-query-log=on # 开启慢查询日志 mysql&gt; set global slow_query_log_file='/var/log/mysql/mysql-slow.log'; # 指定慢查询日志文件位置 mysql&gt; set global log_queries_not_using_indexes=on; # 记录没有使用索引的查询 mysql&gt; set global long_query_time=1; # 只记录处理时间1s以上的慢查询分析慢查询日志，可以使用MySQL自带的mysqldumpslow工具，分析的日志较为简单。mysqldumpslow -t 3 /var/log/mysql/mysql-slow.log # 查看最慢的前三个查询也可以使用percona公司的pt-query-digest工具，日志分析功能全面，可分析slow log、binlog、general log。分析慢查询日志：pt-query-digest /var/log/mysql/mysql-slow.log分析binlog日志：mysqlbinlog mysql-bin.000001 &gt;mysql-bin.000001.sql pt-query-digest --type=binlog mysql-bin.000001.sql 分析普通日志：pt-query-digest --type=genlog localhost.log 5.3 数据库备份备份数据库是最基本的工作，也是最重要的，否则后果很严重，你懂得！高频率的备份策略，选用一个稳定快速的工具至关重要。数据库大小在2G以内，建议使用官方的逻辑备份工具mysqldump。超过2G以上，建议使用percona公司的物理备份工具xtrabackup，否则慢的跟蜗牛似得。这两个工具都支持InnoDB存储引擎下热备，不影响业务读写操作。 5.4 数据库修复有时候MySQL服务器突然断电、异常关闭，会导致表损坏，无法读取表数据。这时就可以用到MySQL自带的两个工具进行修复，myisamchk和mysqlcheck。前者只能修复MyISAM表，并且停止数据库，后者MyISAM和InnoDB都可以，在线修复。注意：修复前最好先备份数据库。 123456789myisamchk常用参数： -f --force 强制修复，覆盖老的临时文件，一般不使用 -r --recover 恢复模式 -q --quik 快速恢复 -a --analyze 分析表 -o --safe-recover 老的恢复模式，如果-r无法修复，可以使用此参数试试 -F --fast 只检查没有正常关闭的表例如：myisamchk -r -q *.MYI 12345678910mysqlcheck常用参数： -a --all-databases 检查所有的库 -r --repair 修复表 -c --check 检查表，默认选项 -a --analyze 分析表 -o --optimize 优化表 -q --quik 最快检查或修复表 -F --fast 只检查没有正常关闭的表例如：mysqlcheck -r -q -uroot -p123456 weibo 5.5 MySQL服务器性能分析 重点关注：id：CPU利用率百分比，平均小于60%正常，但已经比较繁忙了。wa：CPU等待磁盘IO响应时间，一般大于5说明磁盘读写量大。 KB_read/s、KB_wrtn/s 每秒读写数据量，主要根据磁盘每秒最高读写速度评估。 r/s、w/s：每秒读写请求次数，可以理解为IOPS（每秒输入输出量），是衡量磁盘性能的主要指标之一。await：IO平均每秒响应时间，一般大于5说明磁盘响应慢，超过自身性能。util：磁盘利用率百分比，平均小于60%正常，但已经比较繁忙了。 小结由于关系型数据库初衷设计限制，在大数据处理时会显得力不从心。因此NoSQL（非关系型数据库）火起来了，天生励志，具备分布式、高性能、高可靠等特性，弥补了关系型数据库某方面先天性不足，非常适合存储非结构化数据。主流NoSQL数据库有：MongoDB、HBase、Cassandra等。 单纯数据库层面优化效果提升并不多明显，主要还是要根据业务场景选择合适的数据库！]]></content>
      <tags>
        <tag>MySQL, turning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[性能优化checklist]]></title>
    <url>%2F2019%2F03%2F06%2Fperformance-checklist%2F</url>
    <content type="text"><![CDATA[1. 总原则 可扩展性架构，堆机器能不能解决问题是最最优先考虑的问题 去中心化的点对点通信，优于通过中心代理的通信 池化的长连接，优于短连接 二进制数据，优于文本数据 尽量减少交互，一次调用的粗粒度聚合接口 优于 多次调用的细粒度接口 尽量减少交互，批量接口优于循环调用 尽量只交互必要的数据 尽量就近访问 尽量使用缓存 总是设定超时 在合适的场景，并行化执行 在合适的场景，异步化执行 2. 环境准备线下压测服务器的配置要与生产环境一致 2.1 操作系统 调优应包含TCP内核参数，网卡参数及多队列绑定，IO&amp;Swap内核参数，ulimit资源限制等。 2.2 JVM与应用服务器 使用JDK7.0 u80 或 JDK8 最新版。 检查JVM启动参数已按自家规范调优，见《关键业务系统的JVM参数推荐》 检查应用服务器(Tomcat或微服务容器) 已按自家指南调优，如线程数等。 2.3 周边依赖系统 检查数据库，缓存，消息系统，已按自家指南调优。 2.4 后台辅助程序 检查日志收集，系统监控等，已使用最新版本，最优配置。 最好其最大消耗已被控制（通过cgroup，taskset等方式）。 2.5 测试程序 压测工具如JMeter，启动参数要参考真实应用客户端的参数优化（如JVM参数，Netty参数等）。 测试脚本和客户端程序经过review，不存在影响性能的步骤，不存在System.out.println（）等明显的瓶颈。 2.5 流量模型 扇入模型：平时与高峰期的流量估算，各接口的流量比例，响应时间要求 扇出模型：各接口对远程服务、数据库、缓存、消息系统的调用比例，响应时间估算。 3.数据库3.1 拓扑根据扩展性原则考虑： 垂直拆分：按业务将不同的表拆分到不同的库。 水平拆分：水平分库分表。 读写分离：在业务允许的情况下，在从库读取非实时数据。 3.2 Schema 统一的存储引擎，主键策略。 禁用存储过程，函数，触发器，外键约束。 列类型永远越短越好，建议：布尔/枚举：tinyint，日期与时间戳：timestamp或int，char/text/blob: 尽量用符合实际长度的varchar（n），小数及货币：移位转为int 或 decimal，IP地址：int。 索引策略：索引字段的顺序需要考虑字段值去重之后的个数，较多的放前面，合理创建联合索引，避免冗余索引，合理利用覆盖索引等。 3.3 SQL 自家规范应包含： 如禁止多于3表join，禁用子查询 禁止where子句中对字段施加函数，如to_date（add_time）&gt;xxxxx 避免MySQL进行隐式类型转化，如ISENDED&eq;1 与 ISENDED&eq;1 不建议使用%前缀模糊查询，模糊查询较多时建议使用ElasticSearch 根据尽量少数据原则与尽量少交互的原则来设计SQL: 禁止select ＊ 合理的SQL语句，减少交互次数 根据扩展性原则，将负载放在更容易伸缩的应用服务实例上： 尽量不要做数学运算，函数运算, 或者输出格式转换等非必要操作 避免count（＊），计数统计实时要求较强使用memcache或者redis，非实时统计使用单独统计表，定时更新。 甚至排序都是不鼓励的，尽量在应用侧进行。另外避免多余的排序，使用GROUP BY 时，默认会进行排序，当你不需要排序时，可以使用order by null。 联系DBA进行MySQL统计的慢查询的Review，解析SQL查询计划时尽量避免extra列出现：Using File Sort，Using Temporary 3.4 DAO框架 根据尽量少交互与尽量少数据的原则，需使用对SQL完全可控的DAO框架，建议为MyBatis 或 Spring JDBC Template。 必须使用prepareStatement，提升性能与防注入。 根据一切皆有超时的原则，配置SQL执行的超时。可在连接池里设置default值，可在MyBatis的Mapper定义里可设置每个请求的超时，可惜规范是秒级的。 JDBC driver 规范本身不支持异步模式，如果一定要异步，可以像Quasar那样把请求封装成Callable交给另外的线程池执行，但要注意其额外开销。 3.5 事务 不使用事务，连接池设置autocommit，使用其他方式来保持数据一致性。 通过Transaction Annotation控制事务，事务跨度尽量短，把非事务范围内的业务逻辑剔除到被标注的函数之外。 只读事务可以不加事务标注。 3.6 连接池 在分库分表时，根据点对点通信优先的原则，尽量使用客户端分片的实现。功能不满足时才用MyCat中央代理。 推荐使用性能最高HikariCP，或者Druid，不推荐c3p0与DBCP。 连接池的配置： 配置初始值，再联系DBA获得线上数据库支持的连接数，计算最大连接数。 连接有效性检查，只在连接空闲检测时执行，不在拿出和归还连接时执行，最好是直接使用数据的Ping方案，不要配置检查SQL。 根据总是设置超时的原则，配置获取连接超时的时间。 配置合理的空闲连接回收间隔和空闲时间。 4. 缓存4.1 多级缓存 根据缓存原则， 缓存 &gt; 数据库/远程调用 根据就近原则， 堆内缓存 &gt; 堆外缓存 &gt; 集中式缓存 堆内缓存受大小限制，并影响GC 堆内缓存与堆外缓存，分布在每一台应用服务器上，刷新方式比集中式缓存复杂 堆外缓存与集中式缓存，需要序列化/反序列化对象 集中式缓存，有网络传输的成本，特别是数据超过一个网络包的大小。 集中式缓存，一次获取多个键时，在有分区的情况下，需要收发多个网络包。 使用上述条件选择合适的缓存方案，或同时使用多级缓存，逐层回源。 4.2 综述 需要对回源进行并发控制，当key失效时，只有单一线程对该key回源。 基于二进制优于文本数据的原则，JSON的序列化方案较通用与更高的可读性。而对于较大，结构较复杂的对象，基于Kyro，PB，Thrift的二进制序列化方案的性能更高，见后面的序列化方案部分。 4.3 堆内缓存 推荐Guava Cache。 Ehcache较重，性能也较差。更不要使用存在严重bug的Jodd Cache。 GuavaCache： 正确设置并行度等参数。 重载load（）参数，实现单一线程回源。 Guava Cache能后台定时刷新，在刷新的过程中，依然使用旧数据响应请求，不会造成卡顿，但需要重载实现reload（）函数。 Guava Cache同时还支持并发安全版的WeakHashMap。 4.4 堆外缓存 推荐Cassandra的OHC 或者 OpenHFT的Chronical map2。 OHC够简单，其实R大不喜欢Chronical，玩的太深，换个JDK都可能跑不起来。 Chronical map3的license则较不友好，复杂度高且要求JDK8。 其他的Ehcache的Terracota Offheap 一向不喜欢。 4.5 Memcached​客户端： 基于点对点通信优于网关的原则，使用客户端一致性哈希分区。 推荐Spymemcached。 XMemcached 太久没更新，Folsom知名度不高。 注意Spymemcached为单线程单连接架构（一个MemcachedClient只有一条IO线程，与每台Memcached只有一条连接），必要时可多建几个MemcachedClient随机选择，但不要用Commons Pool去封装它，把Spy原本的设计一笔抹杀。 根据在合适场景使用并发的原则，Spymemcached支持异步API。 根据一切皆设超时的原则，可在连接工厂中设置最大超时数，默认值两秒半太长。 数据结构： Key必须设置失效时间。 Key必须有长度限制。 Value长度需要控制，以不超过1个网络包（MTU，千五字节）为佳。 Value大小差别较大的缓存类型，建议拆分到不同MC集群，否则会造成低使用率并且产生踢出。 4.6 Redis as CacheRedis拓扑： 基于点对点通信优于网关的原则，使用如下两种拓扑 无HA的普通分片：由Jedis客户端完成分片路由。 Redis Cluster：同样由Jedis客户端封装分区，跳转，重试等逻辑，需要使用最新版的Jedis版本。 服务端： Cache节点与持久化数据节点不要混用。 Cache节点是否需要持久化要仔细衡量。 由于Redis是单线程，使用taskset进行cpu绑定后可以有效地利用cpu，并在单机上运行多个redis实例。 对热键进行监控，发现不合理的热健要进行分拆等处理。 客户端： Jedis基于Apache Commons Pool进行了多连接的封装，正确配置总连接数不超过Redis Server的允许连接数。 性能考虑，空闲连接检查不要过于频繁（建议30秒以上），另不要打开testOnBorrow等测试参数。 根据一切皆有超时的原则，设定统一的调用超时，获取连接的最长等待时间参数，重试次数 根据在合适的地方异步的原则，Jedis本身没有异步API，只在PipleLine模式下支持。 数据结构： 必须对Key设置失效时间。 Key必须有长度限制。 Value长度需要控制，不要超过一个网络包。另外集合的元素不要超过五千个。 除了使用序列化的String，同样可以考虑用Hash来存储对象，注意内部结构为ZipList与HashTable时，hmget 与hgetall的不同复杂度。 命令： 慎用的命令：LANGE（0, -1）, HGETALL, SMEMBER 高复杂度的命令: ZINTERSTORE, SINTERSTORE, ZUNIONSTORE, ZREM 尽量使用多参数的命令：MGET/MSET，HMGET/HMSET, LPUSH/RPUSH, LRANGE 尽量使用pipeline 根据减少交互的原则，必要时可使用Redis的Lua脚本 5. 服务调用5.1 接口设计 尽量少交互的原则： 支持批量接口，最大的批量，综合考虑调用者的需求与 后端存储的能力。 支持粗粒度接口，在支持原子细粒度接口的同时，支持粗粒度接口/聚合层接口，将多个数据源的获取，多个动作，合并成一个粗粒度接口。 尽量少数据的原则： 在提供返回所有数据的大接口的同时，提供只提供满足部分调用者需要的轻量接口。 最好再提供能定制返回字段的接口。 二进制数据优于文本数据 同样是一个简单通用性，与性能的选择，特别是大数据量时。 5.2 RESTful仅以Apache HttpClient为例，大部分Restful框架都是对Apache HttpClient的封装。 另外OkHttp也值得看看。 不要重复创建ApacheClient实例，使用连接池，正确配置连接池的连接数。 连接池总是有锁，针对不同的服务，使用不同的Apache HttpClient实例，将锁分散开来。在高并发时比使用全局单例的ApacheClient，有很大的性能提升。 根据一切调用皆有超时的原则，每次调用均设置超时时间。RequestConfig里共有Connect Timeout, Socket Timout 和 从Pool中获取连接的Timeout三种超时。 需要异步或并行的场景，使用Apache AsyncHttpClient项目。但要注意AsyncHttpClient项目，检查调用超时的周期默认为1秒。 5.3 自家RPC框架每家的RPC框架特性不同，但考虑点都类似。 6.消息异步6.1 选型 根据就近原则，可以先尝试用JVM内的队列来解决，然后再考虑中央消息系统。 可靠性要求极高的选择RabbitMQ，可支持单条消息确认。 海量消息场景，允许极端情况下少量丢失则使用Kafka。 6.2 Kafka 在同步和异步之间做好权衡，异步批量发送可以极大的提高发送的速度。 关注消费者如下参数：commitInterval(自动提交offset间隔)，prefetchSize(指单次从服务器批量拉取消息的大小)，过大和过小都会影响性能，建议保持默认。 6.3 RabbitMQ 根据扩展性原则，RabbitMQ本身没有分片功能，但可以在客户端自行分片。 如非必要情况，应该保持默认的同步发送模式。 关注消费者如下参数：autocommit(自动提交确认，默认false) ，在消息拉取到本地即认为消费成功，而不是真正消费成功后提交。prefetchCount(预取消息条数，默认64条) 生产者在必要时也可以临时降级不进行confirm。 7. 日志7.1 综述 Log4j2或logback，不要再使用Log4j。 除了应用启停日志，不允许使用超慢的System.out.println() 或 e.printStack(); 严格控制日志量避免过高IO，对海量日志，应该有开关可以动态关停。 如果可能出现海量异常信息，可仿效JDK的优化，用RateLimiter进行限流，丢弃过多的异常日志。 7.2 内容 严格控制日志格式，避免出现消耗较大的输出如类名，方法名，行号等。 业务日志不要滥用toJSONString（）来打印对象，尽量使用对象自身的toString()函数，因为JSON转换的消耗并不低。 在生产环境必定输出的日志，不要使用logger.info（”hello {}”, name）的模式，而是使用正确估算大小的StringBuilder直接拼装输出信息。 7.3 异步日志 同步日志的堵塞非常严重，特别是发生IO的时候，因此尽量使用异步日志。 Logback的异步方案存在一定问题，需要正确配置Queue长度，阀值达到多少时丢弃Warn以下的日志，最新版还可以设置如果队列已满，是等待还是直接丢弃日志。 如果觉得Logback的异步日志每次插入都要询问队列容量太过消耗，可重写一个直接入列，不成功则直接丢弃的版本。 8. 工具类8.1 JSON 使用Jackson 或 FastJSON。GSON的性能较前两者为差，尤其是大对象时。 超大对象可以使用Jackson或FastJSON的流式 API进行处理。 将不需要序列化的属性，通过Annotation排除掉。 FastJson： 尽量使用最新的版本。 SerializerFeature.DisableCircularReferenceDetect 关闭循环引用检查。 Jackson： 设置参数，不序列化为空的属性，等于默认值的属性。 除了jackson-databinding，可试用简化版没那么多花样的jackon-jr。 8.2 二进制序列化需要定义IDL的PB与Thrift，不需要定义的Storm等用的Kyro 都可选择，其他一些比较旧就算了。 8.3 Bean复制在VO，BO之间复制时，使用Orika（生成代码） 或 Dozer（缓存反射），不要使用需要每次进行反射的Apache BeanUitls，Spring BeanUtils。 8.4 日期JDK的日期类与字符串之间的转换很慢且非线程安全。 继续用Java日期不想大动作的，就用CommonsLang的FastDateFormat。 能大动作就用joda time，或者JDK8的新日期API。 9.Java代码优化 与 业务逻辑优化参考《Java调优指南1.8版》，对内存使用，并发与锁等方面进行优化。 规则前置，将消耗较大的操作放后面，如果前面的条件不满足时可。 另外前面提到的一堆原则，比如尽量缓存，尽量少交互，尽量少数据，并行，异步等，都可在此使用。]]></content>
      <tags>
        <tag>checklist, performance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务调用超时处理]]></title>
    <url>%2F2018%2F12%2F11%2Ftimeout-design%2F</url>
    <content type="text"><![CDATA[1. 同步超时 请求超时，客户端给服务端发送请求时超时，此时服务端没有收到客户端的请求； 服务端内部超时，服务端可能存在DB操作、IO操作、调用其他服务超时； 响应超时，服务端给客户端返回响应时超时，此时服务端已经处理了请求。 客户端无论是何种超时，对于客户端来说都是透明的，即客户端无法知道具体发生超时的点。客户端对于超时的处理，有如下两种常见方法： 查询，通过主动查询去拉取超时请求的状态。这种方法需要服务端提供查询接口，并且是根据客户端生成的请求流水号作为查询的条件，因为同一个服务或者接口可能会存在多个调用方，这就需要服务端能够唯一标识某一个客户端请求。 重试，需要设置重试梯度（5s,30s,1min…），以及重试次数的阈值(最多重试的次数)。另外，客户端的重试需要服务端支持幂等（多次执行和只执行一次的效果一样）。 服务端对于①.请求超时和③.响应超时服务端是无法感知的，也就没法进行处理。而在②.服务端内部超时时服务端应该快速失败，立即响应客户端。如果是服务端调用其他服务(例如，服务C)超时，服务端除了快速失败之外，还需要调用服务C的冲正操作。 服务C的冲正接口需要能够判断之前是否接收过服务端超时的请求，如果接收过请求并做了处理，则应该执行反向的回滚操作，如果没有接收过，则忽略冲正请求。 2. 异步超时 请求超时，客户端给服务端发送请求时超时，此时服务端没有收到客户端的请求； 服务端内部超时，服务端可能存在DB操作、IO操作、调用其他服务超时； 同步响应超时，服务端同步返回响应给客户端超时，此时服务端已经接收了请求。 异步响应超时，服务端异步返回响应给客户端超时，此时服务端已经处理完了请求。 客户端此时客户端的处理方式和同步调用时客户端的方式一样。 服务端服务端对于请求超时和同步响应超时无能为力，不过对于异步响应超时、服务端内部超时是可以处理的，具体如下： 对于异步通知超时可以采用最大努力通知，服务端要求客户端在收到异步通知时明确回应服务端接收成功，如果服务端没有收到客户端的回应，服务端重发异步结果。关于异步结果通知超时处理具体可以参考微信支付中的支付结果通知文档 服务端内部超时，我们应该尽最大努力使得用户的请求处理成功。如果是服务端调用其他服务超时，可以通过查询其他服务，根据查询到的结果再进行后续的操作，并将最终的结果通过异步通知反馈给客户端。 消息队列超时 生产者投递消息超时，对应上图的①,②； 消费者消费消息超时。 生产者超时生产者超时一般都采用可靠消息服务来解决 消费者超时一般在开发过程中，基本上都可以认为只要生产者将消息投递到了MQ中间件的服务端，那么该消息就一定会被消费者所消费，这主要是基于对消息中间件的信赖。一般而言，各大MQ中间件都有一定的机制来保障其到消费者之间的消息不会丢失。不同MQ中间件的消费者机制有所不同，大概可以概括成以下两类： 一旦消费者从消息中间件取走消息（无论是推模式或者拉模式都一样），不管消费者是否成功处理，消息中间件都会将该条消息删除； 消费者从消息中间件取走消息之后，消息中间件不会立马将该消息删除，必须要等到消费者告知消息中间件已经处理完了该消息后，消息中间件才会将消息进行删除。 所以在使用消息中间件的时候，我们必须得清楚这个消息中间件产品，它消息消费的具体逻辑是怎样的。]]></content>
      <tags>
        <tag>timeout, design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web安全开发规范]]></title>
    <url>%2F2018%2F11%2F23%2Fweb-security-specification%2F</url>
    <content type="text"><![CDATA[1. 编码安全1. 输入验证 说明 检查项 概述 任何来自客户端的数据，如URL和参数、HTTP头部、 JS戓其他嵌入代码提交的信息都属于不可信数据 白名单 能使用白名单就使用白名单 黑名单 不可信数据中包含不良输入字符时,如空字节(%00)、换行符(%0d,%0a,\r, \n)、路径字符(…/ 或 …)等,建议直接阻止该数据,若需要接受该数据,则应做不同方式的净化处理 规范化 不可信数据的净化和校验前置进行规范化,如将目录遍历(./或)等相对路径转化成绝对路径URL解码等 净化 不可信数据需实施各种净化处理时,应彻底删除恶意字符,只留下已知安全的字符,或者在处理前对它们进行适当编码或”转义”,如数据输出到页面时对其进行HTML编码可防止脚本攻击 合法性校验 不可信数据的合法性校验包括:数据类型如字符.数字、日期等特征;数据范围;数据长度等 防范SQL注入 不可信数据进入后端数据库操作前,使用参数化查询来处理,避免出现SQL注入 文件校验 不可信数据为解压缩的文件时,如果文件位于服务目录外或文件大小超过限制,应拒绝处理 访问控制 不可信数据通过上述校验后,还应确认所提交的内容是否与用户的身份匹配,避免越权访问 2. 输出验证 说明 检查项 概述 考虑目标编译器的安全性，对所有输出字符进行正确编码与数据脱敏 编码场景 不可信数据输出到前后端页面时,根据输出场景对其进行相关编码,如HTML实体编码、UR编码 净化场景 针对操作系统命令、SQL和LDAP查询,净化所有输出的敏感信息,如银行卡、手机号、系统信息等 3. SQL注入1234567let querySQL = ` SELECT * FROM user WHERE username='$&#123;username&#125;' AND psw='$&#123;password&#125;'`;// 接下来就是执行 sql 语句... 恶意攻击者输入的用户名是 zoumiaojiang’ OR 1 = 1 –，密码随意输入 说明 检查项 概述 用户的输入参数进入SQL操作前,对输入进行合法性校验 参数化处理 用参数化查询(Java用 PreparedStatement,C#用 Sqlparameter)方法对敏感字符如”进行转义,然后再进行SQL操作 最小化授权 为每个应用配置最小化数据库操作权限,禁止用管理员权限进行数据库操作,限制操作连接数 敏感数据加密 敏感信息都采用了加密、哈希或混淆等方式进行保密存储,降低可能漏洞带来的数据泄露风险 禁止错误回显 禁止系统开启 Debug模式或异常时返回包含敏感信息的提示,建议使用自定义的错误信息模板异常信息应存放在日志中用于安全审计 4. XSS跨站 Cross Site Script 持久型XSS 非持久型XSS 基于字符集的 XSS 说明 检查项 输入校验 对输入的数据进行过滤和转义,包含但不限于&lt;&gt;”9%0&amp;+\V”等危险特殊字符 页面渲染的所有内容或者渲染的数据都必须来自于服务端。前端渲染的时候对任何的字段都需要做 escape 转义编码。不一定来源于 URL，refferer，forms 等，还有可能来源于数据库中读出来的数据 输出编码 输入数据输出到不同场景中进行不同形式的编码,如输出到HTML标签中则进行HTML编码输出到URL中则进行URL编码,输出到JS中则行 Script编码,输出到 CSS中则进行CSS编码 4. XML注入 说明 检查项 输入校验 在XML文档内部或外部引用数据时,过滤用户提交的参数,如&lt;、&gt;&amp;等特殊字符。禁止加载外部实体,禁止报错 输出编码 建议对XML元素属性或者内容进行输出转义 5. CSRF跨站请求伪造Cross-Site Request Forgery 盗用你的登录身份，可以理解为有一个小偷在你配钥匙的地方得到了你家的钥匙，然后拿着钥匙去你家想偷什么偷什么 说明 检查项 Token使用 在非 GET 请求中增加 token。在重要操作的表单中增加会话生成的 Token字段一次一用,提交后在服务端校验该字段 二次验证 在关键表单提交时,要求用户进行二次身份验证如密码、短信验证码等 Referer验证 检验用户请求中 Referer:字段是否存在跨域提交的情况 2. 逻辑安全1. 身份验证 说明 检查项 概述 所有对非公开的网页和资源的访问,必须在后端服务上执行标准的、通用的身份验证过程 提交凭证 用户凭据必须经过加密且以POST方式提交,建议用HTTPS协议来加密通道、认证服务端 错误提示 安全地处理失败的身份校验,如使用”用户名或密码错误”来提示失败,防止泄露过多信息 异常处理 登录入口应具有防暴力或撞库猜解(利用已泄露的密码字典进行批量登录尝试)的措施,超过1次验证失败自动启用图灵测试,超过多次验证失败自动启用账户锁定机制限制其访问 二次验证 在执行关键操作(如账户密码修改、资料更新、交易支付等)时,先启动图灵测试,再对用户身份进行二次验证。交易支付过程还应该形成完整的证据链,待交易数据应经过发起方数字签名 多因子验证 高度敏感或核心的业务系统,建议使用多因子身份验证机制,如短信验证码、软硬件 Token等。 2. 短信验证 说明 检查项 验证码生成 复杂度至少6位数字或字母,一次一用,建议有效期不超过180秒 验证码限制 前后端设置用户获取频率为60秒一次,建议每个用户每天获取的短信最多10条 安全提示 增加安全提示:至少含本次操作的功能、验证码发送编号、是否是个人自己操作的风险等信息 凭证校验 禁止在响应中返回验证码,服务器端同时校验密码、短信验证码等凭证信息,防止出现多阶段认证绕过的漏洞 3. 图灵测试 说明 检查项 验证码生成 复杂度至少4位数字或字母,或者采用拼图等验证方式,一次一用,建议有效期不超过180秒 验证码使用 建议从用户体验和安全角度出发,可设计为当用户输错1次密码后自动弹出验证码输入框验证 验证码校验 禁止在响应中返回验证码,验证码校验应在服务端进行 4. 密码管理 说明 检查项 密码设置 密码设置时,应该满足8位及以上长度,含大小写字母、数字及特殊字符等的要求。用户密码设置必须经过后端验,不允许设置不满定复杂度要求的敏感密码 密码存储 用户密码存储时,应采用哈希算法(如SHA1)计算用户密码和唯一随机盐值(Salt)的摘要值保存其摘要和Sat值,建议分开存储这两个值 密码修改 用户修改密码时,修改操作需要通过手机号或者邮箱地均进行一次身份验证。密码变更时,应短信或者邮件通知如用户是否是本人操作,告知其安全风险 密码找回 用户密码找回时,后端需要对注册手机号或邮箱进行二次验证,验证码和验证链接应发送至预先注册的地址,并设置有效期以防止暴力破解。密保问题,应当支持尽可能随机的问题提问 密码使用 应用开发中禁止设置万能密码、硬编码明文的密 码、使用数据库管理员账户操作、不同用户公用账户操作或者将密码输出到日志文件或者控制台 5. 会话安全 说明 检查项 防止会话劫持 在应用程序进行身份验证时,建议持续使用HTTPS连接,认证站点使用HTTPS协议。如果连接是从防止会话劫持HTTP跳转到HTTPS,需要重新生成会话标识符。禁止在HTTP和HTTPS之间来回转换,这可能会导致会话被劫持 会话标识符安全 设置会话 Cookie时,正确设置” Httponly’属性(禁止脚本等读取 Cookie信息)” Secure’属性(禁止Cookie通过HTTP连接传递到服务器端进行验证);” Domain”属性(跨域访问时可指定的授权访问域名),”Path”属性(授权可访问的目录路径) 防止CSRF攻击 服务器端执行了完整的会话管理机制,保证每个会话请求都执行了合法的身份验证和权限控制 会话有效期 会话应在平衡风险和功能需求的基础上设置有效期。定期生成一个新的会话标识符并使上一个会话标识符失效,这可以缓解那些因原会活标识符被盗而产生的会话劫持风险 会话注销 注销功能应用于所有受身份验证保护的网页,用户会话注销登出后应立即清理会话相关信息,终止相关的会话连接 6. 访问控制 说明 检查项 控制管理 限制只有授权的用户才能访问受保护的URL、文件、服务、应用数据、配置等 接口管理 限制只有授权的外部应用程序或接口才能访问受保护的本地程序或资源等 权限变更 当权限发生变更时,应记录日志,并通知用户是否是本人操作,告知存在的安全风险 7. 文件上传安全 说明 检查项 身份校验 进行文件上传时,在服务端对用户的身份进行合法性校验 合法性校验 进行文件上传时,在服务端对文件属性进行合法性校验,白名单形式检查文档类型(如文件的后缀名、文件头信息校验等)和大小(图片校验长、宽和像素等) 存储环境设置 进行文件保存时,保存在与应用环境独立的文档服务器中(配置独立域名),保存的目录权限应设置为不可执行 隐藏文件路径 进行文件保存时,成功上传的文件需要进行随机化重命名,禁止给客户端返回保存的路径信息 文件访问设置 进行文件下载时,应以二进制形式下载,建议不提供直接访问(防止木马文件直接执行) 8. 接口安全 说明 检查项 网络限制 调用方网络限制,比如通过防火墙、主机host和Nginx deny等技术措施进行校验 身份认证 调用方身份认证,比如key、 secret、证书等技术措施进行校验,禁止共享凭证 完整性校验 调用的数据安全,对全部参数使用SHA1等摘要运算进行数字签名,识别数据被篡改 合法性校验 调用的参数检查,如参数是否完整,时间戳和Token是否有效,调用权限是否合法等 可用性要求 调用的服务要求,调用满足等幂性即保持数据一致性,对调用频率和有效期进行限制 异常处理 调用的异常处理,调用行为实时检测,发现异常及时阻拦 4. 数据安全1. 敏感信息 说明 检查项 敏感信息传输 敏感信息传输时,禁止在GET请求参数中包含敏感信息,如用户名、密码、卡号等。建议为所有敏感信息采用TSL加密传输 客户端保存 客户端保存敏感信息时,禁止其表单中的自动填充功能、以明文形式保存敏感信息 服务端保存 服务端保存敏感信息时,禁止在程序中硬编码敏感信息,明文存储用户密码、身份证号、银行卡号、持卡人姓名等敏感信息,临时写入内存或文件中的敏感数据,应及时清除和释放 敏感信息维护 敏感信息维护时,禁止将源码或SQL库上传到开源平台或社区,如 Github、开源中国等 敏感信息展示 敏感信息展示时,如果是展示在web页面上,应在后端服务器上进行敏感字段的脱敏处理 2. 日志规范 说明 检查项 记录原则 确保日志记录包含了重要的应用事件,但禁止保存敏感信息,如会话标识,账户密码、证件等 事件类型 记录所有的身份验证、访问操作、数据变更、关键操作、管理功能、登出记录等事件 事件要求 要记录时间、IP地址和用户账户(如果已通过验证) 日志保护 日志受到严格保护,避免未授权的读取或写入访问 3. 异常处理 说明 检查项 容错机制 在应用实现时应包含完整的功能异常捕获机制如try-catch块,典型位置:文件、网络、数据库、命令操作等。一旦出现异常,应该在日志中完整记录异常的发生时间、代码位置、报错详情、触发错误的可能用户等,重要系统的严重异常应该有报警的机制,及时通知系统运营者及时排查并修复 自定义错误信息 禁止在异常中系统、应用服务器的指纹信息，禁止返回任何系统生成的消息或其他调试信息 隐藏用户信息 禁止在系统异常时泄露用户的隐私信息,典型的有:身份信息、个人住址、电话号码、银行账号、通讯记录、定位信息等 隐藏系统信息 禁止在系统异常时泄露系统的敏感信息(用户账户和密码、系统开发密钥、系统源代码、应用架构、系统账户和密码、网络拓扑等) 异常状态恢复 方法发生异常时要恢复到之前的对象状态,如业务操作失败时的回滚操作等,对象修改失败时要恢复对象原来的状态,维持对象状态的一致性 5. 主机安全1. I/O操作 说明 检查项 共享环境文件安全 在多用户系统中创建文件时应指定合适的访问许可,以防止未授权的文件访问,共享目录中文件的读/写/可执行权限应该使用白名单机制,实现最小化授权 数据访问检查 防止封装好的数据对象被未授权使用,设置合理的数据缓存区大小以防止耗尽系统资源 应用文件处理 应用程序运行过程中创建的文件,需设置访问权限(读、写、可执行),临时文件使用完毕及时删除 2. 运行环境 说明 检查项 最小化开放端口 关闭操作系统不需要的端口和服务 后台服务管理 后台(如数据缓存和存储、监控、业务管理等)限内部网络访问,开放在公网的必须设置身份验证和访问控制 环境配置 使用安全稳定的操作系统版本、Web股务器软件各种应用框架、数据库组件等 敏感代码处理 将客户端敏感代码(如软件包签名、用户名密码校验等)都放在o等软件包中防止篡改 关闭调试通道 生产代码不包含任何调试代码或接口 通信安全 配置网站的HTTPS证书或其它加密传输措施 6. DDoS 攻击Distributed Denial of Service 我开了一家店。平时门庭若市，生意特别红火，而对面二狗家的火锅店却无人问津。二狗为了对付我，想了一个办法，叫了五十个人来我的火锅店坐着却不点菜，让别的客人无法吃饭。 网络层 DDoSSYN Flood 攻击 TCP 三次握手、慢型 DDoS 攻击 网络层 DDoS 防御流量清洗、负载均衡、限制SYN 半连接数目、缩短 SYN 半连接的 Timeout 时间、限制单 IP 请求频率、禁止 ICMP 包、加钱堆机器、CDN分流隐藏IP 应用层 DDoS目的就是耗尽你的带宽 恶意刷消耗资源比较多的页面 HTTP 慢速连接攻击 设置一个较大的 Conetnt-Length，每次只发送很少的字节，让服务器一直以为 HTTP 头部没有传输完成，这样连接一多就很快会出现连接耗尽。 应用层 DDoS 防御 判断 User-Agent 字段（不可靠，因为可以随意构造） 针对 IP + cookie，限制访问频率（由于 cookie 可以更改，IP 可以使用代理，或者肉鸡，也不可靠) 关闭服务器最大连接数等，合理配置中间件，缓解 DDoS 攻击。 请求中添加验证码，比如请求中有数据库操作的时候。 编写代码时，尽量实现优化，并合理使用缓存技术，减少数据库的读取操作。 加钱堆机器。。 应用层 DDoS 防御的核心就是区分人与机器（爬虫） 利用 XSS，借刀杀人 举个例子，如果 12306 页面有一个 XSS 持久型漏洞被恶意攻击者发现，只需在春节抢票期间在这个漏洞中执行脚本使得往某一个小站点随便发点什么请求，然后随着用户访问的增多，感染用户增多，被攻击的站点自然就会迅速瘫痪了。 7. 流量劫持当用户访问 baidu.com 的时候，给你展示的并不是或者不完全是 baidu.com 提供的 “内容” DNS 劫持电脑中毒，被恶意篡改了路由器的 DNS 配置 HTTP 劫持 不法运营商和黑产勾结能够截获 HTTP 请求返回内容，并且能够篡改内容，然后再返回给用户，从而实现劫持页面，轻则插入小广告，重则直接篡改成钓鱼网站页面骗用户隐私。 全站改造成 HTTPS]]></content>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链表相交问题]]></title>
    <url>%2F2018%2F11%2F06%2Flinkedlist-intersect%2F</url>
    <content type="text"><![CDATA[1. 如何判断一个链表是否有环，如果有，则返回第一个进入环的节点，没有则返回null 设置两个指针 pLow, pFast, 都从第一个节点出发 pLow每次前进一个节点 pFast每次前进两个节点 如果pFast遇到了null节点, 则说明链表无环, 返回null 如果pLow和pFast相遇, 则说明链表有环 确定第一个进入环的节点: 记从头节点到入环节点的距离为x 入环节点到pLow和pFast相遇节点的距离为y pLow到相遇节点走过的距离为s, 则由 s = x + y 记环的长度为r, 则pFast到相遇时走过的距离为 s + nr, n &gt;= 1 因为pFast走过的距离为pLow的两倍, 则有s + nr = 2s则可推出 s = nr -&gt; x + y = nr -&gt; x = nr - y 由以上公式可得到, 当一个指针p1从头节点触发, 一个指针p2从相交节点出发, p1走过x的距离时, p2走过nr - y的距离, 又因为p2离相交点的距离为y(此处可画图理解), 所以当p1与p2相遇时, 必然在相交点处 2. 如何判断两个无环链表是否相交，相交则返回第一个相交节点，不相交则返回null 得到链表1和链表2的长度, 分别记为 len1, len2, 假设 len1 &gt; len2 p1指向链表1的头节点, p2指向链表2的头节点 p1先移动 len1 - len2的距离 之后p1和p2同时移动, 并比较两个指针指向的节点是否相同, 如果相同,则说明两个链表相交, 返回该节点. 如果不相同, 继续移动, 直到链表结尾, 说明两个链表不相交. 3. 如何判断两个有环链表是否相交，相交则返回第一个相交节点，不相交则返回null 先根据问题一的算法, 找到两个有环链表的入环节点. 分为三种情况 case 1: 两个链表的入环节点相同 两个链表相交入环节点作为尾部节点, 转换为问题二. case 2: 如果两个链表的入环节点不同 固定一个入环节点, 从另一个入环节点出发, 遍历环一周, 如果遇到第一个入环节点, 则两个链表相交, 返回任意一个入环节点即可. case 3: 如果遍历环一周, 没有遇到第一个入环节点, 则两个链表不相交.]]></content>
      <tags>
        <tag>linkedlist, algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo的问题与坑]]></title>
    <url>%2F2018%2F11%2F06%2Fdubbo-trouble%2F</url>
    <content type="text"><![CDATA[问题与坑0. dubbo中的反序列化异常：构造函数抛出java.lang.NullPointerException？1. 同时配置了 XML 和 properties 文件，则 properties 中的配置无效只有 XML 没有配置时，properties 才生效。 2. dubbo 缺省会在启动时检查依赖是否可用，不可用就抛出异常，阻止 spring 初始化完成，check 属性默认为 true。测试时有些服务不关心或者出现了循环依赖，将 check 设置为 false 3. 服务注册不上检查 dubbo 的 jar 包有没有在 classpath 中，以及有没有重复的 jar 包 检查暴露服务的 spring 配置有没有加载 在服务提供者机器上测试与注册中心的网络是否通 4. 出现 RpcException: No provider available for remote service 异常表示没有可用的服务提供者， a. 检查连接的注册中心是否正确 b. 到注册中心查看相应的服务提供者是否存在 c. 检查服务提供者是否正常运行 5. 出现” 消息发送失败” 异常通常是接口方法的传入传出参数未实现 Serializable 接口。 6. Dubbo 在Telnet下的bug1.目前使用的dubbo-2.5.3方法重载存在问题，判断逻辑存在bug，导致选择方法存在错误，不能正常使用Telnet命名 查看官方issue：https://github.com/alibaba/dubbo/commit/27917f2e86bbd97ee047d69817730a57bdf5ad6b#diff-025ea1457d9d7d70588648a38beba029 2.解决方法： 升级到2.5.4 Telnet文本协议调用dubbo接口 dubbo传输对象使用Transient标识后,有序列化bug! 虽然标识了Transient关键字,还是可以得到该对象，有安全漏洞！]]></content>
      <tags>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot 自动配置原理]]></title>
    <url>%2F2018%2F10%2F16%2Fspringboot-autoconfig%2F</url>
    <content type="text"><![CDATA[1. 快速入门工程1. 配置属性 YAML 注意键和值由冒号及空白字符分开。强调下，空白字符是必须的 .properties 文件默认编码方式是 iso-8859 ，Spring Boot 应用以 UTF-8 的编码方式读取，就导致出现乱码问题 2. 创建属性类1234567891011121314151617181920212223import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Component;/** * 书属性 */@Componentpublic class BookProperties &#123; /** * 书名 */ @Value("$&#123;demo.book.name&#125;") private String name; /** * 作者 */ @Value("$&#123;demo.book.writer&#125;") private String writer; // ... 省略 getter / setter 方法&#125; @Component 注解 @Component 对类进行标注，职责是泛指组件 Bean ，应用启动时会被容器加载并加入容器管理。常见的 @Controller、@Service 、@Repository 是 @Component 的分类细化组件，分别对应控制层、服务层、持久层的 Bean。 @Value 注解 @Value 对 Bean 的字段或者方法参数进行标注，职责是基于表达式给字段或方法参数设置默认属性值。通常格式是注解 + SpEL 表达式，如 @Value(“SpEL 表达式”)。 使用 @Vlaue 注解来引用属性值时，确保所引用的属性值在 application.properties 文件存在并且相对应匹配，否则会造成 Bean 的创建错误，引发 java.lang.IllegalArgumentException 非法参数异常。 2. 配置属性的获取方式2.1 @Value 注解@Value 注解对 Bean 的变量或者方法参数进行标注，职责是基于表达式给字段或方法参数设置默认属性值。通常格式是注解 + SpEL 表达式，如 @Value(“SpEL 表达式”)，并标注在对应的字段或者方法上方，且必须对变量一一标注。这种方式适用于小而不复杂的属性结构。属性结构复杂，字段很多的情况下，这种方式会比较繁琐，应该考虑使用 @ConfigurationProperties 注解。 12345678910111213141516171819202122232425import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.PropertySource;import org.springframework.stereotype.Component;/** * 书属性 */@Component@PropertySource("classpath:book.properties")public class BookProperties &#123; /** * 书名 */ @Value("$&#123;demo.book.name&#125;") private String name; /** * 作者 */ @Value("$&#123;demo.book.writer&#125;") private String writer; // ... 省略 getters / setters 方法&#125; 2.2 @ConfigurationProperties 注解1234567891011121314151617181920212223import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;/** * 书属性 * */@Component@ConfigurationProperties(prefix = "demo.book")public class BookComponent &#123; /** * 书名 */ private String name; /** * 作者 */ private String writer; // ... 省略 getters / setters 方法&#125; @ConfigurationProperties 注解的 prefix 是指定属性的参数名称。会匹配到配置文件中 “ demo.book. ” 结构的属性，星号 “ ” 是指会一一对应匹配 BookComponent 类的字段名。例如，字段 name 表示书名，会匹配到 demo.book.name 属性值。 @Value 注解方式强制字段必须对应在配置文件， @ConfigurationProperties 注解方式则不是必须的。一般情况下，所有字段应该保证一一对应在配置文件。如果没有属性值对应的话，该字段默认为空， @ConfigurationProperties 注解方式也不会引发任何异常，Spring Boot 推荐使用 @ConfigurationProperties 注解方式获取属性。 org.springframework.boot.context.properties.ConfigurationProperties 注解参数 prefix字符串值，绑定该名称前缀的属性对象。 value字符串值，功能同 prefix 参数。 ignoreInvalidFields布尔值，默认 false。绑定对象时，忽略无效字段。 ignoreUnknownFields布尔值，默认 true。绑定对象时，忽略未知字段。 2.3 @ConfigurationProperties 数据验证当属性类被 @Validated 注解标注时，Spring Boot 初始化时会验证类的字段。在类的字段上添加 JSR-303 约束注解，进行数据验证。 123456789101112131415161718192021222324252627282930import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;import org.springframework.validation.annotation.Validated;import javax.validation.constraints.NotEmpty;import javax.validation.constraints.NotNull;/** * 书属性 * */@Component@ConfigurationProperties(prefix = "demo.book")@Validatedpublic class BookComponent &#123; /** * 书名 */ @NotEmpty private String name; /** * 作者 */ @NotNull private String writer; // ... 省略 getters / setters 方法&#125; 3. 外化配置配置分离存储在 classpath 之外 3.1 外化配置优先级java -jar target/chapter-2-spring-boot-config-1.0.jar --demo.book.writer=Jeff SpringApplication.setAddCommandLineProperties(false); 本地 Devtools 全局配置 测试时 @TestPropertySource 注解配置 测试时 @SpringBootTest 注解的 properties 配置 命令行配置 SPRING_APPLICATION_JSON 配置 ServletConfig 初始化参数配置 ServletContext 初始化参数配置 Java 环境的 JNDI 参数配置 Java 系统的属性配置 OS 环境变量配置 只能随机属性的 RandomValuePropertySource 配置 工程 jar 之外的多环境配置文件（application- {profile}.properties 或 YAML） 工程 jar 之内的多环境配置文件（application- {profile}.properties 或 YAML） 工程 jar 之外的应用配置文件（application.properties 或 YAML） 工程 jar 之内的应用配置文件（application.properties 或 YAML） @Configuration 类中的 @PropertySource 注解配置 默认属性配置（SpringApplication.setDefaultProperties 指定） 3.2 属性引用属性之间可以直接通过 “${propName}” 的形式引用其他属性 1234## 书信息demo.book.name=[Spring Boot 2.x Core Action]demo.book.writer=BYSocketdemo.book.description=$&#123;demo.book.writer&#125;'s$&#123;demo.book.name&#125; 3.3 使用随机数例如注入某些密钥、UUID 或者测试用例，需要每次不是一个固定的值。RandomValuePropertySource 类随机提供整形、长整形数、UUID 或者字符串。 123456my.secret=$&#123;random.value&#125;my.number=$&#123;random.int&#125;my.bignumber=$&#123;random.long&#125;my.uuid=$&#123;random.uuid&#125;my.number.less.than.ten=$&#123;random.int(10)&#125;my.number.in.range=$&#123;random.int[1024,65536]&#125; 3.4 多环境配置类似 Maven 构建配置文件的思路，即配置多个不同环境的配置文件，再通过 spring.profiles.active 命令去指定读取特定配置文件的属性。 多环境配置文件的约定命名格式为 application-{profile}.properties。多环境配置功能默认为激活状态，如果其他配置未被激活，则 {profile} 默认为 default，会加载 application-default.properties 默认配置文件，没有该文件就会加载 application.properties 应用配置文件。 4. SpringBoot 自动配置原理4.1 外化配置和自动配置spring-boot-autoconfigure 包里面定义了很多默认的配置项。Spring Boot 会根据所添加的依赖，自动加载依赖相关的配置属性。 自动化配置代替了传统的繁琐的xml配置模式，以前使用 Spring MVC ，需要进行配置组件扫描、调度器、视图解析器等，使用 Spring Boot 自动配置后，只需要添加 MVC 组件即可自动配置所需要的 Bean。 External Configuration指的不是把配置内容分离到properties文件里，而是配置存储在classpath之外，比如spring cloud config 中 自动化配置本身包含了两块内容：@Configuration的定义和properties属性的定义，外部化配置是跟加载过程相关的。 4.2 自动配置原理浅析spring-boot-autoconfigure 包 通过 @EnableAutoConfiguration 核心注解初始化，并扫描 ClassPath 目录中自动配置类对应依赖。比如工程中有木有添加 Thymeleaf 的 Starter 组件依赖。如果有，就按按一定规则获取默认配置并自动初始化所需要的 Bean。 4.3 @EnableAutoConfiguration 核心注解的工作原理@EnableAutoConfiguration 注解核心点是 @Import 的自动配置导入选择器类 AutoConfigurationImportSelector 。 AutoConfigurationImportSelector 会读取 ClassPath 下面的 META-INF/spring.factories 文件。 spring.factories 文件中配置的 Spring Boot 自动配置类，例如常见的Jpa 自动配置类 JpaRepositoriesAutoConfiguration、Thymeleaf 自动配置类 ThymeleafAutoConfiguration 、 WebMvcAutoConfiguration Web MVC 自动配置类和ServletWebServerFactoryAutoConfiguration 容器自动配置类等 。 spring.factories 文件和 application.properties 文件都属于配置文件，均为键值对格式。里面配置的每个自动配置类都会定义相关 Bean 的默认配置，也会定义什么条件下自动配置和哪些 Bean 被实例化。 当 pom.xml 添加某 Starter 依赖组件的时候，就会自动触发该依赖的默认配置。 4.4 spring-boot-starter-web Starter 组件浅析容器自动配置类 ServletWebServerFactoryAutoConfiguration 的部分代码如下：123456789101112package org.springframework.boot.autoconfigure.web.servlet;@Configuration@ConditionalOnClass(&#123;ServletRequest.class&#125;)@ConditionalOnWebApplication( type = Type.SERVLET)@EnableConfigurationProperties(&#123;ServerProperties.class&#125;)@Import(&#123;ServletWebServerFactoryAutoConfiguration.BeanPostProcessorsRegistrar.class&#125;)public class ServletWebServerFactoryAutoConfiguration &#123;... 省略&#125; @ConditionalOnClass 注解表示对应的 ServletRequest 类在 ClassPath 目录下面存在，并且 @ConditionalOnWebApplication 注解表示该应用是 Servlet Web 应用时，才会去启动容器默认配置 通过 ServerProperties 类默认设置了端口为 8080 Type.SERVLET 枚举代表 Servlet Web 应用，Type.REACTIVE 枚举代表响应式 WebFlux 应用。 @ConditionalOnClass 注解类似功能的还有 @ConditionalOnMissingBean 、@ConditionalOnProperty等注解 4.5 一些自动化配置造成的问题 Spring Boot 工程添加某些 Starter 组件依赖，但不想触发组件自动配置 Spring Boot 配置多个不同数据源配置时，比如使用 XML 配置多数据源，但其默认数据源配置会触发自动配置出现问题。 解决方式是排除不需要的特定自动配置类：@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class}) 5. 利用自动配置自定义 Starter 组件一个完整的 Starter 组件包括以下两点： 提供自动配置功能的自动配置模块。 提供依赖关系管理功能的组件模块，即封装了组件所有功能，开箱即用。 实现自定义 Starter 组件，并不会将这两点严格区分，可以将自动配置功能和依赖管理结合在一起实现。 5.1 创建一个新的 Spring Boot 工程，命名为 spring-boot-starter-swagger。在 pom.xml 配置相关123456789101112131415161718192021222324252627282930313233&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;$&#123;version.swagger&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;$&#123;version.swagger&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-bean-validators&lt;/artifactId&gt; &lt;version&gt;$&#123;version.swagger&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.12&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 5.2 新建 SwaggerProperties 配置类新建名为 SwaggerProperties Swagger2 属性配置类，包含了所有默认属性值。使用该组件时，可以在 application.properties 配置文件配置对应属性项，进行覆盖默认配置。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import lombok.Data;import lombok.NoArgsConstructor;import org.springframework.boot.context.properties.ConfigurationProperties;import springfox.documentation.schema.ModelRef;import java.util.ArrayList;import java.util.LinkedHashMap;import java.util.List;import java.util.Map;@Data@ConfigurationProperties("swagger")public class SwaggerProperties &#123; /**是否开启swagger**/ private Boolean enabled; /**标题**/ private String title = ""; /**描述**/ private String description = ""; /**版本**/ private String version = ""; /**许可证**/ private String license = ""; /**许可证URL**/ private String licenseUrl = ""; /**服务条款URL**/ private String termsOfServiceUrl = ""; private Contact contact = new Contact(); /**swagger会解析的包路径**/ private String basePackage = ""; /**swagger会解析的url规则**/ private List&lt;String&gt; basePath = new ArrayList&lt;&gt;(); /**在basePath基础上需要排除的url规则**/ private List&lt;String&gt; excludePath = new ArrayList&lt;&gt;(); /**分组文档**/ private Map&lt;String, DocketInfo&gt; docket = new LinkedHashMap&lt;&gt;(); /**host信息**/ private String host = ""; /**全局参数配置**/ private List&lt;GlobalOperationParameter&gt; globalOperationParameters; ... 省略，具体代码见 GitHub&#125; 用 @ConfigurationProperties(prefix = “swagger”) 标注在类上方是指定属性的参数名称为 swagger。会对应匹配到配置文件中 “ swagger.* ” 结构的属性，例如，字段标题 title 表示标题，会匹配到 swagger.title 属性值。 5.3 新建自动化配置类 SwaggerAutoConfiguration （提供 Swagger2 依赖关系管理功能和自动配置功能）12345678910111213141516171819202122232425262728293031323334import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Import;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;@Configuration@ConditionalOnProperty(name = "swagger.enabled", matchIfMissing = true)@Import(&#123; Swagger2DocumentationConfiguration.class, BeanValidatorPluginsConfiguration.class&#125;)public class SwaggerAutoConfiguration implements BeanFactoryAware &#123; private BeanFactory beanFactory; @Bean @ConditionalOnMissingBean public SwaggerProperties swaggerProperties() &#123; return new SwaggerProperties(); &#125; @Bean @ConditionalOnMissingBean @ConditionalOnProperty(name = "swagger.enabled", matchIfMissing = true) public List&lt;Docket&gt; createRestApi(SwaggerProperties swaggerProperties) &#123; ... 省略，具体代码见 GitHub &#125; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; this.beanFactory = beanFactory; &#125;&#125; @Configuration 注解标注在类上方，表明该类为配置类。 @Import 注解引入 Swagger2 提供的配置类 Swagger2DocumentationConfiguration 和 Bean 数据验证插件配置类 BeanValidatorPluginsConfiguration。 @ConditionalOnMissingBean 注解标注了两处方法，当 Bean 没有被创建时会执行被标注的初始化方法。第一处被标记方法是 swaggerProperties() ，用来实例化属性配置类 SwaggerProperties;第二处被标记方法是 createRestApi()， 用来实例化 Swagger2 API 映射的 Docket 列表对象。 @ConditionalOnProperty 注解标注在 createRestApi() 方法，name 属性会去检查环境配置项 swagger.enabled 。默认情况下，属性存在且不是 false 的情况下，会触发该初始化方法。matchIfMissing 属性默认值为 false ，这里设置为 true，表示如果环境配置项没被设置，也会触发。 5.4 新建启动注解类 EnableSwagger2Doc用于开关 spring-boot-starter-swagger 组件依赖 1234567@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(&#123;SwaggerAutoConfiguration.class&#125;)public @interface EnableSwagger2Doc &#123;&#125; 上面代码 @Import 注解引入 Swagger2 自动配置类 SwaggerAutoConfiguration。当将该注解配置在应用启动类上方，即可开启 Swagger2 自动配置及其功能。]]></content>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 集成配置 HTTPS]]></title>
    <url>%2F2018%2F08%2F18%2Fspringboot-https%2F</url>
    <content type="text"><![CDATA[简单来说，修改 Tomcat 容器配置，加一层对应的安全约束配置即可。 申请SSL证书打开阿里云证书，可以申请免费证书一年有效。一年后继续免费申请一年即可。 下载，这块选择 Tomcat ，因为这次集成只需要修改 Spring Boot 内嵌容器 Tomcat 配置。如果是 nginx ，也可以对应下载并集成配置 配置 HTTPS将 .pfx 文件复制到 resources 根目录，然后配置 application-prod.properties （生产配置文件）： 12345## HTTPSserver.ssl.key-store=classpath:xx.com.pfxserver.ssl.key-store-password=123456server.ssl.key-store-type=PKCS12server.port=443 然后新增 HttpsConfig 类，代码如下 123456789101112131415161718192021222324@Configurationpublic class HttpsConfig &#123; /** * spring boot 1.x */ /* */ @Bean public EmbeddedServletContainerFactory servletContainer() &#123; TomcatEmbeddedServletContainerFactory tomcat = new TomcatEmbeddedServletContainerFactory() &#123; @Override protected void postProcessContext(Context context) &#123; SecurityConstraint constraint = new SecurityConstraint(); constraint.setUserConstraint("CONFIDENTIAL"); SecurityCollection collection = new SecurityCollection(); collection.addPattern("/*"); constraint.addCollection(collection); context.addConstraint(constraint); &#125; &#125;; return tomcat; &#125;&#125; 运行即可，从日志看出已经支持 HTTPS: 122019-06-16 10:42:42.989 INFO 16727 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 443 (https)2019-06-16 10:42:45.782 INFO 16727 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 443 (https) 修改链接所有的http链接修改为https，你懂的 301重定向对于不好修改的http地址，需在Nginx配置中HTTP链接301重定向 HTTP Strict Transport Security (HSTS)浏览器自动将http转写成https CookieSet-Cookie字段加上Secure标志 确保浏览器只在使用 HTTPS 时，才发送Cookie]]></content>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[费曼技巧]]></title>
    <url>%2F2018%2F08%2F06%2Ffeynman-technique%2F</url>
    <content type="text"><![CDATA[步骤 【明确目标】拿出一张白纸，把概念写在最上面 【以教促学】设想你在向一个新人解释这个概念 【化整为零】 【总结提炼】如果卡壳了，就再回顾下学习资料 技巧 技巧1：不断地举实例 技巧2：多提问 一定要写下来。而不是在大脑中想。 大脑的工作内存非常有限 如果你真正理解了一样东西，它在你脑子里一定是非常具体的、形象的 为什么有效？ 强迫切换大脑切换到主动思考模式 一种非常直接的反馈机制，对学习效果的终极反馈，你根本无法自我欺骗 为什么无效？费曼方法可以让我很容易找到自己不会的点。而不会的点就是一个问题，一个要解决的问题。一个问自己的问题。 我先直接去看书，遇到不懂的，反复思考，查阅，提问，推演。这种地方都要做一个记号。也就是学习过程中卡壳的地方做一个记号，不过一般在当天学习完成时我基本能搞懂这些不懂的地方。学到一定量的内容，比如一节，（我一般是一个具体的点学习完后。），或者直接按照学习时间分，比如3小时数学学习里面留30分钟返回去开始设想自己在教别人。这里我是在用记忆宫殿里弄了一个地方，设想了一个人。（至于这个人是谁最好是能激起你热情的人），这里记忆宫殿设想一个人不是一直在那里，更像一个开关，让你进入教别人的状态。用这种方法找出我之前直接看书没注意到的我又不懂的点。然后跟之前一样做记号，反复思考。比如我就是在设想自己在教别人的时候才发现我没注意到：0！=1这个知识点，之所以为1是为了合理性。 最后在完成学习之后留出的半小时里，把做过记号的问题的思考过程记录！ 这是重点：记录的是你遇到问题之后思考的过程。比如这个问题在反复看到书里的哪里哪里，才突然明白，或者哪个数学公式你怎么推导才得出，再或者不太清楚的地方联系到实际。像我就是一开始看不懂复合函数的极限定义部分，然后直接去看了做题的实例才瞬间明白的，我就把这个记录下来。 为什么说费曼方法对学习效率帮助不大？ 如果你数学都学不懂了你怎么教别人？学习学习重点在学不在教。有学才有教啊！教是可以反过来影响你的学，但是就好像是辅助工具一样。你把学习这个主要工具弄好才行啊！ 费曼在读生物学里以猫为实验对象的论文时？不懂里面各种肌肉术语时他不去记各个肌肉的专业术语，他去记猫的各个肌肉的位置联系。为什么，因为肌肉术语你可以直接查到。费曼在巴西教学时，惊讶于学生能够马上讲出定理但是一个现实中的简单物理问题却完全不会。 知识要和知识联系，知识要和实际联系。关注知识的本质。你在学习时不是去想怎么组织语言去教别人，而是去多思考为什么？会怎么样？会发生什么？什么导致的？等等只要是问题的问题！重视那些学习过程中你不懂的点，那个才是你要花时间去思考的。养成遇到难题反而兴奋的习惯，这会帮你很多。心态也非常重要。有良好的心态时学习效率真的不一样，我经历过，明显感觉的到。 费曼方法里简化语言能帮你思考吗？真正的简化是怎么样的？是你联系了实际，联系了以往的知识，你在看到这个知识的时候，不需要再去重新的理解一遍。你可以很快的靠着实例或者以往的知识推理出来。去简化知识的理解程度，而不是语言。而复习也是如此，不是叫你再去看一遍，背一遍。而是思考一遍。 注意这需要很多方面的配合，比如非常规律作息习惯、固定的体育锻炼、饮食上的配合、高质量的睡眠、放松技巧、实时反馈、主题阅读、刻意练习、加速理解、合理复习和记忆技巧，并把这几项都形成习惯，不断的进行调整，直到最终达成目标。 最少要在这几项上面掌握一些非常实用的方法，才能达到这个目标。这些技巧单独拿出来一项并不太难，但每一项都需要一定时间的练习，想组合到一起并取得一定的效果，最少估计要3-5年左右才能掌握并形成习惯。Scott Young研究快速学习并开始写博客也有6、7年了，才达到现在的程度。 其他scoot yong分享过技巧是，法律，经济学，政治学等文科使用举例子较好，而到了数学、化学、物理等逻辑性强的用类比、可视化比较好。 犹太引导法 请家长扮演低年级小学生的角色，而小学生扮演老师角色讲课，讲课前先列一个大纲，明确任务和注意事项，家长鼓励并接受小学生的辅导： 让小学生不看书或者仅有大纲，对家长试讲5分钟，看看学生记得多少。 当小学生讲不下去时候，让他一边看课本或者笔记提示一边讲解，大概15分钟完成。整个讲述即复述过程是20分钟，同时也注重让小学生培养用自己的语言讲解的能力。 讲课时，不能看书，在过程中，妈妈可以用问题引导“小老师”讲课，在合适的时候提出问题，对孩子讲得清楚明白的地方进行表扬，最后一定要对孩子表示感谢。 原文：https://blog.csdn.net/a759478257/article/details/8748071 最没有效率的，是突出显示和下划线的划重点。划重点除了帮助阅读文本之外，这些没有任何益处。划重点会让人把吸引力转向了各个独立的事实，它有可能会妨碍学习者理清各个事实间的关系和做出推论。 重读，比起其他好的策略来说效率更低一些。 总结，做汇总或是列出文章中的主要观点对对于擅长做这些事的人来说是有帮助的，无法充分利用时间。 突出显示、下划线、重读和做汇总都被论文作者们评为“实用性低”的学习技巧。 分散式学习和实际测试都被作者们评为“高实用性”的学习技巧。分散式学习把学习的时间分散开来，而不是像跑马拉松一样地一次性完成学习。 测试，要做更多的自测，单单是回忆脑海中的信息这一过程就能强化知识，并且在未来重拾知识时派上用场。与实际测试相近的技巧：使用记忆卡片。而且现在记忆卡片可以变得数字化，anki或SuperMemo。 其他技巧都处于中间地带——虽然不是完全没用，但是因为太费时间而没有多大的效率。这些技巧有： 心理意象，即看图片记文字（很耗时间，而且只对能联想得到图片的文字有用）； 学习精细化整合（详尽审问），即边读边问自己问为什么（有点烦人，就好像四岁小孩一直拉着你的袖子问问题一样）； 自我解释，即强迫自己解释文中出现的细节内容，而不是之后再被动地重新阅读（这种方法是否有效取决于你的解释是否完整精确）； 交叉实践，即把几种不同的问题组合在一起（没有太多证据能说明这种方法有效，除非是学习开车）； 最后是关键词助记，即把新的词汇（通常是一门外语）与英语读音相近的词联系在一起，举例来说，学习法语词表示“钥匙”的单词 la clef 的时候，想想一把钥匙放在悬崖（cliff）上（这样记单词要花很多功夫）。 分散学习时间、丢掉荧光笔然后去做记忆卡片，你的学习效果会好得多。 费曼技巧实际上融合了以上几种中等以上效果学习技巧：测试效应（练习性测试）；详尽审问；自我解释。但是费曼技巧比较费时间，所以仅用于难点重点较合适。 而使用记忆卡片最好的例子就是SuperMemo、Anki，把你想记的东西做成卡片，反复测试并自动设定复习时间。 遗忘就像衰老一样，它会发生，而且没有奇迹可以治愈它。除非你积极提醒自己，或定期练习技能，否则知识和技能会逐渐消失。那是不幸的部分。 你会忘记的。但是，如果您使用正确的方法，那么这些信息将与您保持更长时间。更好的是，相同的方法可以帮助你记住多年，现在可以帮助你更好地记住，所以即使考试即将来临，它们也值得申请。 控制杠杆一：精神压缩 控制杠杆二：有趣 人们会记住让你感到恐惧，兴奋，惊奇或厌恶的想法。让你觉得太抽象而无聊从而被遗忘了。 联系和有趣性 「如果你不能简单地解释一件事，那就还没弄懂它。」 “超级学习”复习法准备好四个书签，每天四个书签都要往前移动，进行学习或复习。 第一个书签是“开路先锋”，它的主要任务是认真地阅读，深入地思考，广泛地联想，并随时查阅有关的资料。 认真学习完毕后，总结出一个又一个的问题（不能遗漏） 根据这些问题，一一提问自己一遍（不要看书） 第二个书签 —— 复习前一天所学的东西（也就是第一个书签所“扫描”过的内容） 一定要先看第一遍学习时所罗列出的问题，而不要直接看原文。对于所列的问题，必须进行尝试回忆，能完整、准确、顺畅回答出来的算通过，若不能再去仔细看书，并在相应的问题上标明记号。 第三个书签离第二个书签的距离，要比第二个书签与第一个书签的距离远些。第三个书签所复习的内容，应是一个星期前自己所学的内容。除了完成与第二个书签完全相同的程序以外，在第三个书签的复习工作时，还应注意把第一阶段所学的内容进行归纳总结。美国教育心理学家布鲁纳认为，“人类记忆的首要问题在于组织”。 一般说来，按照一个人自己的兴趣和认识结构组织起来的材料，就是最有希望在记忆中“自由出入”的材料。对材料进行加工整理的前提是分析和综合、加深理解。编写提纲是一种词的逻辑记忆方式，因为它把“别人”的语言形式，通过积极的智力活动，转化为“自己的语言”。如数学中三角函数部分的内容可整理为一二三四（一个推广二类问题三组公式四个图象及性质）。 第四个书签与第三个书签相隔的更远，它是复习和检查一个月前学习的内容。一般来说，经过前三轮的学习与复习，绝大多数内容都应已熟练无误地掌握。如果此时还有不熟和错误的地方，要加倍警惕，认真补漏，并做上记号，以备阶段复习和最后总复习时提醒自己格外注意。]]></content>
      <tags>
        <tag>feynman, learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高效学习]]></title>
    <url>%2F2018%2F08%2F06%2Fbrain-science%2F</url>
    <content type="text"><![CDATA[高效能三要素：时间、能量和注意力 《The ABCs of how we learn》 “午休时间”的使用方法是提高下午工作效率的重中之重。由于血清素是一种跟“放松心情”、“回归平常心”息息相关的脑内物质。血清素分泌不足或活力下降的话，人就会焦躁不安或容易发怒，做什么事情都提不起兴致。 所以如何激活血清素的活力就成了关键，其实方法很简单，那就是日光浴、有节奏的运动和咀嚼。外出吃午餐就可以同时实现上面3个方法——走出公司，步行5分钟左右找一家心仪的餐馆，这个过程就晒了日光浴。步行也是一种有节奏的运动。坐下来细嚼慢咽地享用午餐，就做到了充分咀嚼。这一系列过程就能充分提升血清素的活力。 接下来就是午睡20~30分钟。虽然只有二三十分钟，但醒来后会发现自己的体力、脑力、专注力都能得到极大恢复，工作起来不仅不累，效率还很高。 *根据脑科学原理设计的最完美的一天7:00-9:00 自我投资 | 大脑黄金时间9:00-12:00 专注时间 | 处理“专注性工作”（罐头工作术）12:00-13:00 吃午餐 | 激发“血清素”活力以恢复专注力，尽可能外出吃饭、晒太阳、细嚼慢咽13:00-16:00 非专注性工作 | 午间小睡（20-30分钟）、变换工作场所、穿插会议等达到整体重启专注力的目的16:00-18:00 最后冲刺工作时间 | 为每天工作设定一个最后的期限，因“去甲肾上腺素”的高度集中注意力效果，达到又一轮工作效率小高峰18:00-19:00 有氧运动 | 大脑专注力完全“重启”19:00-21:00 自我投资 | 大脑第二个黄金时间21:00-23:00 放松时间 | 产生“后叶催产素”23:00-7:00 保证7小时以上睡眠 | 分泌“褪黑激素” 排除杂念法：1.整理桌面与电脑文件 2.把心里惦记的事情写出来 3.提高大脑前额皮质中血清素的活力：日光浴、运动、咀嚼 4.找到专注空间，不受外界影响，减少手机通信。 白天摆脱困意的方法，舌头舔上颚。恢复精力：运动，闭眼休息1分钟]]></content>
      <tags>
        <tag>brain-science</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java线上问题排查总结]]></title>
    <url>%2F2018%2F08%2F01%2Fonline-troubleshoot%2F</url>
    <content type="text"><![CDATA[Linux命令类tail1tail -300f fixed-center.log #倒数300行并进入实时监听文件写入模式 grep12345678910grep forest f.txt #文件查找grep forest f.txt cpf.txt #多文件查找grep 'log' /home/admin -r -n #目录下查找所有符合关键字的文件cat f.txt | grep -i shopbase #匹配的行 grep 'shopbase' /home/admin -r -n --include *.&#123;vm,java&#125; #指定文件后缀grep 'shopbase' /home/admin -r -n --exclude *.&#123;vm,java&#125; #反匹配seq 10 | grep 5 -A 3 #上匹配seq 10 | grep 5 -B 3 #下匹配seq 10 | grep 5 -C 3 #上下匹配，平时用这个就妥了cat f.txt | grep -c ‘SHOPBASE’ #匹配计数 find12345678910111213sudo -u admin find /home/admin /tmp /usr -name \*.log #多个目录去找find . -iname \*.txt #大小写都匹配find . -type d #当前目录下的所有子目录find /usr -type l #当前目录下所有的符号链接find /usr -type l -name "z*" -ls #符号链接的详细信息 eg:inode,目录find /home/admin -size +250000k #超过250000k的文件，当然+改成-就是小于了find /home/admin f -perm 777 -exec ls -l &#123;&#125; \; #按照权限查询文件find /home/admin -atime -1 #1天内访问过的文件find /home/admin -ctime -1 #1天内状态改变过的文件 find /home/admin -mtime -1 #1天内修改过的文件find /home/admin -amin -1 #1分钟内访问过的文件find /home/admin -cmin -1 #1分钟内状态改变过的文件 find /home/admin -mmin -1 #1分钟内修改过的文件 top12ps -ef | grep javatop -H -p pid #获得线程10进制转16进制 netstat1netstat -nat|awk '&#123;print $6&#125;'|sort|uniq -c|sort -rn #查看当前连接，注意close_wait偏高的情况 btrace &amp; greys12sc -df xxx #输出当前类的详情,包括源码位置和classloader结构trace class method #打印出当前方法调用的耗时情况 系统异常排查流程常见的系统异常现象包括: CPU 占用率过高、CPU上下文切换频率次数较高、磁盘满了、磁盘 I/O 过于频繁、网络流量异常（连接数过多）、系统可用内存长期处于较低值（导致 oom killer）等等。 业务应用排查流程常见的业务服务异常现象包括:PV量过高、服务调用耗时异常、线程死锁、多线程并发问题、频繁进行 Full GC、异常安全攻击扫描等。 GC的JVM参数 -XX:+PrintGCDetails -XX:+PrintGCDateStamps`-Xloggc:/usr/local/gc/gc.log -XX:+UseConcMarkSweepGC GC日志分析：MAT、 http://gceasy.io/]]></content>
      <tags>
        <tag>经验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载机制]]></title>
    <url>%2F2018%2F08%2F01%2Fclass-loading%2F</url>
    <content type="text"><![CDATA[初始化时机new、静态字段或方法被使用、反射、父类、main函数调用 加载过程 加载（获取字节流并转换成运行时数据结构，然后生成Class对象） 验证（验证字节流信息符合当前虚拟机的要求） 准备（为类变量分配内存并设置初始值） 解析（将常量池的符号引用替换为直接引用） 初始化（执行类构造器-类变量赋值和静态块的过程） 类加载器 启动类加载器（Bootstrap ClassLoader）：是虚拟机自身的一部分，它负责加载以java.*开头的核心类库 扩展类加载器（Extension ClassLoader）：它负责加载javax.*开头的类和存放在JRE的ext目录下的类 系统类加载器（ApplicationClassLoader）：它负责加载应用程序自身的类 定义：如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式。 优点：采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次。其次防止恶意覆盖Java核心API。 实际使用场景通过编写你自己的ClassLoader，你可以做到： 容器加载（如tomcat） 热部署 代码保护 动态修改类（例如数据库中取得java class） 当创建自己的Class Loader时，只需要重载findClass()这个方法。]]></content>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java内存区域]]></title>
    <url>%2F2018%2F08%2F01%2Fmemory-area%2F</url>
    <content type="text"><![CDATA[内存区域划分所有线程共享的数据区： 方法区: 存储已被虚拟机加载的类信息、方法信息、常量、静态变量、字节码、JIT编译后的本地代码，并使用永久代来实现方法区。1.8中用元空间替代了永久代，元空间并不在虚拟机中，而是使用本地内存，元空间中可能还存在短指针数据区CCS 堆区: 最大的一块区域，用于存放对象的区域，1.7之后常量池移到这里 每个线程都会有一块私有的数据区： 虚拟机栈: 每个方法执行时在其中创建一个栈帧，用于存储局部变量、操作数栈、动态链接、方法出口等信息 本地方法栈: 功能与虚拟机栈相同，为native方法服务 程序计数器: 存放当前正在执行的指令的地址 直接内存： 直接内存并非Java标准。 JDK1.4 加入了新的 NIO 机制，目的是防止 Java 堆 和 Native 堆之间往复的数据复制带来的性能损耗，此后 NIO 可以使用 Native 的方式直接在 Native 堆分配内存。 直接内存区域是全局共享的内存区域。 新生代进入条件优先选择在新生代的Eden区被分配。 老年代进入条件 大对象，-XX:PretenureSizeThreshold 大于这个参数的对象直接在老年代分配，来避免新生代GC以及分配担保机制和Eden与Survivor之间的复制 经过第一次Minor GC仍然存在，能被Survivor容纳，就会被移动到Survivor中，此时年龄为1，当年龄大于预设值就进入老年代 如果Survivor中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于等于该年龄的对象进入老年代 如果Survivor空间无法容纳新生代中Minor GC之后还存活的对象 Java对象不都是分配在堆上还能分配在栈上 逃逸分析逃逸是指在某个方法之内创建的对象，除了在方法体之内被引用之外，还在方法体之外被其它变量引用到；这样带来的后果是在该方法执行完毕之后，该方法中创建的对象将无法被GC回收，由于其被其它变量引用。正常的方法调用中，方法体中创建的对象将在执行完毕之后，将回收其中创建的对象；故由于无法回收，即成为逃逸。 方法逃逸： 1234567public static StringBuffer craeteStringBuffer(String s1, String s2) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb; &#125; 线程逃逸：方法中的局部变量甚至还有可能被外部线程访问到，譬如赋值给类变量或可以在其他线程中访问的实例变量，称为线程逃逸。 如果能证明一个对象不会逃逸到方法或线程外，则可能为这个变量进行一些高效的优化。 栈上分配如果能够通过逃逸分析确定某些对象不会逃出方法之外，那就可以让这个对象在栈上分配内存，这样该对象所占用的内存空间就可以随栈帧出栈而销毁，就减轻了垃圾回收的压力。 同步消除（锁优化） 减少锁持有时间（减少锁的势力范围） 减小锁粒度（如ConcurrentHashMap） 锁分离（如ReadWriteLock） 锁粗化（频繁获取、释放锁优化成一次） 锁消除（编译器做的-server -XX:+DoEscapeAnalysis -XX:+EliminateLocks，并要开启逃逸分析） 标量替换原始数据类型称为标量，对象是聚合量。如果逃逸分析证明一个对象不会被外部访问，并且这个对象是可分解的，那程序真正执行的时候将可能不创建这个对象，而改为直接创建它的若干个被这个方法使用到的成员变量来代替。拆散后的变量便可以被单独分析与优化，可以各自分别在栈帧或寄存器上分配空间，原本的对象就无需整体分配空间了。 注意：逃逸分析比较耗时，效果不稳定。目前HotSpot虚拟机由于实现会比较复杂，暂时还没有做这项优化。 TLABJVM在内存新生代Eden Space中开辟了一小块线程私有的区域TLAB（Thread-local-allocation-buffer）。在Java程序中很多对象都是小对象且用过即丢，它们不存在线程共享也适合被快速GC，所以对于小对象通常JVM会优先分配在TLAB上，并且TLAB上的分配由于是线程私有所以没有锁开销。因此在实践中分配多个小对象的效率通常比分配一个大对象的效率要高。也就是说，Java中每个线程都会有自己的缓冲区称作TLAB，在对象分配的时候不用锁住整个堆，而只需要在自己的缓冲区分配即可。 GC回收机制回收对象不可达对象：通过一系列的GC Roots的对象作为起点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时则此对象是不可用的。GC Roots包括：虚拟机栈中引用的对象、方法区中类静态属性引用的对象、方法区中常量引用的对象、本地方法栈中JNI（Native方法）引用的对象。 彻底死亡条件：条件1：通过GC Roots作为起点的向下搜索形成引用链，没有搜到该对象，这是第一次标记。条件2：在finalize方法中没有逃脱回收（将自身被其他对象引用），这是第一次标记的清理。 如何回收新生代因为每次GC都有大批对象死去，只需要付出少量存活对象的复制成本且无碎片所以使用“复制算法”老年代因为存活率高、没有分配担保空间，所以使用“标记-清理”或者“标记-整理”算法 复制算法：将可用内存按容量划分为Eden、from survivor、to survivor，分配的时候使用Eden和一个survivor，Minor GC后将存活的对象复制到另一个survivor，然后将原来已使用的内存一次清理掉。这样没有内存碎片。标记-清除：首先标记出所有需要回收的对象，标记完成后统一回收被标记的对象。会产生大量碎片，导致无法分配大对象从而导致频繁GC。标记-整理：首先标记出所有需要回收的对象，让所有存活的对象向一端移动。 Minor GC条件当Eden区空间不足以继续分配对象，发起Minor GC。 Full GC条件 调用System.gc时，系统建议执行Full GC，但是不必然执行 老年代空间不足（通过Minor GC后进入老年代的大小大于老年代的可用内存） 方法区空间不足]]></content>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重构实践手册]]></title>
    <url>%2F2018%2F07%2F31%2Frefactor%2F</url>
    <content type="text"><![CDATA[重构是什么 在不改变软件可观察行为的前提下，提高其可理解性，降低其修改成本。 好的重构应该像一边开车一边换轮胎一样，保证系统随时可工作的前提下，还可以对其结构做出安全高效的调整。 重构之前的事 写好单元测试 持续集成、持续交付 代码的坏味道 重复代码 过长的函数、类 过长的参数列表 冗余代码及参数 不可读的名称 什么时候应该重构 事不过三，三则重构 什么时候不应该重构 重构它还不如重新写一个来得简快 项目已经进入了尾期 重构技巧 小步重构，逐步验证 事不过三，三则重构 函数重构 条件表达式 以卫语句取代多层嵌套的if/else 重构指导思想 Solid设计原则 类的单一职责 开闭原则 里氏替换原则 接口隔离原则 依赖倒置原则 工欲善其事必先利其器 SonarLint、阿里巴巴编码扫描插件 IDEA–&gt;Analyze菜单 根目录右键Optimize Imports 参考编码最佳实践]]></content>
      <tags>
        <tag>优化, 重构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java内存模型]]></title>
    <url>%2F2018%2F07%2F31%2Fjmm%2F</url>
    <content type="text"><![CDATA[定义 JMM是一种规范，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题，保证并发编程场景中的原子性、可见性和有序性。 对象、数组在堆内存中，局部变量、方法定义参数、异常处理器参数不会有内存可见性问题，也不受内存模型的影响。 JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。 实现 volatile、synchronized、final、concurrent包等。其实这些就是Java内存模型封装了底层的实现后提供给程序员使用的一些关键字 主内存：所有变量都保存在主内存中 工作内存：每个线程的独立内存，保存了该线程使用到的变量的主内存副本拷贝，线程对变量的操作必须在工作内存中进行 每个线程都有自己的本地内存共享副本，如果A线程要更新主内存还要让B线程获取更新后的变量，那么需要： 将本地内存A中更新共享变量 将更新的共享变量刷新到主内存中 线程B从主内存更新最新的共享变量 happen-before原则如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系。 它是判断数据是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们解决在并发环境下两操作之间是否可能存在冲突的所有问题。 程序有序性：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作； 锁的有序性：一个unlock操作先行发生于后面对同一个锁的lock操作； volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作； 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C； 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作； 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生； 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行； 对象终结规则：一个对象的初始化完成先行发生于它的finalize()方法的开始；]]></content>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何变得自律]]></title>
    <url>%2F2018%2F07%2F06%2Fhow-to-build-self-discipline%2F</url>
    <content type="text"><![CDATA[1. 核心问题自律的核心问题是：如何让行为符合长期利益？（或者表述为：如何让行为符合理性？） 我们可以将核心问题分解为三个小问题： Q1：什么影响了我们的行为？ Q2：什么行为符合长期利益？ Q3：Q1的结果如何帮助指导Q2的行为？ 关于Q2，原始的大脑里根本没有“长期利益”这个概念，行为自然不会符合“长期利益”。当Deadline来临的时候，“长期利益”在脑海中越来越清晰，人的行为才转向自律。 2. 原理2.1 什么影响了我们的行为？ 输入→模型→输出 信息→大脑→行为 所以，控制信息的输入和调整大脑的状态，是促进自律的两个基本点。 如果一面给自己杂乱的信息，一面要求高效的行为。行为自相矛盾，大脑非崩溃罢工不可。同样如果大脑已经疲惫，仍然要求它高效地运转，这同疲劳驾驶一样是危险的举动。 2.1.1 信息 信息是用于减少随机不确定性的东西。—— 香农 大脑渴求信息，害怕错过一切有助于生存的信息。 时代已经悄然发生了变化——由信息匮乏转变为信息冗余。 为了适应环境的变化，人首先需要转变的是对信息的态度，从信息越多越好，转变为少即是多。 我们如何筛选进入大脑的信息呢？推荐两个维度： 信息源。科普，书籍，论文，记录片，课程等等 半衰期。科学定律的价值不会衰减，经典文学衰减很慢，新闻、微博、朋友圈信息衰减最快，需要远离。 比筛选信息更重要的是，人要有意识地大幅减少信息输入的总量和频次。不要让信息的子弹，把自己的生活打成碎片。 任何信息输入都会增加大脑负担，它们会占用大脑空间，消耗大脑资源，更可能改变大脑的工作状态。因此减少信息输入是最直截了当的自律方法。 应用举例： 起床后第一件事不应该是看微信，微博，知乎，而是看看自己的笔记，背背单词，想想一天的计划。 在完成最主要的任务之前，不允许自己接受杂乱信息。 睡前不要接触开放信息源，否则不容易睡着。 工作时间就不要玩手机，宁可闭目养神也不要玩手机。 2.1.2 大脑的工作模式根据不同的场景，不同的需求，人们把大脑的工作模式有不同的划分，比如理性与感性，意识与潜意识，专注模式与发散模式…… 很多人没有意识到，订立计划时的自己与执行计划的自己是不同的，前者是理性模式下的自己，后者常常是非理性模式下的自己。这是计划得不到执行的主要原因。 1. 理性模式理性模式的首要任务是可控，在可控的基础上提高效率，一个保证方向，一个提供速度。方向比速度更为重要，因为方向错了，速度越快偏离目标更远。 如何做到可控？ 重复率。重复率越高的东西，越值得打磨到极致。 迁移性。迁移性越高的东西，越值得掌握。比如各学科中的基本原理。 压缩。尽可能通过图表等形象化工具压缩知识。 时间用在刀刃上。做自己害怕的事，不会的事。 不要做已经会的题，背已经会的单词。 复习。学习是播种，复习才是收割。 2. 非理性模式非理性模式继承了生物进化中的很多特点： 逃避困难与风险，以免送命。 快速做出决策，反应迟钝就可能被捕食。 偷懒，以储备能量。 在什么情况下，大脑会切换到非理性模式呢？ 疲惫(饭后半小时之内，大脑都不清晰。因此可以冥想) 高刺激(当大脑习惯于高刺激之后，一切低刺激的事情大脑都会本能地排斥。)所有的坏习惯，都有一个共同的特征：追求高刺激。 缺乏能量 没有危机意识人如果没有危机意识，自我意识就会沉睡人应该有一个最基本的危机意识就是时间一去不复返 负面情绪情绪的产生通常都是因为环境的刺激超过了理性能够处理的程度烦躁、生气、抑郁、恐惧，会改变大脑模式 3. 行为塑造大脑自律不起来，因为大脑没有相应的连接。 我们常常把对知识的描述认为是知识，其实只有大脑内真实的连接才是知识。 比如，食谱是知识的描述，背食谱只是记住了对“知识的描述”，做菜的途中在大脑产生做菜的连接，这个才是知识。 自律不起来的原因是，你仅仅摄入了“知识的描述”，而没有在大脑内产生真实的连接。 如果我们只学而不实行，大脑永远只有“知识的描述”，而没有知识。“知而不行，只是未知”，这就是知行合一的精髓。 大脑既不是生而知之，也不是学而知之，更多时候是行而知之。 我们等待大脑驱动行为，然而大脑等待我们通过行为来教会它。这就成了拖延症的原因。 a 大脑通过“知识的描述”指导行为， b 行为产生大脑连接即知识， c 然后大脑自发产生行为。 a 过程中，大脑在冒险，在探索未知，它可能没有任何奖励，因此需要意志的参与。 b 过程是大脑产生神经连接的过程，是把人类语言翻译成大脑可执行语言的过程。反复的练习产生稳定的连接，这就是习惯的生理基础。 c 过程中，大脑已经知道过程和结果，有结果的反馈和奖励，还有成型的脑连接，即习惯，就不太需要意志的参与。 自律的关键就是a 过程，需要一定意志力的参与。 拖延者的思维过程是——因为大脑不愿意做事，所以做事条件并不满足，先做其他大脑愿意做的事，等待条件满足。而条件永远不会满足，因为大脑还没有形成连接。 自律者的思维过程是这样——正因为我不愿意做它，表明大脑里缺乏做它的连接，所以我要通过做它还补全这些连接。 比如：正因为我不想按时睡觉，表明我的大脑缺乏按时睡觉的连接，所以我要按时睡觉来补全它。 行动了之后，我们还要关注这些行为的收益，有意识地给结果打积极的标签，通过正向反馈，让大脑形成闭环。人是在积极的氛围学习的，只有这样的学习才可能持久。行为的闭环也是自律的重点。 通过行动在大脑里产生知识！ 4. 习惯是自律的立足点自律不能用于救火，要用于建立习惯。在习惯建立之前的自律，都是不稳定的、临时的、反复的。只能建立了习惯之后的自律才是持久的。 自律就是用有价值的习惯代替无价值的习惯。 改变命运的方法只有一条，就是提升自己，即稳固地改变自己。提升自己的方法只有一条，就是养成优秀的习惯。 因此，当你接触到一个先进理念，就要死死地抓住它。把它设计成可落实的习惯，全部精力用于养成这个习惯，直到完全消化吸收了它。优秀的习惯越多，成为优秀的人只是水到渠成的结果罢了。 2.1.3 环境 人的行为的目标，就是在适应环境的基础之上，满足自己的需要。 人若只盯着自己的需要，不注意环境的负面反馈，不知不觉会因为贪食刀刃之蜜而送命，熬夜打游戏、看爽文、刷社交软件、用透支生命换取快感的行为，都是因为不能根据环境调整自己的行为。 人如何根据环境调整自己的行为呢？ 1、尽可能选择适合的环境。 2、整理自己的环境。 当你别无选择的时候，只能把它当作磨练意志的时候。What doesn’t kill you makes you stronger. 你需要做的是，把干扰你的东西从你的环境（和网络环境）扫除，把微信、B站、知乎 中不能让你成长的订阅号和关注者清理干净。 把所有的精力、财力、时间 都集中起来，给自己一张书桌、一盏明灯、几位榜样、 几本好书，做好最重要的一件或两件事情，以之为跳板，逐步改变自己的环境。 3、分析自己的环境 比如区分学校的环境，和寒暑假在家的环境有什么不同，两者的优点和缺点分别是什么？采用什么方法可以扩大优点，对抗缺点，从而使寒暑假不至于荒废。 人在优势的环境中，则应主动作为，扩大优势，不可犹豫而贻误时机。 如果自己处于劣势，则应退而求稳，优化自身，不可盲动而恶化事态。 2.1.4 诱惑人之所以不自律，无非是（理性）想做的事情不能去做，（理性）不想做的事情忍不住去做，前者是逃避困难，后者是诱惑让自己分心。 诱惑是让人快乐的、舒适的，大脑都没有意识到诱惑是个问题，不知不觉掉落陷阱之中。因此诱惑是无形的，最为致命。 很多人既不有意识地筛选信息，还任凭诱惑野蛮生长，这样的人怎么可能自律呢？算把手脚打断，也不可能拥有自律。这种行为的自相矛盾，是无数人痛苦的来源。 如何应对诱惑呢？ 1. 预防大于治疗面对灾害，人有两种应对方式，预防和补救。聪明人总是将精力用于预防，而蠢蛋则寄希望于补救。 当人处于诱惑之中，多巴胺主导的欲望系统已经被唤醒，人就如同着火。大多数人将自律用于灭火，必然常常失败，为什么？ 大脑的窄化效应。当大脑受到刺激时，其注意力会收窄。饿让大脑把注意力集中在食物上。大脑收到诱惑时，便把注意力集中在诱惑相关的事物上。 窄化效应三个表现分别是： 聚集刺激 聚焦当下（Present Oritentation） 聚焦自身（Self Oritentation） 受窄化效应的影响，人会趋向无限放大当前的需求，忽略其他任何事物，趋向于即时满足。 当人处于诱惑之中，未来、目标、理想等待已经看不见了， 理性思维与利弊分析已经被多巴胺系统旁路掉，无法有效工作了。基于理性思维的意志力必然受到大幅削弱，自制力用于救火必然失败。 很多人感觉自制力不足。其实自制力未必不足，而是自制力用错了地方。自制力强的人，强在预防，而不是强在救灾。 预防大于治疗，防灾胜于救灾。这是健康医疗和安全消防领域的基本常识。 聪明人应该识别可能的风险，把精力于用预防上面。面对诱惑，常见的预防措施有： 选择合适的环境。比如去图书馆学习。 过滤筛选信息输入，减少信息干扰。 不要等到精力透支才休息。 远离诱惑。有些诱惑就如同过敏原一样，让人无法抵抗。 关注自己的内心，是否有负面情绪，是否追求舒适。 警惕睡前的时间。这时期精力最薄弱，放纵会影响第二天的睡眠。 警惕周未时间。由于空闲时间突然增加很多，人的危机感会下降。 2. 框架效应（Framing Effect）人们对相同问题的不同描述将导致不同的决策。 当人的目光着眼在收益时，大脑会因为风险厌恶，偏向即时满足。 当人的目光着眼在损失时，大脑会因为损失厌恶，而做出相反的决策。 解决即时满足的关键是用计算损失代替计算收益。即时满足的危害正是由忽略损失导致。 猎熊人会在刀刃上涂满蜂蜜，当熊舔舐蜂蜜时，刀刃会划伤舌头，血液会激发熊的嗜血本能，它会一直舔食直到死亡。 熊的死亡并非因为蜂蜜，它不需要也不可能戒断蜂蜜。熊的死亡在于它没有注意到这一次快感的代价是生命。 生命中的一切快感都在暗中标好了价格。我们需要判断自己能否支付。 如果我们愿意支付玩乐的代价，也尽可以放心去玩。 问题在于，大多数情况下，我们没有思考过代价，透支的快乐我们偿还不起，于是痛苦不堪。 3. 先立后破人绝大多数的时间都是被诱惑偷走的，比如网剧网文，游戏、朋友圈，直播、短视频……从这个角度，诱惑是自律最大的敌人。 根据诱惑的程度不同，人的表现可以分为即时满足和上瘾。无论即时满足还是上瘾，都是大脑形成的坏习惯。它们是环境和脑回路共同作用的结果，有很强的客观性。其中上瘾的客观性最强。 多数人面对诱惑的处理思路是，先抵御诱惑，再做正事。处理坏习惯的方法是，先戒掉一个习惯，再培养好习惯。这就是不破不立，先破后立的方法论。 然而这个方法处理诱惑，常常会失败。因为好习惯建立以前，坏习惯很难戒掉。抵御诱惑带来的空闲时间，会被其他诱惑侵占。 正如给房间换气一样，不能先把房间抽成真空，再注入空气。应该不断给房间注入新鲜空气，让腐败之气逐步fade out, 才可能达到换气的效果。 人的心灵也是一样，抵御一个诱惑，其他诱惑就想要填充，戒掉一个坏习惯，其他坏习惯就会替补入场。 正确的办法是——用有价值的信息和任务填充时间，其他的事情稍后处理。当人在人价值的事情上得到满足，消耗精力之后，就没有多少欲望、精力、时间留给诱惑了。这就是先立后破的方法论。 处理诱惑就像掰手腕一样，你越强他越弱，反之亦然。自律感越强的人，维持自律的成本反而低一些，因为他们与诱惑的接触面很少；相反，自律感居中的人，维持自律的成本最高；陷入拖延泥潭的人，容易变得习得性无助。 在《习惯的力量》一书中，作者强调，习惯是不能被拔除的，只能被替代。同样的，诱惑是无法被隔绝的，只能被积极的、有价值的的信息和任务挤占。 在先立后破的总原则上，远离诱惑，整理环境，安排计划都会发挥巨大作用。时间被价值充满，这就是自律的目标和奖励。 4. 找到适合的娱乐方式人绝大多数痛苦在于没有找到适合自己的娱乐方式。 由于娱乐方式与自己的内在需求相左，内心没有得到真正满足，压力无法施放，时间和精力的流逝让自己身心俱疲。 错误的娱乐方式会把人导向堕落甚至毁灭，不适合的娱乐方式会让人陷入长久地煎熬与疲惫，适合的娱乐方式会让自己怡然自得。 我认为判断娱乐是否合适的核心标准有三条： 能有效的停止。 娱乐程度与当前的生活状态相匹配。 能让身心放松。 一切高刺激的娱乐都有一个特点，在疲倦之前，无法停止。就像开车一样，车速越快，动量越大，停止越难。 娱乐是生活中的佐料，而不是主食。当娱乐占用过多的时间，佐料就成为了主食。 一个娱乐越能有效的停止，越是健康的娱乐。 所有称为“瘾”的娱乐，都有一个共同的特点，无法有效停止。有人刷朋友圈成瘾，看连续剧成瘾，刷知乎上瘾 等等 都是身体已经疲惫，大脑的某一区域仍然不愿停止。 每个人的情况不同，“上瘾”的事物不同，凡是让你无法停止，吞噬大量时间的，都不是适合你的娱乐。 根据娱乐的刺激峰值和频率，可以大致分为深度娱乐和浅层娱乐，或者分为高刺激娱乐和低刺激娱乐。 在不同的生活状态中，适合的娱乐就不同。 如果生活状态丰富多彩，就可以选择深度的娱乐。如果生活状态过于单调，就适合浅层娱乐。 为什么？ 如果娱乐提供的刺激 远远超过生活本身的反馈。人会倾向于逃避生活，选择娱乐。这样的娱乐就会让生活本身失色，让生活失去意义。人长期感受不到生活的意义，就会变得抑郁，陷入虚无主义。 高刺激娱乐并不能创造更多快乐，而是以平淡生活之乐为代价。 娱乐提供的刺激，应该与生活本身的刺激在同一个层级。这样娱乐与生活才会相互融合，相互增益。 诸葛亮说，“非静无以成学”，就是因为娱乐方式与生活状态要相匹配。学习的过程中，生活是相对单调的，人就应该选择相对恬静娱乐方式，娱乐才不会喧宾夺主。 娱乐最根本的使命就是让身心放松。 有人认为娱乐应该是有意义的、有价值的，其实这不是娱乐的核心目标。 一个合格的娱乐方式，让人心情愉悦，头脑轻松就够了。 2.2 什么行为符合长期利益人如果没有行为指南，就如同舰船在大海航行没有导航，只能随波逐流，接受环境和命运的摆布。 只有当人知道什么行为符合长期利益，才能有所为、有所不为，这就是自律。 2.2.1 计划目标就是长期利益的集中体现，符合目标的行为就做，不符合目标的行为就不错，事情不就解决了？ 问题在于，人的大脑最善长遗忘。 连目标都忘了，何谈用它做指导？ 遗忘是大脑的自我保护机制。大脑的资源是有限的，它必须的过往的东西遗忘掉，才有空间容纳当前的信息，以适应当前的环境，不被环境消灭。 任何不被使用的知识和技能，都免不了被遗忘的命运。 用目标做行为指南，必然要对抗遗忘。历史上有很多伟大的对抗遗忘的例子，吴王夫差命人侍立宫门，每逢夫差出入，便发问“夫差，你忘记杀父之仇了吗？”三年之后，夫差打败越国。越王勾践呢，每天的卧薪尝胆，提醒自己“你忘记所受的屈辱了吗？”十六年之后打败吴国，报仇雪恨。 只要不忘记目标，目标就是优秀的行为指南。 具体化 把目标分解成计划。 形象化 大脑对图片更敏感，对文字不敏感。把自己的目标明确地、醒目地打印出来，贴在自己最常出入的地方。 逆向化 大脑对损失的敏感，远远大于对利益的追求。夫差勾践都用屈辱来提醒自己，我们也可以用自己的身材照片、最低工资单、最差成绩单这些“耻辱”来激发自己，同时认清现实。 Deadline 给每个小目标设置结束时间，这种外加的紧迫感会提升对目标的记忆。 赋予权重 反复提醒自己，目标达不成后果会非常严重，激发危机意识。 如果没有计划，大脑无所适从，每次都根据当前的情绪做出决断，消耗大量意志力，效果极其不稳定。计划可以有效解决这个问题。 计划是知识与经验的凝结，用于意志力的代偿。 我们制定计划时，一定是综合分析了资源、环境、目的，以及以往的经验，制定一个可行的方案，让自己在混乱中有章可循。在湍急的河流中，有渡河的绳索。 在制定计划时，我们是理性的，有全局视野。但我们亲自下场战斗时，就容易受环境和突发事件的影响，陷入盲目的环境和疲惫的状态中，此时计划就能帮助我们走出困境。 因此，计划是理性对非理性的代偿，意志对惰性的代偿。 2.2.2 正反馈有人提出，借鉴游戏的设计模式，通过设计反馈来规范行为。比如，读一本书，奖励自己一件衣服；考90分，奖励自己一次郊游；玩一次游戏，罚50元钱；等等 如此一来，就可以把自律的事情和正向的反馈联系起来，就能达到自然而然的自律。 在一方法，我曾尝试过，但很难坚持，因为太过于繁琐。 这一方面背后的规律是存在的，即：人倾向于做有正反馈的事情。 我们的确应该有意识地培养自律的快感。大多数人，很喜欢苦拼，熬夜学习，拖着病体工作，大脑就形成了一个印象，自律等于自残。因此，大脑会千方百计地找理由逃避自律，一有机会就会放纵。 所以，我们应该逃避痛苦式、透支式自律，这样的自律只能带来更大的反弹，一定要建立快乐式自律。 及时休息。工作30分钟左右，就让大脑休息一会，伸伸懒腰，活动一下，清清缓存。不要给大脑自律=疲惫印象。 积极暗示。每次自律的完成工作后，给自己积极的心理暗示，“自律的感觉真棒。空气清新，精神爽朗” 拒绝透支。不要把日程排满，精力耗光。饱有余力是最有韧性的状态。 总之，有意识的培养自律的正反馈，慢慢自己会爱上自律。 2.2.3 良知有人说，没有强烈的目标，就没有自律。还有人说，没有在事业上找到发自内心的喜欢，就没有自律。这些人都只看到了问题了一个侧面，而无限放大它的重要性。 对芸芸众生而言，目标并不是时常都清晰，对事业的快感也会有起伏，难到就不能有自律了吗？ 非也。 良知是最佳的行动导引。 良心是内心里一个有棱角的东西，平常它静静不动，一旦干坏事，它便转动起来，刺痛我们。坏事干多了，良心被磨圆了，不就没感觉了。 “致良知”的关键在于“毋自欺”，把良知当作严明的法官，自己如同被告，丝毫不去掩饰。下如此功夫，便是心学着力之处。 千圣皆过影，良知乃吾师。—— 王阳明 把良知当最高法官，完全服从良知的指挥，就能做到“随心所欲不逾矩”，也能做到“此心安处是吾乡”。 相比前两个行动指南，良知是更稳定、更灵敏、更底层的指引，因此是我首推的自律方法。而且良知越用越灵敏，功效越大。 在万事万物上，以良知为至高法令，这样做几近圣人，区区自律不在话下。 2.2.4 不舒适人的大脑常常欺哄自己，为不自律找各种理由，因此“良知”有时会失效。 短期来看，能显著提升自律水平的行为指南是主动“选择不舒适” 如果舒适，则由之即可。正是因为不舒适，才需要自律。 正是不想上课，才需要自律逼自己上课。想打游戏，才需要自律帮自己不打游戏。正如村上春树所说，“今天不想跑，所以才去跑。”因为不想坚持，坚持才有意义。 人的成长就是个舒适区不断扩大的过程。舒适区扩长就是要变不舒适为舒适，因此要战胜“不适”。 根据“行动塑造大脑”的原则，每战胜一点不舒适，就是给自己的大脑创造新的有益的连接，大脑就会变得更强壮。 以不适为食，壮我之精神意志。这就是自律的精神内核。 2.3 如何应用？2.3.1 标本兼治在应用时，我想纠正一个错误。很多认以为纠正思想的错误是治本，具体的策略只是治标，治本比治标重要。 这种思想在晚清极度盛行，当时的知识分子认为修身养性是本，军农工商等职业技能都是标，务本比治标重要。他们以为靠爱国激情，可以打败西方船坚炮利。结果呢，人家治标的暴打治本的。 同样，在自律的问题上，如果你瞧不起具体的方法，现实也将会暴打你这样务虚的人。 “给我一个支点，我能翘起整个地球”，杠杆原理是背后的知识，支点就是具体的方法和计划。任何思想的落实都需要找到它的支点。 任何问题的产生都是思想与环境想结合的产物。单单解放思想，不注重具体方法与步骤，就会导致大跃进式的失败。而具体的方法和步骤只能在分析环境、分析具体问题之后给出。 半部论语不能治中国，三卷资本论也救不了中国。只有思想与策略结合，治本与治标结合，思想的威力才能爆发出来。 任何问题的解决都需要标本兼治。只治标：问题没有根本解决。只治本：系统阻力过大，不稳定性增加，治本之策无法有效落实。 标本兼治，即可解燃眉之急，又可根除隐患。 在学习过程中，分析自己大量的时间都流到哪里去了，找出自己的时间黑洞，找出学习中的所有干扰项和诱惑物，针对性地曲突徙薪，能立刻改善当前的症状，增强自身信心。 3.3.2 低刺激生活低刺激生活是自律的基础。 生物为什么会进化出刺激感知能力？ 答案是显而异见的，38亿年前，蓝绿菌学会感知光线，能透过光合作用获取能量；20亿年前，草履虫进化出碰撞感知能力，可以躲避危险。生物进化出感知能力，是为了趋利避害，存活下去。 一、食欲刺激 至于人类，我们首先来看味觉，味觉的产生就是为了分辨健康食物和有害食物。成熟的柿子是甜的，不成熟的柿子是涩的。原因在于前着有大量人体需要的糖分，后者中的鞣酸对人有毒。新鲜的土豆在煮熟后是香的，发芽的土豆却是苦的。因为前者有人体需要的淀粉，后者中的龙葵碱对人有巨毒。 味觉的产生，就是为了引导人找到需要的营养素，并远离有毒物质。 适当的调味可以补充人体所需的营养，过度的调味则导致感知功能的失常。 学校附近的食堂都是高油、高盐、高味精的，因为这三高是好吃的法宝，非常迎合学生的口味。在重口味的掩饰之后，我们的味蕾无法分辨食物的新鲜程度，也无法判断食物是否有毒，是否包含发芽的土豆，是否有重金属超标。 味觉产生的原因是寻找人体需要的营养素，在此之外的应用就是为了刺激而刺激。重口味首先会让自己的味觉混乱，无法识别人体的需要，导致健康问题。其次导致味觉失常，无法适应清淡食物，面对清淡食物，甚至想要呕吐。 二、性欲刺激 性欲产生的根本原因就是为了生育。随着生产力的提高，人类有了更多的富余精力和时间。人类发明了更强烈的性刺激。高频率、高强度的性刺激可能导致性瘾，甚至性功能障碍。 一切上瘾行为都会有脱敏反应（desensitization），由于多巴胺D2受体水平下降，导致成瘾者对快感反应下降，使得他们对能提升多巴胺的事物更加‘饥饿’。同一种刺激使自己变得麻木。刺激的强度不够，需要进一步升级。上瘾者需要搜索更多的色情片和内容，才能引起同等程度的高潮。结果会导致真实的性爱无法唤醒性欲，即阳痿。 三、信息刺激 人本能会都进行信息过滤，对与生存相关的信息敏感。 信息开始为了刺激而刺激。由于刺激水平的激增，我们的应激水平也水涨船高。我们从一个平台刷到另一个平台，从一个高刺激跳到另一个高刺激。高刺激信息并不缺乏，一旦某个信息稍显枯燥，我们就立马切换。单调是我们最无法忍受的事情。 于是我们连1000余字的文章也没有耐心看完，10分钟的视频也要跳着看，生活被碎片化充斥，被高刺激淹没。 生活中除了高刺激带来的片刻满足，其他的一切都是灰蒙蒙的，都是毫无生机的。那些与我们生存相关的信息，我们的生活信息、环境信息已经不能吸引我们的眼球。我们失去了生活感知能力，无法从生活获得满足感。 生物之所以感知刺激，就是为了适应生活。为了追求刺激而刺激，带来刺激的异化，使刺激失去的生活指挥棒的功能，反而走到了生活的对立面，变成单纯的脑嗨机器。 为了刺激而刺激，不会生产快乐，它只是透支了生活本来的快乐，它的精彩是因为偷窃了生活本来的色彩。 熬夜打游戏看网文很快乐，但是不熬夜，我本来可以早起，可以欣赏日出，感受早晨的露水，可以郊游野炊，可以游泳运动，可以感受很多的快乐。 刺激存在的意义就是为生活服务，为了刺激而刺激，脱离生活去追求刺激，会让生活失色，让人的感知系统失常，让人陷入短暂快乐与长久痛苦的循环之中。 当我们有意识地选择低刺激生活，生活本身的趣味才会显露出来，我们才能享受天然的快乐和隽永的美感。只有还原了生活本色，才可能热爱生活。 2.3.3 休息 谁不会休息，谁就不会工作。 —— 列宁 我们常常以为自律的关键是如何更努力地工作，然而自律的关键其实是如何正确地休息。 大多数的自律者，成功就成功在休息上，失败也失败在休息上。 人饿了都会去吃；渴了都会去喝，累了却不去休息，结果大脑必然产生焦虑和烦躁，于是切换到非理性工作模式，自律就荡然无存了。 因此，休息是日常生活中最大的自律杀手，也是最隐蔽的杀手。 上文已经提到，大脑没有淋巴系统清理垃圾，只有睡眠能清理。因此休息和睡眠是大脑正常工作的前提。 如何正确休息呢？ 每隔30分钟提醒自己闭目一分钟，中间伴随伸懒腰，深呼吸。这一过程大幅放松大脑，减少脑部废物的积累。 每隔2个小时走动一下，也就是上午，下午各有一次活动的时间，放松身心。 在床上不娱乐，可以看书、听课、背单词。因为睡前记忆效果最好。中午和晚上饭后，都安排短时间的浅睡眠。 11点之前睡觉，有固定的睡眠时间。 天气冷的时候，睡觉泡脚。 2.3.4 精力管理人每天的精力不是均等分布的，而是波浪型分布。如图，起床清醒后，精力会迅速攀升，在上午达到高峰，然后随时间幂指式递减。 午休和冥想都会清理大脑进程，清空缓存，和睡眠一样，会恢复大脑一定精力，提升一天的精力总值。 而精力管理的目标并不是单单提升精力，而是充分利用精力和时间做最有价值的事情。 宽度代表时间；高度代表精力 如上图所示，精力管理的目标是：在精力曲线与时间围成的区间内，填充总价值量最多的任务块。 任务一：开拓创新型任务。精力消耗量大（高度很高），持续时间有限，价值很高。 任务二：维护型任务。精力消耗量低（高度低），持续时间长，价值一般。 任务三：一般事情。精力消耗量低（高度底），持续时间短，价值较低。 干扰项：趣事。即粉色区块，需单独说明。 趣事有很强的趣味性，也会提供一定的价值，就像看视频、微博、微信、知乎一样，提供大量的趣味和零散的信息和知识。它们刚开始时消耗精力极少，用户粘性强，持续时间长，后期消耗精力大。 为什么后期消耗精力大？一方面快感也会消耗精力的，另一方面由于价值供应不足，人就会因为价值的缺失而产生焦虑，消耗精力。最后，人为了填充价值的缺失，就会增加趣事的摄入量，导致消耗更多精力。 1、根据精力曲线的形状和任务的特点，人最佳的方案是：在上午时完成任务一，中午是完成任务二，晚上完成任务三。 上午：完成最重要、最有挑战性的开拓型任务。 下午：完成持续性、维护性、一般性任务。 晚上：完成机械型、重复型任务，或单纯信息摄入型任务，比如听听讲座，看学习视频等。 2、根据干扰项的特点，人要尽量推迟插入干扰项的时间，因为它们持续时间长，消耗大量精力，导致其余任务很难完成。 同时，根据边际效用递减法则，娱乐会在刚开始时产生大量快感，后期也会变得枯燥。人沉迷其中，主要是因为惯性。因此最具性价比的休闲方式是推迟娱乐的开始时间，控制娱乐的结束时间。设定边界是极好的方法。 3. 总结核心原则： 信息是行为的导火索，Less is more. 理性的目的是在可控的基础上提高效率。 用行为塑造大脑。 自制力强的人，强在预防，而不是强在救灾。 低刺激生活是自律的基础]]></content>
      <tags>
        <tag>discipline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存设计模式]]></title>
    <url>%2F2018%2F06%2F15%2Fcache-design%2F</url>
    <content type="text"><![CDATA[一种经典的错误做法：先删除缓存，再更新数据库，再加载最新数据到缓存中。 错误原因：假如，有两个并发操作，一个是更新、一个是查询。更新操作先删除了缓存，然后，查询操作只得去DB拿数据，接着，更新操作才更新DB。这样就产生了脏数据。 缓存更新模式SoR(system-of-record)：数据源，实际存放数据的地方。 缓存更新模式主要分为两类： Cache-Aside Cache-As-SoR(Read Through、Write Through、Write Behind) Cache-Aside 看图：Cache在前，业务代码围绕着Cache写： 12345// 读场景：先从缓存中获取数据if(value == null) &#123; value = loadFromSoR(key); myCache.put(key, value);&#125; 1234// 写场景：先将数据写入SoRwriteToSoR(key, value);// 失效缓存，然后下次读时再加载缓存myCache.invalidate(key); Cache-Aside 适合用 AOP实现。 注意：这里的更新是先更新数据库，成功后，再让缓存失效。 现在，不删除缓存了，读操作依然可以拿到老数据，然后更新操作使缓存失效，后续的查询就都是正确的了。 123为什么不是写完数据库后更新缓存？—— 主要是怕两个并发的写操作导致脏数据。 123是不是这样就不会有并发问题了？不是！比如，读操作没有命中缓存，就去DB取数据，此时来了个更新操作，写完数据后让缓存失效，然后刚才那个读操作又把老数据加载进去了，造成了脏读！但是！！实际上出现的概率非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。 要么通过2PC或是Paxos协议保证一致性，要么就是拼命的降低并发时脏数据的概率，而Facebook使用了这个降低概率的玩法，因为2PC太慢，而Paxos太复杂。当然，最好还是为缓存设置上过期时间 1234567Cache-Aside 并发场景怎么办？- 如果是用户维度的数据(如订单数据、用户数据)，因为并发情况少，可以不考虑，加上过期时间来解决- 对于如商品这种基础数据，可以考虑使用canal订阅binlog，来进行增量更新分布式缓存，但是本地缓存更新会有延迟，需要根据不一致容忍度设置合理的过期时间- 读服务场景，可考虑使用一致性哈希，将相同的操作负载均衡到同一个实例，从而减少并发机率，或设置较短的过期时间。 Cache-As-SoR即把Cache看作是SoR，业务代码只操作Cache，然后由Cache实现对SoR的真实读写。 Read-Through当缓存失效时(过期或LRU换出)，Cache Aside是由调用方负责把数据加载入缓存中，而 Read-Through 是由缓存服务自身来加载，对应用是透明的。 需要配置一个 CacheLoader 组件来回源到 SoR 加载源数据。Guava Cache、Ehcache 3.x 都支持该模式。 优点： 业务代码更简洁。 解决了 Dog-pile effect，即当某个缓存失效时，又有大量请求没命中从而回源到后端，会导致后端压力过大，此时限定一个请求去拿即可。 Write-Through和Read-Through类似，只是把缓存更新操作挪到了更新操作中。 业务代码首先调用Cache写(新增/修改)数据，然后由Cache负责写SoR，而不是由业务代码(注意：SoR写入成功后，再写入Cache)。 Write-Behind 回写模式这玩意其实就是Linux文件系统的Page Cache算法！ 不同于 Write-Through 是同步写 SoR 和 Cache，Write-Behind 是异步写。异步之后可以实现批量写、合并写、限时、限流。让 IO 操作奇快无比！ 但是，带来的问题就是数据一致性问题。数据不是强一致的，可能会丢失(非正常关机)。反正Trade-Off吧！ 另外，Write-Back 实现逻辑比较复杂，因为它需要track有哪些数据是被更新了的，需要刷到持久层上。操作系统的write-back机制会在仅当这个Cache需要失效的时候，才会被真正持久化，比如，内存不够了、进程退出了等等，所谓 Lazy Write。 上面，我们没有考虑缓存（Cache）和持久层（Repository）的整体事务的问题。比如，更新Cache成功，更新数据库失败了怎么吗？或是反过来。关于这个事，如果你需要强一致性，你需要使用“两阶段提交协议”——prepare, commit/rollback，比如Java 7 的XAResource，还有MySQL 5.7的 XA Transaction，有些cache也支持XA，比如EhCache。当然，XA这样的强一致性的玩法会导致性能下降，关于分布式的事务的相关话题，你可以看看《分布式系统的事务处理》一文。 参考资料 https://coolshell.cn/articles/17416.html 《亿级流量网站架构核心技术》]]></content>
      <tags>
        <tag>cache, design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo的SPI扩展机制]]></title>
    <url>%2F2018%2F06%2F12%2Fdubbo-spi%2F</url>
    <content type="text"><![CDATA[Dubbo 微内核 + 插件 通常可扩展的实现有下面几种: Factory模式 IoC容器 OSGI容器 Dubbo作为一个框架，不希望强依赖其他的IoC容器，比如Spring，Guice。OSGI也是一个很重的实现，不适合Dubbo。最终Dubbo的实现参考了Java原生的SPI机制，但对其进行了一些扩展，以满足Dubbo的需求。 Dubbo的SPI机制Java SPI有以下的不足: 需要遍历所有的实现，并实例化，然后我们在循环中才能找到我们需要的实现。 配置文件中只是简单的列出了所有的扩展实现，而没有给他们命名。导致在程序中很难去准确的引用它们。 不提供类似于Spring的IOC和AOP功能 扩展很难和其他的框架集成，比如扩展里面依赖了一个Spring bean，原生的Java SPI不支持 Dubbo扩展点机制基本概念扩展点(Extension Point)是一个Java的接口。 扩展(Extension)扩展点的实现类。 扩展实例(Extension Instance)扩展点实现类的实例。 扩展自适应实例(Extension Adaptive Instance)扩展代理类，其实就是一个Extension的代理，它实现了扩展点接口。在调用扩展点的接口方法时，会根据实际的参数来决定要使用哪个扩展。 @SPI@SPI，表明该接口是一个扩展点。可以被Dubbo的ExtentionLoader加载。 @Adaptive@Adaptive 自适应方法。代理会为该方法生成对应的代码。方法内部会根据方法的参数，来决定使用哪个扩展。 ExtentionLoader类似于Java SPI的ServiceLoader，负责扩展的加载和生命周期维护。 扩展别名和Java SPI不同，Dubbo中的扩展都有一个别名，用于在应用中引用它们。比如 12random=com.alibaba.dubbo.rpc.cluster.loadbalance.RandomLoadBalanceroundrobin=com.alibaba.dubbo.rpc.cluster.loadbalance.RoundRobinLoadBalance 其中的random，roundrobin就是对应扩展的别名。这样我们在配置文件中使用random或roundrobin就可以了。 加载路径和Java SPI从/META-INF/services目录加载扩展配置类似，Dubbo也会从以下路径去加载扩展配置文件: META-INF/services/：应用级扩展配置（比如定点项目的扩展）。 META-INF/dubbo/：框架外部扩展配置（比如架构组的扩展）。 META-INF/dubbo/internal/：框架内置扩展配置。 Dubbo的LoadBalance扩展点解读Dubbo中的一个服务，通常有多个Provider，consumer调用服务时，需要在多个Provider中选择一个。这就是一个LoadBalance。我们一起来看看在Dubbo中，LoadBalance是如何成为一个扩展点的。 LoadBalance接口123456@SPI(RandomLoadBalance.NAME)public interface LoadBalance &#123; @Adaptive("loadbalance") &lt;T&gt; Invoker&lt;T&gt; select(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) throws RpcException;&#125; @SPI注解有一个默认参数 random的定义在配置文件META-INF/dubbo/internal/com.alibaba.dubbo.rpc.cluster.LoadBalance中:1234random=com.alibaba.dubbo.rpc.cluster.loadbalance.RandomLoadBalanceroundrobin=com.alibaba.dubbo.rpc.cluster.loadbalance.RoundRobinLoadBalanceleastactive=com.alibaba.dubbo.rpc.cluster.loadbalance.LeastActiveLoadBalanceconsistenthash=com.alibaba.dubbo.rpc.cluster.loadbalance.ConsistentHashLoadBalance 可以看到Dubbo提供了4种负载均衡的实现，我们可以通过xml文件，properties文件，JVM参数显式的指定一个实现。如果没有，默认使用随机。 @Adaptive注解修饰select方法，表明方法select方法是一个可自适应的方法。Dubbo会自动生成该方法对应的代码。 当调用select方法时，会根据具体的方法参数来决定调用哪个扩展实现的select方法。@Adaptive注解的参数loadbalance表示方法参数中的loadbalance的值作为实际要调用的扩展实例。 但奇怪的是，我们发现select的方法中并没有loadbalance参数，那怎么获取loadbalance的值呢？ select方法中还有一个URL类型的参数，Dubbo就是从URL中获取loadbalance的值的。这里涉及到Dubbo的URL总线模式，简单说，URL中包含了RPC调用中的所有参数。URL类中有一个Map&lt;String, String&gt; parameters字段，parameters中就包含了loadbalance。 获取LoadBalance扩展1LoadBalance lb = ExtensionLoader.getExtensionLoader(LoadBalance.class).getExtension(loadbalanceName); 使用ExtensionLoader.getExtensionLoader(LoadBalance.class)方法获取一个ExtensionLoader的实例，然后调用getExtension，传入一个扩展的别名来获取对应的扩展实例。 自定义一个LoadBalance扩展https://github.com/vangoleo/dubbo-spi-demo 1234567package com.dubbo.spi.demo.consumer;public class DemoLoadBalance implements LoadBalance &#123; @Override public &lt;T&gt; Invoker&lt;T&gt; select(List&lt;Invoker&lt;T&gt;&gt; invokers, URL url, Invocation invocation) throws RpcException &#123; System.out.println("DemoLoadBalance: Select the first invoker..."); return invokers.get(0); &#125; 添加文件:META-INF/dubbo/com.alibaba.dubbo.rpc.cluster.LoadBalance。文件内容如下: 1demo=com.dubbo.spi.demo.consumer.DemoLoadBalance 1&lt;dubbo:reference id="helloService" interface="com.dubbo.spi.demo.api.IHelloService" loadbalance="demo" /&gt; 总结 对Dubbo进行扩展，不需要改动Dubbo的源码 自定义的Dubbo的扩展点实现，是一个普通的Java类，Dubbo没有引入任何Dubbo特有的元素，对代码侵入性几乎为零。 将扩展注册到Dubbo中，只需要在ClassPath中添加配置文件。使用简单。而且不会对现有代码造成影响。符合开闭原则。 dubbo的扩展机制设计默认值：@SPI(“dubbo”) 代表默认的spi对象 Dubbo的扩展机制支持IoC,AoP等高级功能 Dubbo的扩展机制能很好的支持第三方IoC容器，默认支持Spring Bean，可自己扩展来支持其他容器，比如Google的Guice。 切换扩展点的实现，只需要在配置文件中修改具体的实现，不需要改代码。使用方便。]]></content>
      <tags>
        <tag>Dubbo, SPI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[人生公式]]></title>
    <url>%2F2018%2F05%2F06%2Flife-formula%2F</url>
    <content type="text"><![CDATA[Happiness = Health + Wealth + Good Relationships Health = Exercise + Diet + Sleep Exercise = High Intensity Resistance Training + Sports + Rest Diet = Natural Foods + Intermittent Fasting + Plants Sleep = No alarms + 8-9 hours + Circadian Rhythms Wealth = Income + Wealth * (Return on Investment) Income = Accountability + Leverage + Specific Knowledge Accountability = Personal Branding + Personal Platform + Taking Risk? Leverage = Capital + People + Intellectual Property Specific Knowledge = Knowing how to do something that society cannot yet easily train other people to do RoI = Buy-and-Hold + Valuation + Margin of Safety]]></content>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL优化技巧]]></title>
    <url>%2F2018%2F04%2F12%2FMySQL-turning%2F</url>
    <content type="text"><![CDATA[1. EXPLAIN type列，连接类型。一个好的sql语句至少要达到range级别。杜绝出现all级别 key列，使用到的索引名。如果没有选择索引，值是NULL。可以采取强制索引方式 key_len列，索引长度 rows列，扫描行数。该值是个预估值 extra列，详细说明。注意常见的不太友好的值有：Using filesort, Using temporary 2. SQL语句中IN包含的值不应过多MySQL对于IN做了相应的优化，即将IN中的常量全部存储在一个数组里面，而且这个数组是排好序的。但是如果数值较多，产生的消耗也是比较大的。再例如：select id from table_name where num in(1,2,3) 对于连续的数值，能用 between 就不要用 in 了；再或者使用连接来替换。 3. 不要使用SELECT *4. 当只需要一条数据的时候，使用limit 1这是为了使EXPLAIN中type列达到const类型 5. 如果排序字段没有用到索引，就尽量少排序6. 如果限制条件中其他字段没有索引，尽量少用or必须where中所有的or条件都是独立索引，否则不走索引很多时候使用 union all 或者是union(必要的时候)的方式来代替“or”会得到更好的效果 7. 尽量用union all代替unionunion和union all的差异主要是前者需要将结果集合并后再进行唯一性过滤操作，这就会涉及到排序，增加大量的CPU运算，加大资源消耗及延迟。当然，union all的前提条件是两个结果集没有重复数据。 8. 不使用ORDER BY RAND()1select id from `table_name` order by rand() limit 1000; 上面的sql语句，可优化为 1select id from `table_name` t1 join (select rand() * (select max(id) from `table_name`) as nid) t2 on t1.id &gt; t2.nid limit 1000; 9. 区分in和exists， not in和not exists1select * from 表A where id in (select id from 表B) 上面sql语句相当于 1select * from 表A where exists(select * from 表B where 表B.id=表A.id) 区分in和exists主要是造成了驱动顺序的改变（这是性能变化的关键），如果是exists，那么以外层表为驱动表，先被访问，如果是IN，那么先执行子查询。所以IN适合于外表大而内表小的情况；EXISTS适合于外表小而内表大的情况。 关于not in和not exists，推荐使用not exists，不仅仅是效率问题，not in可能存在逻辑问题。如何高效的写出一个替代not exists的sql语句？ 原sql语句 1select colname … from A表 where a.id not in (select b.id from B表) 高效的sql语句 1select colname … from A表 Left join B表 on a.id = b.id where b.id is null 10. 使用合理的分页方式以提高分页的效率1select id,name from table_name limit 866613, 20 使用上述sql语句做分页的时候，可能有人会发现，随着表数据量的增加，直接使用limit分页查询会越来越慢。 优化的方法如下：可以取前一页的最大行数的id，然后根据这个最大的id来限制下一页的起点。比如此列中，上一页最大的id是866612。sql可以采用如下的写法： 1select id,name from table_name where id&gt; 866612 limit 20 11. 分段查询在一些用户选择页面中，可能一些用户选择的时间范围过大，造成查询缓慢。主要的原因是扫描行数过多。这个时候可以通过程序，分段进行查询，循环遍历，将结果合并处理进行展示。 12. 避免在 where 子句中对字段进行 null 值判断对于null的判断会导致引擎放弃使用索引而进行全表扫描。 13. 不建议使用%前缀模糊查询创建全文索引的sql语法是： 1ALTER TABLE `table_name` ADD FULLTEXT INDEX `idx_user_name` (`user_name`); 使用全文索引的sql语句是： 1select id,fnum,fdst from table_name where match(user_name) against('zhangsan' in boolean mode); 注意：在需要创建全文索引之前，请联系DBA确定能否创建。同时需要注意的是查询语句的写法与普通索引的区别 MySQL 5.6 以前的版本，只有 MyISAM 存储引擎支持全文索引； MySQL 5.6 及以后的版本，MyISAM 和 InnoDB 存储引擎均支持全文索引; 只有字段的数据类型为 char、varchar、text 及其系列才可以建全文索引。 MySQL 中的全文索引，有两个变量，最小搜索长度和最大搜索长度，对于长度小于最小搜索长度和大于最大搜索长度的词语，都不会被索引。通俗点就是说，想对一个词语使用全文索引搜索，那么这个词语的长度必须在以上两个变量的区间内。 show variables like ‘%ft%’; // InnoDBinnodb_ft_min_token_size = 3;innodb_ft_max_token_size = 84; 两种全文索引 自然语言的全文索引自然语言搜索引擎将计算每一个文档对象和查询的相关度。这里，相关度是基于匹配的关键词的个数，以及关键词在文档中出现的次数。在整个索引中出现次数越少的词语，匹配时的相关度就越高。相反，非常常见的单词将不会被搜索，如果一个词语的在超过 50% 的记录中都出现了，那么自然语言的搜索将不会搜索这类词语。上面提到的，测试表中必须有 4 条以上的记录，就是这个原因。 布尔全文索引在布尔搜索中，我们可以在查询中自定义某个被搜索的词语的相关性，当编写一个布尔搜索查询时，可以通过一些前缀修饰符来定制搜索。 MySQL 内置的修饰符，上面查询最小搜索长度时，搜索结果 ft_boolean_syntax 变量的值就是内置的修饰符，下面简单解释几个，更多修饰符的作用可以查手册 + 必须包含该词 - 必须不包含该词 提高该词的相关性，查询的结果靠前 &lt; 降低该词的相关性，查询的结果靠后 (*)星号 通配符，只能接在词后面 对于上面提到的问题，可以使用布尔全文索引查询来解决，使用下面的命令，a、aa、aaa、aaaa 就都被查询出来了。 1select * test where match(content) against('a*' in boolean mode); MySQL 的全文索引最开始仅支持英语，因为英语的词与词之间有空格，使用空格作为分词的分隔符是很方便的。亚洲文字，比如汉语、日语、汉语等，是没有空格的，这就造成了一定的限制。不过 MySQL 5.7.6 开始，引入了一个 ngram 全文分析器来解决这个问题，并且对 MyISAM 和 InnoDB 引擎都有效。 事实上，MyISAM 存储引擎对全文索引的支持有很多的限制，例如表级别锁对性能的影响、数据文件的崩溃、崩溃后的恢复等，这使得 MyISAM 的全文索引对于很多的应用场景并不适合。所以，多数情况下的建议是使用别的解决方案，例如 Sphinx、Lucene 等等第三方的插件，亦或是使用 InnoDB 存储引擎的全文索引。 使用全文索引前，搞清楚版本支持情况； 全文索引比 like + % 快 N 倍，但是可能存在精度问题； 如果需要全文索引的是大量数据，建议先添加数据，再创建索引； 对于中文，可以使用 MySQL 5.7.6 之后的版本，或者第三方插件。 14. 避免在where子句中对字段进行表达式操作15. 避免隐式类型转换16. 对于联合索引来说，要遵守最左前缀法则17. 必要时可以使用force index来强制查询走某个索引18. 注意范围查询语句对于联合索引来说，如果存在范围查询，比如between,&gt;,&lt;等条件时，会造成后面的索引字段失效。 19. 关于JOIN优化 LEFT JOIN A表为驱动表 INNER JOIN MySQL会自动找出那个数据少的表作用驱动表 RIGHT JOIN B表为驱动表 注意：MySQL中没有full join，可以用以下方式来解决 1234select * from A left join B on B.name = A.name where B.name is null union allselect * from B; 1. 尽量使用inner join，避免left join参与联合查询的表至少为2张表，一般都存在大小之分。如果连接方式是inner join，在没有其他过滤条件的情况下MySQL会自动选择小表作为驱动表，但是left join在驱动表的选择上遵循的是左边驱动右边的原则，即left join左边的表名为驱动表。 2. 合理利用索引被驱动表的索引字段作为on的限制字段。 3. 利用小表去驱动大表 4. 巧用STRAIGHT_JOINinner join是由mysql选择驱动表，但是有些特殊情况需要选择另个表作为驱动表，比如有group by、order by等「Using filesort」、「Using temporary」时。STRAIGHT_JOIN来强制连接顺序，在STRAIGHT_JOIN左边的表名就是驱动表，右边则是被驱动表。在使用STRAIGHT_JOIN有个前提条件是该查询是内连接，也就是inner join。其他链接不推荐使用STRAIGHT_JOIN，否则可能造成查询结果不准确。 这个方式有时可能减少3倍的时间。]]></content>
      <tags>
        <tag>MySQL,turning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程06线程池]]></title>
    <url>%2F2018%2F04%2F06%2Fconcurrent-06-thread-pool%2F</url>
    <content type="text"><![CDATA[线程池线程池的好处 重用存在的线程，减少对象创建、消亡的开销，性能佳，降低资源消耗； 可有效控制最大并发线程数，提高系统资源利用率，同时可以避免过多资源竞争，避免阻塞，提高响应速度； 提供定时执行、定期执行、单线程、并发数控制等功能，以达到提高线程的可管理性。 Executors利用工厂模式向我们提供了4种线程池实现方式，但是并不推荐使用，原因是使用Executors创建线程池不会传入相关参数而使用默认值所以我们常常忽略了那些重要的参数（线程池大小、缓冲队列的类型等），而且默认使用的参数会导致资源浪费，不可取。 ThreadPoolExecutorThreadPoolExecutor 类继承结构是： Executor(I) &lt;- ExecutorService(I) &lt;- AbstractExecutorService(C) &lt;- TreadPoolExecutor 构造器中各个参数的含义： corePoolSize：核心池的大小。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了预创建线程的方法，即在没有任务到来之前就创建 corePoolSize 个线程或者 一个线程： prestartCoreThread() : 预创建一个核心线程，使其闲置等待工作。 prestartAllCoreThreads() : 启动所有核心线程，导致它们空闲地等待工作。 默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； maximumPoolSize：线程池最大线程数，它表示在线程池中最多能创建多少个线程； 当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0； unit workQueue： 一个阻塞队列，用来存储等待执行的任务，一般来说，这里的阻塞队列有以下几种选择： ArrayBlockingQueue：基于数组的先进先出队列，此队列创建时必须指定大小； LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE； SynchronousQueue ：这个队列比较特殊，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。 threadFactory：线程工厂，主要用来创建线程。 创建线程的工作交给ThreadFactory来完成。要使用线程池，就必须要指定ThreadFactory。 RejectedExecutionHandler：当提交给线程池的某一个新任务无法直接被线程池中“核心线程”直接处理，又无法加入等待队列，也无法创建新的线程执行；又或者线程池已经调用shutdown()方法停止了工作；又或者线程池不是处于正常的工作状态；这时候ThreadPoolExecutor线程池会拒绝处理这个任务，触发创建ThreadPoolExecutor线程池时定义的RejectedExecutionHandler接口的实现 ThreadPoolExecutor.AbortPolicy：丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行新提交的任务。 submit()接收任务参数，并将参数封装为FutureTask任务类 将封装好的FutureTask提交到execute()中 结论：submit()真正实现的任务处理流程跟execute()一样，也可以说submit()就是调用了execute() 提交任务到线程池； 线程池判断核心线程池里的线程是否都在执行任务，如果不是，则创建一个新的工作线程来执行任务。如果核心线程池里的线程都在执行任务，则进入下一个流程。 线程池判断工作队列是否已满。如果工作队列没有满，则将新提交的任务储存在这个工作队列里。如果工作队列满了，则进入下一个流程。 线程池判断其内部线程是否都处于工作状态。如果没有，则创建一个新的工作线程来执行任务。如果已满了，则交给饱和策略来处理这个任务。]]></content>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何变得富有]]></title>
    <url>%2F2018%2F04%2F06%2Fhow-to-be-rich%2F</url>
    <content type="text"><![CDATA[1. 寻求财富，而不是金钱或地位 财富是在你睡着时也能帮你赚钱的资产 财富是拥有在你睡觉时还能为你赚钱的资产。金钱由我们的时间和财富转化而来。地位是你在社会阶层中的位置。 财富就是工厂、机器人、24h运行的程序，也可以是你银行里的资金，正在被再投资，不断生产价值。甚至房子也是一种财富，因为你可以把房子出租来赚取租金 财富可以给你带来自由 对我来说获取财富的目的就是获得自由，而不是为了购买皮草大衣、开法拉利等等，这些东西会使你变得非常无聊，非常愚蠢 金钱是社会转移财富的方式 如果我们为社会创造价值，社会会说，“哦，谢谢你。对于您过去所做的工作，我们欠您一些东西。这是一点点借条。我们称之为钱。“ 财富是非常基础的一种东西，财富就是一些我们想要的东西，诸如食物、衣服、房子、车子、工具、去有趣的地方旅行等等。你可以在没有钱的情况之下就拥有财富，比如说假设你拥有一台机器可以按照命令帮你做一台车或是帮你煮晚餐，或是帮你洗衣服或是做任何你想要的事情，你压根儿不需要钱。然而如果你是在南极，在那边没有任何东西可以买，不管你有多少钱都没有用。 使得人们迷失的源头是金钱的抽象化，金钱不是财富，它只是我们用来转移财富的工具，但这个世界上并不是只有有限的财富。你可以创造更多财富，财富在人类历史上已经被无数次的创造与摧毁了。 假设你有拥有一台坏掉的老车，你可以选择虚度你的下一个夏天，或是把时间花在把你的车修回到正常的状态，你只要这样做就是在创造财富了。这个世界，特别是对你而言，多了一台完好的旧车与更富有的你，如果你卖掉你的车，你还可能可以得到更多。在修复你的老车的过程，你已经让你自己变得更富有，但并没有因此让任何人变得更穷。 有些人从大学毕业就觉得，或是被告知，他们需要找到一份工作，如同成为某个组织的一员一样重要。一个更直接的方式来说明这件事情是：你需要开始做一些人们想要的事物。但其实你不需要加入一家公司就可以做到这件事情，所有的公司都是一群人聚在一起，合力做出一些人们想要的东西，真正重要的事情是做出一些人们需要的东西，而不是加入一个组织。 然而公司并不是为了奖励想要做这种事情的人而设立，你不能跑去你老板面前说，我想要十倍努力地工作，所以你应该付我十倍的薪水。这是一个很直观的状况：即使你已经尽可能的努力，真正严重的问题是，这家公司并没有合适的方式去衡量你的产出。 另外在大公司里面薪水最高的人是高阶经理人，理由其实跟业务员一致，他们的表现可以被衡量。高阶经理人往往被赋予整个公司产出的责任。一般的员工的产出不容易被经常衡量，因此他们也不被期待要做更多去产出更多价值。但高阶经理人，跟业务员一样，必须要被数字衡量。一家公司的执行长完全责无旁贷，如果一家公司干的不好，那就是他干的不好。 如果一家公司可以非常精确地衡量所有员工的付出，并付出薪水，这无疑的是一种巨大的成功，许多员工可以因此获得更多报酬，将会更努力的工作。更重要的是，如此的公司将会吸引一些想要超级认真工作获取超级回报的人，它将会彻底击溃它的竞争者。 然而，公司并无法像是支付业务员那样支付所有员工的薪水。业务员单独工作，但大部分员工的工作是互相牵连的。假设一家公司制作消费者产品，工程师必须要设计一个可信赖、具备所有新特色的产品；然后工业设计师要为他设计一个美观的盒子，然后行销人员必须要说服所有人这是他们需要的东西。你怎麽知道这个产品的销售成果是来自于各个单位的贡献？或者，又有多少是来自于之前的产品所留下来的公司名声？世界上并没有方法去解构所有这些贡献，即使你可以完全了解所有消费者的心思，你依然无法搞懂这些错综复杂的因果关係。 如果你想要走的快一点，把你的工作跟一堆人绑在一起会是一个问题。在一个大团体里面，你的表现不是单独的被衡量，而且其他团体中的人还会减慢你的速度。 如果要变得富有，你必须要把你自己放在具备两种要素的环境之内：衡量与杠杆。你必须要在一个可以被衡量的位置上，否则你做再多都不会获得更多报酬。另外你必须要具备杠杆，这意味着你做的决定必须具有巨大的效果。 身份地位是我们社交游戏中的排名 有两个现代社会的人们都在玩的大型游戏，一个是金钱游戏，另一个是身份游戏。 这两个游戏区别在于：财富游戏不是零和游戏，而身份游戏是，为了赢得身份游戏你必须把别人比下去，而这会让你成为一个好斗易怒的人。 几千年前，狩猎采集者就生活在只有身份游戏的社会中，因为那时的财富贫乏而且根本无法积累保存，但是现代工业社会则早已并非如此 忽略玩地位游戏的人。他们通过攻击玩致富游戏的人来获得地位。 2. 为世界创造东西 财富不是要从别人那里拿东西，而是为世界创造东西 环顾四周，你会发现你身边的大部分东西都源于某一次发明创造。 实际上，现代文明中的大部分财富都是发明创造出来的 曾经有一段时间，石油是一种新的发明创造，使得洛克菲勒富裕起来。又有一段时间，汽车是一种新的发明创造，使亨利福特富裕起来。 自由市场是人类的内在天性 我们人类是唯一能在整个物种范围内大规模交换、分工、合作的动物，也正因如此人类过着比其他动物富裕得多的生活 你会因为规模化地提供社会需要的，但是还不知道如何得到的东西而变得富有。 3. 赚钱不全是因为运气 如果把我全身衣服剥光，一个子儿不剩的把我丢在沙漠里，只要有一个骆驼队经过，过不了十年我又会成为亿万富翁。——洛克菲勒 运气有四种： 盲目出现的运气：那就是命运，比如王思聪 创造出来的运气：有人在网上默默写了很多年博客，慢慢积攒出来了自己的名气，直到机会找上他们 善于发现运气：如果你在某个领域非常精通，那你很可能发现该领域中某个还不被人注意的机会 从你独特的个性中获得的运气：这就是你在那里建立一个独特的角色，一个独特的品牌，一个独特的心态，然后运气找到你。 例如，假设你是深海水下潜水世界上最棒的人。大家都知道，你可以进行深海水下潜水，而其他人甚至都不敢尝试。然后，幸运的是，有人在海岸边找到了一艘沉没的宝船。他们无法得到它。好吧，他们的运气只是成了你的运气，因为他们会来找你去获得宝藏。你会得到报酬。 所以，怪癖不一定是坏事。事实上，这是一件好事 极端的人会得到极端的结果。—— Sam Altman 反例——“玩愚蠢的游戏赢得愚蠢的奖品。”很多人花了很多时间玩Twitter等社交游戏，试图提高你的社交地位，那你基本上赢得了毫无价值的愚蠢社交奖。 4. 你不会通过出售你的时间而致富这意味着当你在睡觉时，你就没有收入。当你生病、退休时，你没有收入。当你在度假时，你没有收入。 是有一些医生看似出售自己的时间变得真的很富有。但那是因为要么他们开了一家公司，要么是他们创造了某种医疗设备，程序或具有知识产权的过程。 5. 你必须拥有东西才能获得财务自由真正富裕起来的人，都是通过拥有某种价值迅速增长的东西而致富。 这种价值迅速增长的东西，可以是股权、房地产、自然资源、知识产权或其他类似的东西。你需要拥有一些这样的东西来获取收入，而不能仅仅依靠出卖自己的时间换取收入，因为时间是一种线性资源。想要要多的收入，只能出卖更多的时间，而你一天只有24小时。 使你的东西的价值迅速增长，最好方法就是让大量的人想要你的东西。 6. 你需要一个输入与输出不成正比的职业 具有高创造力和高杠杆率的工作往往是这样的，你可以工作一个小时，而获得极大回报。或者你也可以工作1000小时，却什么也没有得到。 例如，看看软件工程。一个伟大的工程师可以在3个月内创造比特币，创造价值数十亿美元的价值。而一个工作在错误的事情上，或者说没那么有创造性，有思想性工作上的工程师，可能辛苦工作了整整一年，但产出的每一行代码最终都没有被使用过就被废弃，因为没有客户想要它。 学会利用复利，复利是世界第七大奇迹 玩迭代游戏。生活中所有的回报，无论是财富、人际关系还是知识，都来自于复利。 7. 用特定知识、责任和杠杆武装自己 特定知识是指不能通过培训获得的知识。如果社会能培训你，它也可以培训别人，并取代你。 用特定的知识武装自己。它不能靠训练出来，但可以通过追求你真正的好奇心找到它。 建立特定知识的过程对你来说会像在玩一样，而在别人看来你是在工作。 特殊知识通常是高技术性或创造性的。它既不能外包给别人，也不能被自动化。 责任意味着你必须要容忍有人批评你 财富需要杠杆作用。 商业杠杆来自资本，人员，和没有边际复制成本的产品（代码和媒体）。 资本和劳力是需要得到他人许可的杠杆。每个人都在追逐资本,但总得有人给你钱。每个人都想做领导,但总得有人跟随你。 (你创作的）代码和媒体是无需得到他人许可的杠杆。 他们是新富阶层背后的杠杆。 你能够创建在你睡觉时仍然为你工作的软件和媒体。（睡后收入！） 如果你不会写代码，则写书和博客，录制视频和播客。（睡后收入！） 杠杆是你的判断力的力量倍增器。 经典的例子是投资，或者预测天气的能力，你必须不可被其他人或者机器替代 Scott Adams 就是一个很好的例子，他是世界上最权威的催眠专家。他年轻时就沉迷于催眠，他还学会了如何通过漫画与人进行交流，并阅读了所有关于催眠领域的书。他没有受过高等教育，没有上班，但他仍旧变得十分富有。 这就是一个在职业生涯中积累了特定知识的人的例子。他可以轻松地致富，而且永远不担心被年轻人取代、或被机器自动化。 8. 你不必太刻意地拼凑这种特定的知识 你不必试图在一件事情上做到最好，可以试着非常非常擅长三件或更多事情。 最好的方法就是追随让自己感到痴迷的东西，因为如果你变得过于以目标为导向，那么你实际上不会选择你喜欢做的事情，所以你也不会深入研究它，不会获得很大的成就。 此外，根据收益递减定律，做到世界第一极为困难，收益却变得相对有限。如果能在三到四件事情上做到前20%比在专一领域上成为世界第一更容易成功。 9. 学会销售，学会建立联系 在某种程度上，所有的职业都是在做销售。 建立联系最好的办法就是尽可能多地帮助他人 选择聪明的、干劲十足的商业伙伴，最重要的，选择正直的商业伙伴。 10. 数学和逻辑是理解一切事物的基础 万物皆数，任何事物的本质归根结底就是数学与逻辑 11. 如果你愿意每天流一点血，你可能会在以后赢得大奖 不要停留在舒适区 21. 劳动力和资本是旧的杠杆 财富需要杠杆。劳动力和资本是每个人都在争夺的旧形式的杠杆。 22. 产品和媒体是新的杠杆24. 选择具有杠杆的商业模式 理想情况下，你应该选择具有网络效应，低边际成本和规模经济的商业模式。 规模效应：你生产的越多，它就越便宜 边际成本效应：Office软件的边际成本是免费的 网络效应：价值随着客户数量的平方而增长 网络效应业务就是要细分垄断 在网络效应中，每个新用户都会为现有用户增加价值 26. 判断力是决定性的技能在无限杠杆的时代，判断力成为最重要的技能 我们现在生活在一个几乎无限的杠杆时代，所有巨大的财富都是通过杠杆创造的。你的第一份工作应该用来去获取杠杆。 或者，你可以通过学习如何编码或成为良好的沟通者和播客，创建视频，写作等来无限制地获得杠杆作用。 但一旦你掌握了杠杆，你会怎么做呢？那么，你职业生涯的第一部分就是为了获得杠杆而匆匆忙忙。一旦你掌握了杠杆，那么你想慢一点，因为你的判断力真的很重要。 杠杆是你的判断力放大器 不要让自己太忙，连喝咖啡的时间都没有 沃伦巴菲特现在非常富有。即使你明天要拿走沃伦的全部钱，投资者也会再拿出1000亿美元给他，因为他们知道他的判断是如此的好，他们愿意再给他1000亿美元做投资。 判断很难建立起来。这实际上是智力和经验发挥出来的作用。 没有任何经验的智力往往比无用更糟糕，因为你获得了智力给你的信心，并且你获得了一些可信度，但是因为你没有真正的经验，也没有真正的责任感，你只是在投掷飞镖。 现实世界总是远比我们某个人的智能复杂得多。特别是所有快速前进的边缘领域和问题，没有经验你就无从前进。如果你很聪明并且你快速迭代，那么你可能不需要花费10,000小时进入某个领域，但是你需要花费10,000次尝试。 判断力最好的人是最不情绪化的人 阻止你看到实际发生的事情的是你的情绪。我们的情绪不断影响我们的判断力，投资，经营公司，产品或成为企业家，情绪真的会成为一种阻碍。 情绪会阻止你看到实际发生的事情，直到你再也无法抵抗正在发生的事情的真相，直到它变得太突然，然后你被迫受苦，然后打破幻想。 首先，你要对自己的判断负责。判断是运用智慧。智慧来自经验; 并且可以通过短迭代加速经验。 很多顶级投资者经常听起来像哲学家 投资书籍是了解投资最糟糕的地方，因为投资是一种高度多变的现实世界活动，所有的优势总是面临竞争。它始终处于最前沿领域。 你真正需要的是非常非常广泛的判断和思考。最好的方法是研究一切，包括很多哲学。哲学也会让你更加坚忍，让你减少情绪化，从而做出更好的决定; 你有更好的判断力。 某人越愤怒，他的判断力就越糟糕 我保证你的愤怒越多，你的判断力就越糟糕。如果某人不断发出怒吼的话，你可能不想把你的车钥匙交给这个人，更不用说你公司的钥匙了。 28. 尽可能聪明又努力地工作 你或许可以在你的专业领域得90分，如果你仅仅是很聪明、或者很努力的话。但是如果你想要得99分，那就需要你聪明与努力兼具了。那些能考上名校的人没有一个不是如此。 极端的人获得极端的结果。 努力工作。即使和你一起工作的人以及和你合作的人更重要。 一个人的聪明、想象力和知识跟他的效能没太大关系……这三者必不可少，可是只有通过效能才能转化成现实的成果；光靠它们，只会为你原本能做成的事设置限制。—— 彼得·德鲁克 灵感是易腐烂的 如果我有灵感写博客文章或发布推特，我应该马上做。否则，它不会离开那里; 我不会再回来了。灵感是一种美丽而有力的东西，当你拥有它时，就抓住它。 30. 继续重新定义你做的事 在你做的事情上成为世界上最好的。继续重新定义你所做的事情，直到这是真的。 找到创始人 - 产品 - 市场的契合点 对公司来说最重要的是找到适合产品的市场。我想对企业家来说最重要的是找到创始人 - 产品 - 市场契合点。你自然倾向于建立一个有市场的正确产品，这是一个三个焦点的问题。你必须让所有这三个点工作。 34. 拒绝大多数建议 大多数建议是人们给你他们的中奖彩票号码。 最好的创始人听取每个人的意见，但要自己决定 35. 一个平静的心灵，一个健康的身体，一个充满爱的房子 当你终于富裕的时候，你会发现它并不是你一开始就寻求的。但那是另一天了。 一个有趣的现象就是，在美国，穷人更有可能是胖子。有钱人吃生菜沙拉、清蒸豆腐佐红藜，在健身房里挥汗如雨，而住在贫民窟或贫民区的小女生则看着肥皂剧，大口嚼着美国的国民零食Twinkie蛋糕、奇多、汉堡包和比萨。 我认为这三件事，你的健康，你的心理健康和亲密的关系是你必须培养的东西，并且可能比任何金钱都能给你带来更多的平安和幸福。 许多离婚发生在金钱上，很多战斗都发生在内心的愤怒之中 我认为一个充满爱的家庭和人际关系实际上会自动脱离其他事物。如果你有一个平静的心态，如果你已经赚了钱，你应该有一个良好的关系。你没有理由不这样做。很多离婚实际上发生在金钱上，不幸的是，这确实是现实，但有钱可以规避这个问题。 很多外部战斗都发生，因为你的内部状态并不好。当你自然地在内心安静的时候，你会选择更少的打架。你会更加热爱而不期待任何回报，这会照顾外部关系方面的事情。 对我来说，金钱的最终目的，就是你不必在特定的时间在特定的地方做任何你不想做的事情。 36. 没有任何快速致富的计划 任何能快速致富计划只是让别人变得富有的计划。 37. 生产自己的产品 弄清楚你擅长什么，并尽可能多地应用杠杆。 无论你什么时候做生意，如果你期待一直富有下去，你应该问自己，“这对我来说是真实的吗？这是我真的想要的吗？“然后，”我是否应该将其产品化？我该扩大化它吗？我是通过劳动，资本，代码还是媒体将其扩大？“ 你需要弄清楚你擅长什么，或者你有什么独特之处，并尽可能多地运用杠杆。所以赚钱甚至不是你做的事情，这不是技巧。这就是你是谁的定义，剔除了所有的杂质后的结果。 找到让你丰富，健康和富有创造力的爱好 至少找到三个爱好。一个让你赚钱，一个让你健康，一个让你有创意。如果它们能有交叉点当然是最好的。]]></content>
      <tags>
        <tag>rich</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程05JUC]]></title>
    <url>%2F2018%2F04%2F05%2Fconcurrent-05-JUC%2F</url>
    <content type="text"><![CDATA[Callable 与 Runnable在Java中一般通过继承Thread类或者实现Runnable接口这两种方式来创建多线程，但是这两种方式都有个缺陷，就是不能在执行完成后获取执行的结果，在Java 1.5之后提供了Callable和Future接口，通过它们就可以在任务执行完毕之后得到任务的执行结果。 Callable接口和Runnable接口很像，都可以被另外一个线程执行，Callable功能更强大些，正如前面所说的，Runnable不会返回数据也不能抛出异常，而Callable可以有返回值与可以抛出异常。 FutureFuture接口代表异步计算的结果，通过Future接口提供的方法可以查看异步计算是否执行完成，或者等待执行结果并获取执行结果，同时还可以取消执行。也就是说Future就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。通常不能从线程中获得方法的返回值，这时Future就出场了，Future可以监控目标线程调用call()的情况。总结来说，Future可以得到线程任务方法的返回值。 因为Future只是一个接口，所以是无法直接用来创建对象使用的，因此就有了下面的FutureTask。 FutureTask Future只是一个接口，不能直接用来创建对象，FutureTask是Future的实现类。 public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; {} FutureTask实际上实现了Runnable与Future接口，所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。 场景：假设有个很费时的逻辑需要计算，并且返回这个计算值，同时这个值又不是马上需要，那么就可以使用这个FutureTask，用另外一个线程计算返回值，而当前线程在使用这个返回值之前，可以做其他的操作，等到需要这个返回值时，才通过Future得到。 以上Future与以下FutureTask要实现的效果是一样的。 参考深入学习 FutureTask Fork/JoinFork/Join框架是Java7提供了的一个用于并行执行任务的框架， 是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。它的思想与MapReduce类似，从字面上理解，Fork即把一个大任务，切割成若干个子任务并行执行，Join即把若干个子任务结果进行合并，最后得到大任务的结果，主要采取工作窃取算法（work-stealing）。 假如我们需要做一个比较大的任务，我们可以把这个任务分割为若干互不依赖的子任务，为了减少线程间的竞争，于是把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应，比如A线程负责处理A队列里的任务。但是有的线程会先把自己队列里的任务干完，而其他线程对应的队列里还有任务等待处理。干完活的线程与其等着，不如去帮其他线程干活，于是它就去其他线程的队列里窃取一个任务来执行。而在这时它们会访问同一个队列，所以为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。 工作窃取算法的优点是充分利用线程进行并行计算，并减少了线程间的竞争，其缺点是在某些情况下还是存在竞争，比如双端队列里只有一个任务时。并且消耗了更多的系统资源，比如创建多个线程和多个双端队列。 对于Fork/Join框架而言，当一个任务正在等待它使用Join操作创建的子任务结束时，执行这个任务的工作线程，寻找其他并未被执行的任务，并开始执行，通过这种方式，线程充分利用它们的运行时间，来提高应用程序的性能。为了实现这个目标，Fork/Join框架执行的任务有一些局限性： 任务只能使用Fork、Join操作来作为同步机制，如果使用了其他同步机制，那他们在同步操作时，工作线程则不能执行其他任务。如：在框架的操作中，使任务进入睡眠，那么在这个睡眠期间内，正在执行这个任务的工作线程，将不会执行其他任务 所执行的任务，不应该执行IO操作，如读和写数据文件 任务不能抛出检查型异常，必须通过必要的代码处理它们 核心是两个类：ForkJoinTask与ForkJoinPool。Pool主要负责实现，包括上面所介绍的工作窃取算法，管理工作线程和提供关于任务的状态以及它们的执行信息；Task主要提供在任务中，执行Fork与Join操作的机制。 任务类继承RecursiveTask，ForkJoinTask与一般的任务的主要区别在于它需要实现compute()方法，在这个方法里，首先需要判断任务是否足够小，如果足够小就直接执行任务。如果不足够小，就必须分割成两个子任务。使用join()方法会等待子任务执行完并得到其结果。 从上面的例子可以知道，声明ForkJoinTask后，将其加入到ForkJoinPool中，并返回一个Future对象。 ForkJoinPool ：ForkJoinTask需要通过ForkJoinPool来执行，任务分割出的子任务会添加到当前工作线程所维护的双端队列中，进入队列的头部。当一个工作线程的队列里暂时没有任务时，它会随机从其他工作线程的队列的尾部获取一个任务。 ForkJoinTask：我们要使用ForkJoin框架，必须首先创建一个ForkJoin任务。它提供在任务中执行fork()和join()操作的机制，通常情况下我们不需要直接继承ForkJoinTask类，而只需要继承它的子类，Fork/Join框架提供了以下两个子类： RecursiveAction：用于没有返回结果的任务。 RecursiveTask ：用于有返回结果的任务。 ExceptionForkJoinTask在执行的时候可能会抛出异常，但是我们没办法在主线程里直接捕获异常，所以ForkJoinTask提供了isCompletedAbnormally()方法来检查任务是否已经抛出异常或已经被取消了，并且可以通过ForkJoinTask的getException()方法获取异常。 ForkJoinPool中维护了一组WorkQueue，也就是工作队列，工作队列中又维护了一个工作线程ForkJoinWorkerThread与一组工作任务ForkJoinTask WorkQueue是一个双端队列（Deque），即 Double Ended Queue ，Deque是一种具有队列和栈的性质的数据结构，双端队列中的元素可以从两端弹出，其限定插入和删除操作在表的两端进行。 每个工作线程在运行中产生新的任务（通常是因为调用了fork()）时，会放入工作队列的队尾，并且工作线程在处理自己的工作队列时，使用的是LIFO 方式，也就是说每次从队尾取出任务来执行。 在遇到 join() 时，如果需要 join 的任务尚未完成，则会先处理其他任务，并等待其完成。 在既没有自己的任务，也没有可以窃取的任务时，进入休眠。 ForkJoinPool自身也拥有工作队列，这些工作队列的作用是用来接收由外部线程（非 ForkJoinThread 线程）提交过来的任务，而这些工作队列被称为 submitting queue 。 并不是每个 fork() 都会促成一个新线程被创建，而每个 join() 也不是一定会造成线程被阻塞。 fork() 做的工作只有一件事，既是把任务推入当前工作线程的工作队列里。 join() 的工作则复杂得多，也是join() 可以使得线程免于被阻塞的原因 检查调用 join() 的线程是否是 ForkJoinThread 线程。如果不是（例如 main 线程），则阻塞当前线程，等待任务完成。如果是，则不阻塞。 查看任务的完成状态，如果已经完成，直接返回结果。 如果任务尚未完成，但处于自己的工作队列内，则完成它。 如果任务已经被其他的工作线程偷走，则窃取这个小偷的工作队列内的任务（以 FIFO 方式），执行，以期帮助它早日完成欲 join 的任务。 如果偷走任务的小偷也已经把自己的任务全部做完，正在等待需要 join 的任务时，则找到小偷的小偷，帮助它完成它的任务。 递归地执行第5步。 BlockingQueue 先进先出，当队列为空、满了时阻塞 BlockingQueue 是一个接口，继承自 Queue，所以其实现类也可以作为 Queue 的实现来使用，而 Queue 又继承自 Collection 接口。 Throws Exception Special Value Blocks TimeOut insert add(o) offer(o) put(o) offer(o,timeout,timeunit) remove remove(o) poll() take() poll(timeout,timeunit) examine element() peek() - - Throws Exception：抛出异常。如果不能马上进行，则抛出异常。 Special Value：如果不能马上进行，则返回特殊值，一般是True或False Blocks：如果不能马上进行，则操作会被阻塞，直到这个操作成功 Times Out：如果不能马上进行，操作会被阻塞指定的时间。如果指定时间还未执行，则返回特殊值，一般是True或False。 BlockingQueue 的实现都是线程安全的，但是批量的集合操作如 addAll, containsAll, retainAll 和 removeAll 不一定是原子操作。如 addAll(c) 有可能在添加了一些元素后中途抛出异常，此时 BlockingQueue 中已经添加了部分元素，这个是允许的，取决于具体的实现。 ArrayBlockingQueue有界的阻塞队列，内部实现是一个数组，有边界的意思是：容量是有限的，必须初始化时，指定它的容量大小，以先进先出的方式存储数据，最新插入的对象在尾部，最先移除的对象在头部。 ArrayBlockingQueue 在生产者放入数据和消费者获取数据，都是共用同一个锁对象，由此也意味着两者无法真正并行运行。 通过构造函数得知，参数fair控制对象的内部锁是否采用公平锁，默认采用非公平锁。 items、takeIndex、putIndex、count等属性并没有使用volatile修饰，这是因为访问这些变量（通过方法获取）使用都是在锁块内，并不存在可见性问题，如size() 另外有个独占锁lock用来对出入队操作加锁，这导致同时只有一个线程可以访问入队出队。 LinkedBlockingQueueLinkedBlockingQueue之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。 需要注意的是，如果构造一个LinkedBlockingQueue对象，而没有指定其容量大小，LinkedBlockingQueue会默认一个类似无限大小的容量（Integer.MAX_VALUE），这样的话，如果生产者的速度一旦大于消费者的速度，也许还没有等到队列满阻塞产生，系统内存就有可能已被消耗殆尽了。 LinkedBlockingQueue是一个使用链表完成队列操作的阻塞队列。链表是单向链表，而不是双向链表。 通过其构造函数，得知其可以当做无界队列也可以当做有界队列来使用。 与 ArrayBlockingQueue 对比 ArrayBlockingQueue是共享锁，粒度大，入队与出队的时候只能有1个被执行，不允许并行执行。LinkedBlockingQueue是独占锁，入队与出队是可以并行进行的。当然这里说的是读和写进行并行，两者的读读与写写是不能并行的。总结就是LinkedBlockingQueue可以并发读写。 ArrayBlockingQueue和LinkedBlockingQueue间还有一个明显的不同之处在于，前者在插入或删除元素时不会产生或销毁任何额外的对象实例，而后者则会生成一个额外的Node对象。这在长时间内需要高效并发地处理大批量数据的系统中，其对于GC的影响还是存在一定的区别。 DelayQueue DelayQueue是一个无界阻塞队列，只有在延迟期满时才能从中提取元素。该队列的头部是延迟期满后保存时间最长的Delayed元素。 存放到DelayDeque的元素必须继承Delayed接口。Delayed接口使对象成为延迟对象，它使存放在DelayQueue类中的对象具有了激活日期，该接口强制执行下列两个方法： CompareTo(Delayed o)：Delayed接口继承了Comparable接口，因此有了这个方法 getDelay(TimeUnit unit):这个方法返回到激活日期的剩余时间，时间单位由单位参数指定 使用场景 关闭空闲连接。服务器中，有很多客户端的连接，空闲一段时间之后需要关闭之。 缓存。缓存中的对象，超过了空闲时间，需要从缓存中移出。 任务超时处理。在网络协议滑动窗口请求应答式交互时，处理超时未响应的请求。 PriorityBlockingQueueSynchronousQueue它是一个特殊的队列，当一个线程往队列中写入一个元素时，写入操作不会立即返回，需要等待另一个线程来将这个元素拿走；同理，当一个读线程做读操作的时候，同样需要一个相匹配的写线程的写操作。这里的 Synchronous 指的就是读线程和写线程需要同步，一个读线程匹配一个写线程，同理一个写线程匹配一个读线程。 不像ArrayBlockingQueue、LinkedBlockingDeque之类的阻塞队列依赖AQS实现并发操作，SynchronousQueue直接使用CAS实现线程的安全访问。 较少使用到 SynchronousQueue 这个类，不过它在线程池的实现类 ScheduledThreadPoolExecutor 中得到了应用。]]></content>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程03线程安全策略]]></title>
    <url>%2F2018%2F04%2F04%2Fconcurrent-03-safe-strategy%2F</url>
    <content type="text"><![CDATA[线程安全策略不可变对象需要满足的条件： 对象创建后它的状态就不能修改 所有的域都是final类型 对象是正确构建的(在对象创建期间，this引用没有逸出) final 修饰类：不能被继承，final类中的成员属性可以根据需要设置为final，但final类中所有的成员方法都被隐式指定为final方法。一般不建议将类设置为final类型。 修饰方法：1）锁定方法不被继承类修改；2）效率 修饰变量：1）基本数据类型变量，初始化后便不能进行修改；2）引用类型变量，初始化之后不能再指向别的引用 final类中所有的方法都会被隐式指定为final，参见String Collections.unmodifiableXXXCollection、List、Set、Map… Guava ImmutableXXXImmutableXXX：Collection、List、Set、Map… 除了不可变对象，还存在一个方法 就是线程封闭 线程封闭把对象封装到一个线程中，只有一个对象能够看到该对象，那么就算这个对象不是线程安全的，也不会出现任何线程安全问题 Ad-hoc 线程封闭：程序控制实现，非常脆弱、最糟糕，忽略 堆栈封闭：局部变量 ThreadLocal ThreadLocal123456ThreadLocal&lt;String&gt; mThreadLocal = new ThreadLocal&lt;String&gt;() &#123; @Override protected String initialValue() &#123; return Thread.currentThread().getName(); &#125;&#125;; 12345(C)ThreadLocal -&gt; (C)ThreadLocalMap -&gt; (C)Entry(C)Thread -&gt; (f)ThreadLocal.ThreadLocalMap 1234567public class Thread implements Runnable &#123; /* * ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ ThreadLocal.ThreadLocalMap threadLocals = null;&#125; ThreadLocal的作用是提供线程内部的局部变量，这种变量只存在线程的生命周期。 ThreadLocalMap的key是ThreadLocal类的实例对象，value为用户的值 工作原理 set方法 首先获取当前线程 利用当前线程作为句柄获取一个ThreadLocalMap的对象 如果上述ThreadLocalMap对象不为空，则设置值，否则创建这个ThreadLocalMap对象并设置值 总结：实际上，ThreadLocal的值是放入了当前线程的一个ThreadLocalMap的成员变量中，所以只能在本线程中访问，其他线程无法访问 每个线程中都有属于自己的ThreadLocalMap，互不干扰 使用InheritableThreadLocal可以实现多个线程访问ThreadLocal的值。 会导致内存泄露么 首先ThreadLocal实例被线程的ThreadLocalMap实例持有，也可以看成被线程持有。 如果应用使用了线程池，那么之前的线程实例处理完之后出于复用的目的依然存活 所以，ThreadLocal设定的值被持有，导致内存泄露。 上面的逻辑是清晰的，可是ThreadLocal并不会产生内存泄露，因为ThreadLocalMap在选择key的时候，并不是直接选择ThreadLocal实例，而是ThreadLocal实例的弱引用。 所以实际上从ThreadLocal设计角度来说是不会导致内存泄露的。 ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用引用它，那么系统gc的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，再如果当前线程迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：ThreadLocal Ref -&gt; Thread -&gt; ThreadLocalMap -&gt; Entry -&gt; value永远无法回收，造成内存泄露。比如使用线程池的时候，线程结束是不会销毁的，会再次使用的就可能出现内存泄露 。 ThreadLocal通过Entry保存在map中，key为Thread的弱引用（GC时会自动回收），value为存入的变量副本，一个线程不管有多少个ThreadLocal，都是通过一个ThreadLocalMap来存放局部变量的。 总结： 使用ThreadLocal，建议用static修饰 static ThreadLocal headerLocal = new ThreadLocal();这样的话ThreadLocal的生命周期就更长，由于一直存在ThreadLocal的强引用，所以ThreadLocal也就不会被回收，也就能保证任何时候都能根据ThreadLocal的弱引用访问到Entry的value值，然后remove它，防止内存泄露。 为了避免参数传递的麻烦，在controller中将已经封装好的参数放入ThreadLocal中，在其它层调用时直接通过ThreadLocal对象获取。在方法结束时，定义拦截器（或者Filter）进行ThreadLocal的remove方法。 使用完ThreadLocal后，执行下remove操作。 常见线程不安全类与写法StringBuilder 与 StringBufferStringBuilder 不是线程安全的类，而StringBuffer是线程安全的。 SimpleDateFormat 与 JodaTimeSimpleDateFormat在多线程下共享使用就会出现线程不安全情况。建议将SimpleDateFormat声明为局部变量，这样才会避免线程不安全所带来的异常 ArrayList、HashSet、HashMap 等 Collections同步容器 ArrayList -&gt; Vector、Stack HashMap -&gt; HashTable(key、value均不能为null) Collections.synchronizedXXX(List、Set、Map) 如果在使用foreach或iterator进集合的遍历， 尽量不要在操作的过程中进行remove等相关的更新操作。 如果非要进行操作，则可以在遍历的过程中记录需要操作元素的序号， 待遍历结束后方可进行操作，让这两个动作分开进行 同步容器中的方法主要采取synchronized进行同步，因此执行的性能会收到受到影响，并且同步容器并不一定能做到真正的线程安全。 并发容器 J.U.CCopyOnWriteArrayList、CopyOnWriteArraySetCopyOnWriteArrayList相比于ArrayList是线程安全的，从字面意思理解，即为写操作时复制。当有新元素添加到CopyOnWriteArrayList时，先从原有的数组中拷贝一份出来，然后在新的数组做写操作，写完之后，再将原来的数组引用指向到新数组。 CopyOnWriteArrayList add操作 会加锁。 由于写操作的时候，需要拷贝数组，会消耗内存，如果原数组的内容比较多的情况下，可能导致young gc或者full gc 不能用于实时读的场景，像拷贝数组、新增元素都需要时间，所以调用一个set操作后，读取到数据可能还是旧的，虽然CopyOnWriteArrayList能做到最终一致性，但是还是没法满足实时性要求； 由于所有的写操作都是在新数组进行的，这个时候如果有线程并发的写，则通过锁来控制，如果有线程并发的读，则分几种情况： 如果写操作未完成，那么直接读取原数组的数据； 如果写操作完成，但是引用还未指向新数组，那么也是读取原数组数据； 如果写操作完成，并且引用已经指向了新的数组，那么直接从新数组中读取数据。 ConcurrentSkipListSetTreeSet -&gt; ConcurrentSkipListSet 和TreeSet一样，都支持自然排序，并且在构造时可定义Comparator比较器 和其他Set集合一样，底层都是基于相应的Map的 多线程并发时，add、contains、remove都是线程安全的，但是对于批量操作addAll、removeAll、containsAll并不能保证原子性。 不允许使用null元素，因为无法将其与不存在的元素区分开来 ConcurrentHashMap锁分离技术 ConcurrentSkipListMapTreeMap -&gt; ConcurrentSkipListMap ConcurrentHashMap与ConcurrentSkipListMap性能测试在4线程1.6万数据的条件下，ConcurrentHashMap 存取速度是ConcurrentSkipListMap 的4倍左右。 但ConcurrentSkipListMap有几个ConcurrentHashMap不能比拟的优点： ConcurrentSkipListMap 的key是有序的，而ConcurrentHashMap是做不到的 ConcurrentSkipListMap 支持更高的并发。ConcurrentSkipListMap的存取时间是log（N），和线程数几乎无关。也就是说在数据量一定的情况下，并发的线程越多，ConcurrentSkipListMap越能体现出他的优势。 总结 不安全类 并发容器 ArrayList CopyOnWriteArrayList HashSet CopyOnWriteArraySet TreeSet ConcurrentSkipListSet HashMap ConcurrentHashMap TreeMap ConcurrentSkipListMap]]></content>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程04AQS]]></title>
    <url>%2F2018%2F04%2F04%2Fconcurrent-04-AQS%2F</url>
    <content type="text"><![CDATA[AQS 基本结构AbStractQueuedSynchronizer —— 一个用来构建锁和同步器的框架 它提供一个FIFO的队列，可以用来构建锁或其他同步器 Sync queue即同步队列，它是双向链表。 Condition queue不是必须的，单向链表，只有在需要使用到condition的时候才会存在这个单向链表，并且可能存在多个Condition queue 设计： AQS中，存在一个state成员变量，基于AQS有一个同步组件ReentrantLock，在这个组件中，state表示获取锁的线程数，假如state == 0表示无线程获取锁，state == 1表示已有线程获取锁，state &gt; 1表示锁的数量 AQS的设计是基于模板方法，使用需要继承AQS，并覆写其中的方法。 子类通过继承并通过实现它的方法管理其状态{acquire() 和 release()}的方法操纵状态 可以同时实现排它锁和共享锁模式（独占、共享）。它的所有子类中，要么实现并使用它的独占功能API，要么实现共享锁的功能，而不会同时使用两套API。即便是它比较有名的子类ReentrantReadWirteLock也是通过两个内部类读锁和写锁分别使用两套API实现的。 在LOCK包中的相关锁(常用的有ReentrantLock、 ReadWriteLock)都是基于AQS来构建.然而这些锁都没有直接来继承AQS,而是定义了一个Sync类去继承AQS，因为锁面向的是使用用户,而同步器面向的则是线程控制,那么在锁的实现中聚合同步器而不是直接继承AQS就可以很好的隔离二者所关注的事情. AQS内部维护了一个CLH队列来管理锁，线程首先会尝试获取锁，如果失败，会将当前线程以及等待状态等信息包装成Node结点加入同步队列（Sync queue）中。接着不断循环尝试获取锁，条件是当前结点为head直接后继才会尝试，如果失败则会阻塞自己，直到自己被唤醒；而当持有锁的线程，释放锁的时候，会唤醒队列中后继线程。基于这些基础的设计和思路，JDK提供了许多基于AQS的子类。 独占式锁过程总结： AQS的模板方法acquire通过调用子类自定义实现的tryAcquire获取同步状态失败后-&gt;将线程构造成Node节点(创建一个独占式节点)(addWaiter)-&gt;将Node节点添加到同步队列队尾(addWaiter)-&gt;节点以自旋的方法获取同步状态(acquirQueued)。在节点自旋获取同步状态时，只有其前驱节点是头节点的时候才会尝试获取同步状态，如果该节点的前驱不是头节点或者该节点的前驱节点是头节点但获取同步状态失败，则判断当前线程需要阻塞，如果需要阻塞则需要被唤醒过后才返回。在释放同步状态时，同步器调用tryRelease(int arg)方法释放同步状态，然后唤醒头节点的后继节点。 共享式锁过程总结： 共享式获取与独占式获取的最主要区别在于同一时刻能否有多个线程同时获取到同步状态。通过调用acquireShared(int arg)方法可以共享式得获取同步状态。 同步器调用tryAcquireShared(int arg)方法尝试获取同步状态，其返回值为int类型，当返回值大于0时，表示能够获取同步状态。因此，在共享式获取的自旋过程中，成功获取同步状态并且退出自旋的条件就是tryAcquireShared(int arg)方法返回值大于等于0。共享式释放同步状态状态是通过调用releaseShared(int arg)方法 CountDownLatch、ReentrantReadWriteLock、Semaphore等都是共享式获取同步状态的。 同步队列结构分析 本小节内容引用于AQS实现分析 同步器中包含了两个节点类型的引用，一个指向头节点(head)，一个指向尾节点(tail),没有获取到锁的线程，加入到队列的过程必须保证线程安全，因此同步器提供了一个基于CAS的设置尾节点的方法CompareAndSetTail(Node expect,Node update),它需要传递当前线程认为的尾节点和当前节点，只有设置成功后，当前节点才能正式与之前的尾节点建立关联。 同步器将结点加入到同步队列的过程： 同步队列遵循FIFO，首节点是获取锁成功的节点，首节点的线程在释放锁时，将会唤醒后继节点，而后继节点将会在获取到锁时，将自己设置为首节点，设置首节点是由成功获取锁的线程来完成的，由于只有一个线程能够成功获取锁，因此设置首节点不需要CAS操作。 过程如下所示： 同步组件概览 CountDownLatch：是闭锁，通过一个计数来保证线程是否需要一直阻塞 Semaphore：控制同一时间，并发线程的数目 CyclicBarrier：和CountDwonLatch相似，能阻塞线程 ReentrantLock Condition：使用时需要ReentrantLock FutureTask CountDownLatch SemaphoreSemaphore经常用于限制获取某种资源的线程数量，其内部是基于AQS的共享模式，AQS的状态表示许可证的数量，在许可证数量不够时，线程将会被挂起；而一旦有一个线程释放一个资源，那么就有可能重新唤醒等待队列中的线程继续执行。 应用场景 Semaphore可以用于做流量控制，特别公用资源有限的应用场景，比如数据库连接。假如有一个需求，要读取几万个文件的数据，因为都是IO密集型任务，我们可以启动几十个线程并发的读取，但是如果读到内存后，还需要存储到数据库中，而数据库的连接数只有10个，这时我们必须控制只有十个线程同时获取数据库连接保存数据，否则会报错无法获取数据库连接。这个时候，我们就可以使用Semaphore来做流控 tryAcquire 尝试获取许可，如果获取不成功，则放弃操作，tryAcquire方法提供几个重载 tryAcquire() : boolean tryAcquire(int permits) : boolean 尝试获取指定数量的许可 tryAcquire(int permits,long timeout,TimeUnit timeUnit) : boolean tryAcquire(long timeout,TimeUnit timeUnit) : boolean 尝试获取许可的时候可以等待一段时间，在指定时间内未获取到许可则放弃 emaphore有两种模式，公平模式和非公平模式。 CyclicBarrier CyclicBarrier也是一个同步辅助类，它允许一组线程相互等待， 直到到达某个公共的屏障点（common barrier point），也称之为栅栏点。通过它可以完成多个线程之间相互等待，只有当每个线程都准备就绪后，才能各自继续进行后面的操作。它和CountDownLatch有相似的地方，都是通过计数器实现。当某个线程调用await()方法之后，该线程就进入等待状态，而且计数器是执行+1操作，当计数器值达到设定的值，因为调用await()方法进入等待的线程，会被唤醒，继续执行他们后续的操作。由于CyclicBarrier在等待线程释放之后，可以进行重用，所以称之为循环屏障。它非常适用于一组线程之间必需经常互相等待的情况。 与CountDownLatch比较相同点： 都是同步辅助类。 使用计数器实现 不同点： CountDownLatch允许一个或多个线程，等待其他一组线程完成操作，再继续执行。 CyclicBarrier允许一组线程相互之间等待，达到一个共同点，再继续执行。 CountDownLatch不能被复用 CyclicBarrier适用于更复杂的业务场景，如计算发生错误，通过重置计数器，并让线程重新执行 CyclicBarrier还提供其他有用的方法，比如getNumberWaiting方法可以获得CyclicBarrier阻塞的线程数量。isBroken方法用来知道阻塞的线程是否被中断。 场景比较： CyclicBarrier : 好比一扇门，默认情况下关闭状态，堵住了线程执行的道路，直到所有线程都就位，门才打开，让所有线程一起通过。 CyclicBarrier可以用于多线程计算数据，最后合并计算结果的应用场景。比如我们用一个Excel保存了用户所有银行流水，每个Sheet保存一个帐户近一年的每笔银行流水，现在需要统计用户的日均银行流水，先用多线程处理每个sheet里的银行流水，都执行完之后，得到每个sheet的日均银行流水，最后，再用barrierAction用这些线程的计算结果，计算出整个Excel的日均银行流水。 CountDownLatch : 监考老师发下去试卷，然后坐在讲台旁边玩着手机等待着学生答题，有的学生提前交了试卷，并约起打球了，等到最后一个学生交卷了，老师开始整理试卷，贴封条 ReentrantLock(可重入锁)和synchronized区别 可重入性：ReentrantLock字面意思即为再进入锁，称为可重入锁，其实synchronize所使用的锁也是可以重入的，两者关于这个区别不大，它们都是同一个线程进入一次，锁的计数器进行自增，要等到锁的计数器下降为零时，才能释放锁 锁的实现：synchronized依赖于JVM实现很难看到源码，而ReentrantLock基于JDK实现，区别就类似于操作系统控制实现与用户使用代码实现。 性能区别：在JDK1.6以前，synchronized性能比ReentrantLock差很多，但自从synchronize引入了偏向锁、轻量级锁（自选锁）后 ，也就是自循锁后，两者性能就差不多了。synchronized的优化其实是借鉴了ReentrantLock中的CAS技术，都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。 功能区别： 便利性：synchronized更便利，它是由编译器保证加锁与释放。ReentrantLock是需要手动声明与释放锁，所以为了避免忘记手工释放锁造成死锁，所以最好在finally中声明释放锁。 锁的细粒度和灵活度：ReentrantLock优于synchronized ReentrantLock独有的功能 ReentrantLock可以指定是公平锁还是非公平锁，synchronized只能是非公平锁。 提供了一个Condition类，可以分组唤醒需要唤醒的线程。不像是synchronized要么随机唤醒一个线程，要么全部唤醒。 提供能够中断等待锁的线程的机制，通过lock.lockInterruptibly()实现，这种机制ReentrantLock是一种自旋锁，通过循环调用CAS操作来实现加锁。性能比较好的原因是避免了进入内核态的阻塞状态。 ReentrantReadWriteLock ReentrantLock是一个排他锁，同一时间只允许一个线程访问，而ReentrantReadWriteLock允许多个读线程同时访问，但不允许写线程和读线程、写线程和写线程同时访问。相对于排他锁，提高了并发性。在实际应用中，大部分情况下对共享数据（如缓存）的访问都是读操作远多于写操作，这时ReentrantReadWriteLock能够提供比排他锁更好的并发性和吞吐量。 StampedLockJDK 1.8 新增，它是 ReentrantReadWriteLock 的增强版。 它把读操作进一步细分为：乐观读、悲观读 它的思想是读写锁中读不仅不阻塞读，同时也不应该阻塞写。 在读的时候如果发生了写，则应当重读而不是在读的时候直接阻塞写。即读写之间不会阻塞，但是写和写之间还是阻塞的 Condition除了AQS sync队列之外，还有可能存在Condition队列（不存在或者存在多个等待队列）。 使得某个，或者某些线程一起等待某个条件（Condition），只有当该条件具备(signal 或者 signalAll方法被带调用)时，这些等待线程才会被唤醒，从而重新争夺锁。 Condition 队列 –&gt; 等待队列]]></content>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程02安全发布对象]]></title>
    <url>%2F2018%2F04%2F03%2Fconcurrent-02-safe-publication%2F</url>
    <content type="text"><![CDATA[线程安全线程安全的类：不管采用何种调度方式，主调代码中不需要任何额外的同步或协调。 原子性：互斥操作 可见性：一个线程对主存的修改可以即时被线程看到 有序性：指令重排 volatile 原子性Atomic 包AtomicXXX：CAS、Unsafe.compareAndSwapXXX AtomicLong 与 LongAdder(JDK8)AtomicLong 底层是通过CAS来保障原子性的更新的。 LongAdder的核心原理：跟ConcurrentHashMap差不多内部分多个桶，每次分散加锁，提高并发度。 求和时，如果有并发更新，可能会导致统计的数据有误。 LongAdder适合更高的并发场景，并发度较低时建议使用AtomicLong 更简单轻量。 AtomicReference1unsafe.compareAndSwapInt(currentValue, valueOffset, expect, update); 将 currentValue 修改为 update 这个值 AtomicReference 不能保证多线程修改引用对象的属性时线程安全性 AtomicReferenceFieldUpdaterAtomicIntegerFieldUpdater、AtomicLongFieldUpdater用来并发修改对象的field值 该字段要用 volatile声明，同时不能被static修饰 AtomicStampReference它主要解决CAS的ABA问题 J.U.C 提供了两个类解决ABA问题，一个是AtomicStampReference ，另一个是 AtomicMarkableReference AtomicLongArray对Long数组进行原子操作，可并发修改指定位置的元素 AtomicBooleanisHappened.compareAndSet(false, true)可保证代码只会执行一次 锁synchronized底层由JVM进行原子性控制 注意：父类用 synchronized 修饰的同步方法块，子类调用时该方法是不加锁的，因为 synchronized 不属于方法声明的一部分 对比 synchronized ：不可中断锁，适合竞争不激烈的情况，可读性较好 lock：可中断锁，灵活多样化，适合竞争激烈的场景 Atomic：性能更好，但只能同步一个值 volatile通过加入内存屏障和禁止指令重排序来实现 对volatile变量写时，会在写操作之后加入一条store屏障指令，将本地内存中的共享变量刷新到主存中 volatile 适合作为状态标记符 有序性指令重排对单线程程序无影响，却会影响多线程程序的正确性 synchronized、Lock 保证串行有序性，另外，JMM 的 Happen-Before 具备先天的有序性。 锁定规则：对一个对象的 unLock 操作先于 Lock 操作 volatile规则： 传递规则 线程启动规则：Thread的start方法先行于该线程的每一个动作 线程中断规则：interrupt()方法先行于代码检测到中断事件 线程终结原则 对象终结原则 安全发布对象发布与逸出对象逸出：错误地发布对象，使得当它还没有构造完成就对其他线程可见 public 访问级别发布 通过 public 级别发布了对象的属性，这样发布对象是不安全的 在构造完成之前发布 比如在构造函数中启动一个线程 安全发布对象 在静态初始化函数中初始化一个对象的访问 将对象的访问保存到volatile类型域或AtomicReference对象中 将对象的引用保存到某个正确构造对象的final类型域中 将对象的引用用锁保护]]></content>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发编程01基本概念]]></title>
    <url>%2F2018%2F04%2F02%2Fconcurrent-01-basic%2F</url>
    <content type="text"><![CDATA[Java 内存模型 是一个规范，它规范了 java 虚拟机是如何与计算机内存协同工作的。屏蔽掉各种系统硬件和操作系统的内存访问差异，以达到跨平台运行的目的，它规定了一个线程如何以及何时能够看到其他线程修改过的共享变量的值， 以及在必须时，如何同步地访问共享变量。 堆的优势：可以动态分配大小，生存期无需事先告诉编译器需要多少内存，因为是自动分配的。缺点：由于需要动态分配内存，所以速度会慢一些。 栈的优势：存取速度比堆要快，仅次于寄存器。缺点：数据大小、生存期必须是确定的，缺乏灵活性。 栈主要存放一些基本类型：int、short、long、byte、double、float、boolean、char、对象句柄 一个本地的对象，它的引用变量存放在Stack上，对象存在堆Heap上。成员变量跟随者对象存放在堆上，静态成员变量跟随类的定义一起存在堆上。 read 是把变量从 shared memory 读入 CPU local memory，或者说从内存读入 CPU cache， write 反之 load 是把变量从 CPU local memory 读入 JVM stack，你可以认为它是把数据从 CPU cache 读入到“ JVM 寄存器”， store 反之 个人的理解：read 是一个 copy 操作，从主存拷贝对象到工作内存；load 就相当于把工作内存的对象和栈上的引用建立连接。 CountDownLatch CountDownLatch 位于 JUC 包，可以用它实现类似计数器的功能。比如有一个任务需要等待其他4个任务执行完毕才能执行。 12public CountDownLatch(int count) &#123; &#125;; //参数count为计数值 SemaphoreSemaphore可以阻塞线程并控制同时访问的线程个数，通过acquire()获取一个许可，如果没有就阻塞等待，而release()释放一个许可。 模拟并发：使用Semaphore控制并发数，CountDownLatch保证线程执行完后再执行其他操作。]]></content>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[principles-of-security-design]]></title>
    <url>%2F2018%2F03%2F15%2Fprinciples-of-security-design%2F</url>
    <content type="text"><![CDATA[本文不涉及web安全方面的东西，只是根据接口设计，讲讲开发一个可靠的服务，需要考虑的几个维度，这些都是老生常谈的东西，每个人都清楚，但是很少有人能够考虑全面（比如前端发起一个删除数据的请求，后端直接调用xxxDao.delete而不做任何验证），这里单独拎出来讲讲，旨在提高意识。 1. 参数校验参数校验的目的是不相信前端传过来的数据，一方面是因为前端js问题导致校验失效，还有前端数据都是可以篡改的。 1.1 格式校验字段大小、长短、范围、格式校验；// todo 整理一份参数校验手册 1.2 特殊业务校验比如起草合同时采购计划不能跨单位、起草期次时标项不能大于10个，严格意义上来说，后端都应该做好校验； 偷懒的底线：一些次要信息（比如名字、地址长度这些可以为空，仅仅作为展示的字段）可以放到前端来做校验，但是对于会影响后续流程的关键性字段（比如金额、评分方式枚举等），后端必须做严格的校验，需要分辨这些关键信息。 2. 权限校验2.1 垂直越权说明：A并没有配置“生成项目”的权限，但是可以通过postman等http工具访问这个接口，导致越权。后果：危害性较大，抛开主动攻击不谈，最常见的危害是，不少用户具有多账号多类别，在双开界面下，如果不同界面的所属机构或者用户类别不同，就会导致session串掉，后台获取的LoginUser就会有问题（detailCategory、operatorId、orgId、orgName等），尤其是用了新的用户API，employee按照类别横向拆分成了多个Operator，用户切换类别导致operatorId不同（而老用户接口employeeId是相同的），使得问题出现频率更高。举例：（1）跨类别：在一个账号下，用户同时具有采购人和代理机构两个类别，然后在一个界面是采购人身份，填了一些项目信息，然后新开了一个界面是代理机构类别，此时在第一个界面点击保存，那么LoginUser就有问题——首先detailCategory是不同的，如果用的是老用户API，用的是loginUser.id，同一个账号下用户类别不同，但是id都是相同的，所以只要不用detailCategory，老用户API下即使用户类别串掉了，也没有影响的，但是在新用户模块下，用户类别不同则operatorId不同，就会产生数据问题。（2）跨机构（跨类别）：采购人生成委托单，然后委托给代理机构审核，不少用户为了操作方便，有采购人和代理机构两个账号，习惯性先用一个账号开一个采购人界面，再用一个账号开代理机构界面，然后在采购人界面操作，此时session已经串掉了，导致获取到的LoginUser的detailCategory、id、operatorId都串掉。 两者本质都是一样的，都是在另一个界面偷偷更换了用户session信息。 后果演示： （1）跨类别：登录binjiangcgjg账号，切换到采监处类别，在第一个界面填好期次信息，然后开另一个窗口，并切换到采购单位类别，回到第一个界面点击保存，检查后端获取的LoginUser;（2）跨机构：登录binjiangcgjg账号，切换到采监处类别，在第一个界面填好期次信息，然后开另一个窗口，登录binjiangcgr账号，回到第一个界面点击保存，检查后端获取的LoginUser; 解决：配置@AuthZcy注解，该注解应该加在方法级（类级别尽量不要加），对于增、删、改、审核等接口，必须配置categorys和privileges属性，对于查询接口，至少需要配置categorys属性，privileges属性需要尽力配置。 2.2 水平越权说明：A和B都有“修改项目”的权限，此时如果A将projectId换成了B拥有的一个项目的ID，由于接口没有做数据权限校验，导致A偷偷越权修改（访问）了B的数据。后果：就用户操作来说，相对来说危害性小一些，出现频率不高，但被恶意攻击，数据安全性危害就很大。解决：（1）明确数据权限粒度：是平台级、区化级、机构级还是用户级； （2）在创建数据时，关键的数据权限信息，不要从前端获取，而要从loginUser里面拿，比如某个项目的创建人、机构、区划信息，直接从LoginUser里拿，前端传的话容易被篡改。 （3）删、改、查、审核等操作时，需要加上数据权限验证（查询接口危害很小，但安全性检测时最常检测的就是查询接口）。 12345678910111213@Transactional@Overridepublic PubfundProjectOpenBidModel queryOpenBidDetail(Long projectId) &#123; validThrow(projectId, "项目id不能为空"); PubfundProject project = validThrow(this.pubfundProjectDao.selectById(projectId), "项目不存在"); PubfundProjectFile projectFile = validThrow(this.pubfundProjectFileDao.getProjectFile(projectId), "招标文件不存在"); // 数据权限校验 LoginUser user = getAndCheckLoginUser(); if (!user.getOperatorId().equals(project.getAgencyOperatorId())) &#123; throw ExcpUtil.genServiceException("无权查看该项目"); &#125; ...&#125; 三、业务校验（上下文越权）说明：上下文越权，主要就是绕过了状态机校验、包括一些业务上的特殊限制。后果：只通过前端校验，后端不校验的情况下，在双开界面下，或者通过http工具发送请求，就会绕开这些限制。后果演示：在一个界面创建期次，然后新开一个界面提交期次，此时回到第一个界面，依然能够保存。解决：提高意识。 四、并发及幂等校验说明：是上下文越权的特例，侧重于并发访问下导致的问题，主要是消息、关键性一次性的节点，平台目前还没有推行一套token防并发的方案，前端的一些控制也是治标不治本，但是不管怎么样后端也是要校验的。解决：提高意识，一些方案，如基于版本号的乐观锁、基于状态的乐观锁、去重表，以及其他一些复杂的方案。 123456789101112131415161718192021int count = 0;if (userInfo.isExpert) &#123; // 状态更新加锁校验（利用数据库事务的原子性，本质上也是基于状态的幂等校验） count = this.pubfundExpertDao.updateStatusNoLock(itemId, // beforeStatusNo BidOpenPageEnum.SCORE_GATHER_PAGE.getExpertStatus().getCode(), // afterStatusNo PubfundExpertContext.ExamineStatus.WAIT_ASSIGN_AMOUNT.getCode(), Lists.newArrayList(user.getOperatorId()));&#125; else &#123; // 状态更新加锁校验（利用数据库事务的原子性，本质上也是基于状态的幂等校验） count = this.pubfundProjectItemDao.updateExamineStatusLock(itemId, // beforeStatusNo PubfundProjectItemContext.BidExamineStatus.WAIT_SCORE_GATHER.getCode(), // afterStatusNo PubfundProjectItemContext.BidExamineStatus.WAIT_ASSIGN_AMOUNT.getCode());&#125;// 幂等校验if (count &gt; 0) &#123; this.amountAssignService.computeSupplierBidLimit(itemId, RE_COMPUTE);&#125; 五、关注事务和日志存在的问题：（1）涉及db更新的接口，不少地方都忘记加事务控制；（2）加了事务控制，也要思考程序在某些关键步骤（尤其是涉及外部调用失败）执行失败该如何回滚，比如本地的db优先执行，外部调用放到代码后面；（3）关键节点和一些比较容易出错的操作，要做好详细的日志，作日志不是简单记录一下，要记录关键信息，便于以后排查问题搜索，根据某个字段能搜出整个流程日志。 六、一份样本1234567891011121314151617181920212223242526272829// 垂直权限校验@AuthZcy(categorys = &#123;Category.PROCUREMENT_AGENCY, EVALUATION_EXPERTS&#125;, privileges = &#123;TREASURY_AGENCY_OPENBID, TREASURY_EXPERT_EXAMINE&#125;)@RequestMapping(value = "/startAssignBidAmount", method = RequestMethod.POST)public Boolean startAssignBidAmount(@RequestParam(value = "itemId") Long itemId) &#123; return this.pubfundBidOpenService.startAssignBidAmount(itemId);&#125; @Transactional // 1.事务控制@Overridepublic Boolean startAssignBidAmount(Long itemId) &#123; validThrow(itemId, "标项id不能为空"); LoginUser user = getAndCheckLoginUser(); PubfundProjectItem item = validThrow(this.pubfundProjectItemDao.selectById(itemId), "标项不存在"); PubfundProject project = validThrow(this.pubfundProjectDao.selectById(item.getProjectId()), "项目不存在"); // 2.数据权限校验 UserInfo userInfo = getAndCheckUser(user, project.getAgencyOperatorId(), itemId); // 3.状态机校验 checkPageAction(userInfo, project, item, BidOpenActionEnum.BID_ASSIGN, true); List&lt;PubfundSupplierBid&gt; suppliers = this.queryBidSuccSuppliers(itemId, project, true, true); validThrow(!CollectionUtils.isEmpty(suppliers), "没有评审通过的供应商，请废标"); // 4.关键节点：基于状态机的幂等校验 int count = this.pubfundProjectItemDao.updateExamineStatus(itemId, project.getId(), PubfundProjectItemContext.BidExamineStatus.BID_FINISH.getCode()); if (count == 0) &#123; throw ExcpUtil.genServiceException("已经分配过存款额"); &#125; // 分配存款额 ...&#125; 七、全文总结 一个可靠的接口，可能有40%以上的校验代码； 前端都是不可靠的，一方面是因为浏览器兼容问题，js校验在某些场景下并不能控住，一方面是接口都有可能被绕过的。 墨菲定律：会出错的事总会出错，担心的坏事更有可能发生 对于增、删、改、审等涉及到db更新的操作，要从上述几个方面去思考，不同场景并不一定要求非要这样做，可以有选择地控制，关键是要有这个意识。 再次强调一下讲的几个方面：参数校验、垂直越权、水平越权、上下文越权、幂等校验、关注事务和日志。]]></content>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例SINGLETON模式]]></title>
    <url>%2F2018%2F01%2F21%2FSingleton-Design-pattern%2F</url>
    <content type="text"><![CDATA[Singleton的教学版本1234567891011// version 1.0public class Singleton &#123; private static Singleton singleton = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (singleton== null) &#123; singleton= new Singleton(); &#125; return singleton; &#125;&#125; 私有（private）的构造函数，表明这个类是不可能形成实例了。这主要是怕这个类会有多个实例。 即然这个类是不可能形成实例，那么，我们需要一个静态的方式让其形成实例：getInstance()。注意这个方法是在new自己，因为其可以访问私有的构造函数，所以他是可以保证实例被创建出来的。 在getInstance()中，先做判断是否已形成实例，如果已形成则直接返回，否则创建实例。 存在线程安全问题在多线程情况下，如果多个线程同时调用getInstance()的话，那么，可能会有多个进程同时通过 (singleton== null)的条件检查，于是，多个实例就创建出来，并且很可能造成内存泄露问题。 虽然我们的synchronized方法会帮助我们同步所有的线程，让我们并行线程变成串行的一个一个去new，那不还是一样的吗？同样会出现很多实例。看来，还得把那个判断(singleton== null)条件也同步起来。 然而，读取的动作不需要线程同步啊 看来，在线程同步前还得加一个(singleton== null)的条件判断，如果对象已经创建了，那么就不需要线程的同步了 这就是“双重检查”Double-Check 然而，singleton = new Singleton()这句，并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。 给 singleton 分配内存 调用 Singleton 的构造函数来初始化成员变量，形成实例 将singleton对象指向分配的内存空间（执行完这步 singleton才是非 null 了） 指令重排序，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。 如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了，所以线程二会直接返回 instance，然后使用，然后就报错了。 Singleton 的简化版本 使用static、final，在类加载时就会实例化singleton对象，所以保证了线程安全性。但是，我们还是想要懒加载，而不是把类的创建委托给类装载器 Singleton 优雅版本123public enum Singleton&#123; INSTANCE;&#125; 默认枚举实例的创建是线程安全的 单元素的枚举类型已经成为实现Singleton的最佳方法。]]></content>
      <tags>
        <tag>Singleton,Design-Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GFW与翻墙原理]]></title>
    <url>%2F2017%2F09%2F23%2FGFW-fanqiang%2F</url>
    <content type="text"><![CDATA[DNS污染和劫持DNS劫持是指返回给你一个伪造页面的IP地址，DNS污染是返回给你一个不存在的页面的IP地址。 解决办法： 使用OpenDNS（208.67.222.222）或GoogleDNS（8.8.8.8） 使用一些第三方的DNS服务器 自己用VPS搭建DNS服务器 修改机器host文件，直接IP访问 封锁IP虽然通过上面一些方式，可以绕过DNS污染。但是目前针对IP进行大范围的封锁。 不过目前不可能把所有国外的IP全部封锁掉，所以我们才有机会从国内连接到国外的VPS，进行翻墙。 解决办法： 使用VPS搭建代理 使用IPV6 （IPV6地址巨大，采用封地址不现实，但是目前国内只有部分高校部署了IPV6） 封锁HTTP代理对于没有办法搭建VPS的人来说，最好的办法就是使用HTTP代理。客户端不在直接请求目标服务器，而是请求代理服务器，代理服务器在去请求目标服务器。然后返回结果。 对于HTTP代理来说，封锁起来非常简单。因为HTTP协议是明文，Request Message中就带有要请求的URL或IP地址，这样很容易就被检测到。对于HTTPS来说，虽然通信是进行加密了，但是在建连之前会给代理服务器发送CONNECT方法，这里也会带上要访问的远端服务器地址。如果代理服务器在国外，在出去前就会被检测到。 如果代理服务器在国内，呵呵，你也出不去啊。 对于HTTP代理，因为是明文，所以很容易被服务器了解你的一些数据。所以不要随便使用第三方的HTTP代理访问HTTP网站，而HTTPS虽然不知道你的数据，但是可以知道你去了那里。 解决办法： 使用VPS搭建VPN 使用第三方VPN 封锁VPN虚拟专用网（英语：Virtual Private Network，简称VPN），是一种常用于连接中、大型企业或团体与团体间的私人网络的通讯方法。虚拟私人网络的讯息透过公用的网络架构（例如：互联网）来传送内联网的网络讯息。它利用已加密的通道协议（Tunneling Protocol）来达到保密、发送端认证、消息准确性等私人消息安全效果。 正常网络通信时，所有网络请求都是通过我们的物理网卡直接发送出去。而VPN是客户端使用相应的VPN协议先与VPN服务器进行通信，成功连接后就在操作系统内建立一个虚拟网卡，一般来说默认PC上所有网络通信都从这虚拟网卡上进出，经过VPN服务器中转之后再到达目的地。 通常VPN协议都会对数据流进行强加密处理，从而使得第三方无法知道数据内容，这样就实现了翻墙。翻墙时VPN服务器知道你干的所有事情（HTTP，对于HTTPS，它知道你去了哪）。 VPN有多种协议：OPENVPN、PPTP、L2TP/IPSec、SSLVPN、IKEv2 VPN，Cisco VPN等。其中的PPTP和L2TP是明文传输协议。只负责传输，不负责加密。分别利用了MPPE和IPSec进行加密。 OpenVPN 速度快，并且安全可信。但劣势是缺乏对移动设备的支持，另外还需要安装第三方客户端。 对于VPN和其他一些加密的传输的协议来说，没有办法直接获取明文的请求信息，所以没有办法直接封锁，而是使用了监控分析的方式： 暴力破解对于一些使用弱加密方式的协议来说，直接使用暴力破解检查传输内容。比如PPTP使用MPPE加密，但是MPPE是基于RC4，对于强大的防火墙背后的超级计算机集群，破解就是几秒钟的事情。 破解后明文中一旦包含了违禁内容，请求就会被封。而对应的IP可能会进入重点关怀列表。 特征检测要想成功翻墙都必须与对应的远程服务器建立连接，然后再用对应的协议进行数据处理并传输。而问题就出在这里：翻墙工具和远程服务器建立连接时，如果表现的很独特，在一大堆流量里很显眼，就会轻易被GFW识别出从而直接阻断连接，而VPN（尤其是OPENVPN）和SSH这方面的问题尤其严重。 流量监控当一个VPN地址被大量人请求，并保持长时间连接时，就很容易引起关注。SSH接口有大量数据请求。一般会结合其他特征。 深度包检测深度数据包检测（Deep packet inspection，缩写为 DPI），又称完全数据包探测（complete packet inspection）或信息萃取（Information eXtraction，IX），是一种电脑网络数据包过滤技术，用来检查通过检测点之数据包的数据部分（亦可能包含其标头），以搜索不匹配规范之协议、病毒、垃圾邮件、入侵，或以预定之准则来决定数据包是否可通过或需被路由至其他不同目的地，亦或是为了收集统计数据之目的。 比如我们用HTTPS来访问一个网站，TLS/SSL协议在建连过程如下： 很明显的会发送“client hello”和“server hello” 这种特诊很明显的信息。（当然不会根据这个就封掉，否则https没法用了）。而后续会有服务端证书发送，验证，客户端密钥协商等过程。有明显的协议特征。 Socks代理/SSH SocksSOCKS是一种网络传输协议，主要用于客户端与外网服务器之间通讯的中间传递。SOCKS是”SOCKetS”的缩写[1]。 当防火墙后的客户端要访问外部的服务器时，就跟SOCKS代理服务器连接。这个代理服务器控制客户端访问外网的资格，允许的话，就将客户端的请求发往外部的服务器。 根据OSI模型，SOCKS是会话层的协议，位于表示层与传输层之间 与HTTP代理的对比SOCKS工作在比HTTP代理更低的层次：SOCKS使用握手协议来通知代理软件其客户端试图进行的连接SOCKS，然后尽可能透明地进行操作，而常规代理可能会解释和重写报头（例如，使用另一种底层协议，例如FTP；然而，HTTP代理只是将HTTP请求转发到所需的HTTP服务器）。虽然HTTP代理有不同的使用模式，CONNECT方法允许转发TCP连接；然而，SOCKS代理还可以转发UDP流量和反向代理，而HTTP代理不能。HTTP代理通常更了解HTTP协议，执行更高层次的过滤（虽然通常只用于GET和POST方法，而不用于CONNECT方法） Socks代理本身协议是明文传输，虽然相对HTTP有一些优势，但是明文也导致Socks代理很容易被封。所以可以考虑对Socks进行加密。所以出现了SSH Socks，对于MAC和Linux来说，不需要Client就可以进行访问。详细可以看：SSH隧道技术简介：端口转发&amp;SOCKS代理 但是有些地区好像会对一些VPS的SSH进行端口干扰。而且SSH一般是小流量数据，如果数据量特别大，也会被认为是翻墙，进入特别关怀列表。 Shadowsocks认准官网：https://shadowsocks.org/en/index.html Shadowsocks 目前不容易被封杀主要是因为： 建立在socks5协议之上，socks5是运用很广泛的协议，所以没办法直接封杀socks5协议 使用socks5协议建立连接，而没有使用VPN中的服务端身份验证和密钥协商过程。而是在服务端和客户端直接写死密钥和加密算法。所以防火墙很难找到明显的特征，因为这就是个普通的socks5协议。 Shadowsock搭建也比较简单，所以很多人自己架设VPS搭建，个人使用流量也很小，没法通过流量监控方式封杀。 自定义加密方式和密钥。因为加密主要主要是防止被检测，所以要选择安全系数高的加密方式。之前RC4会很容易被破解，而导致被封杀。所以现在推荐使用AES加密。而在客户端和服务端自定义密钥，泄露的风险相对较小。 Shadowsocks-rss前面认为Shadowssocks特征并不是很明细，但是了解协议工作原理后会发现，SS协议本身还有有漏洞，可以被利用来检测特征，具体讨论看：ShadowSocks协议的弱点分析和改进。 我总结了下大致意思是： 协议过于简单，并且格式固定，很容易被发起中间人攻击。先看看协议结构 Address Type Destination Address Destination Port Data 1 Variable 2 Variable Possible values of address type are 1 (IPv4), 4 (IPv6), 3 (hostname). For IPv4 address, it’s packed as a 32-bit (4-byte) big-endian integer. For IPv6 address, a compact representation (16-byte array) is used. For hostname, the first byte of destination address indicates the length, which limits the length of hostname to 255. The destination port is also a big-endian integer. The request is encrypted using the specified cipher with a random IV and the pre-shared key, it then becomes so-called payload. 结构很简单，上面解释也很清楚。Client每一个请求都是这种格式，然后进行加密。Server端解密然后解析。看起来没什么问题，没有密钥你无法模拟中间人攻击，也没什么明显特征。但是看看Server处理逻辑会发现存在一些问题： Client数据在加密目前用的最多的是AES系列，加密后在协议数据前会有16位的IV。而Server段解析后，首先判断请求是否有效，而这个判断很简单： 判断的依据就是Address Type的那个字节，看它是不是在那三个可能取值，如果不是，立即断开连接，如果是，就尝试解析后面的地址和端口进行连接。 如果能发起中间人攻击，模拟Client请求，这个就是一个很明显的特征，如果把Address Type穷举各种情况，其中只有3种情况会连接成功。那么很可能就是一个Shadowsocks 服务器。 所以只需要先劫持一条socks5的请求，因为AES加密后Address Type位置是固定的（第17位），篡改这一位，穷举256种情况（AES-256），然后发送给服务器。如果服务器在3种情况没有关闭连接，就说明这个很可能是Shadowsock服务。你这个IP很快就进入关怀列表了。 这里的关键就是AES加密明文和密文对应关系。 1234567891011121314151617举个例子，现在有一个协议包，共7个字节0x01, 0x08, 0x08, 0x08, 0x08, 0x00, 0x50对照socks5协议，很明显这是一个IPv4包(第一个字节是0x01)，目的地是8.8.8.8的80端口被shadowsocks加密了以后（密码abc，加密方式aes-256-cfb），数据包就变成了这样0xbb, 0x59, 0x1c, 0x4a, 0xb9, 0x0a, 0x91, 0xdc, 0x07, 0xef, 0x72, 0x05, 0x90, 0x42, 0xca, 0x0d, 0x4c, 0x3b, 0x87, 0x8e, 0xca, 0xab, 0x32前16个字节，从0xbb到0x0d，都是iv，根据issue中提到的弱点和之前的总结，只需要修改0x4c，即真正密文中的第一个字节，就可要起到修改明文中的第一个字节的效果。那就把0x4c修改成0x4d吧，解密以后的结果是0x00, 0x08, 0x08, 0x08, 0x08, 0x00, 0x50的确只有第一个字节被改掉了，根据breakwa11的理论，不难推出其他情况，其中合法的是0x4e =&gt; 0x03 (Domain Name)0x49 =&gt; 0x04 (IPv6) 所以目前Shadowsocks应该是比较容易被检测出来。但是为什么没有被封掉，呵呵，就不知道了。所以这个项目目的就是在SS基础上进行一些混淆。因为原有实现确实有漏洞。 不过目前这个项目好像也停止更新了。并且木有开源。 当然如果是自己用完全可以自己修改一个私有协议，这样就没法被检测到了。但是需要同时修改Server段，MAC Client，Windows Client， Android Client。 – -！ GoAgent和GoProxyGoogle App Engine是一个开发、托管网络应用程序的平台，使用Google管理的数据中心 GoAgent的运行原理与其他代理工具基本相同，使用特定的中转服务器完成数据传输。它使用Google App Engine的服务器作为中传，将数据包后发送至Google服务器，再由Google服务器转发至目的服务器，接收数据时方法也类似。由于服务器端软件基本相同，该中转服务器既可以是用户自行架设的服务器，也可以是由其他人架设的开放服务器。 GoAgent其实也是利用GAE作为代理，但是因为他是连接到google的服务器，因为在国内现在google大量被封，所以GoAgent也基本很难使用。目前github上源码也已经删除。 但是GoAgent本身不依赖于GAE，而且使用Python编写，完全可以部署到VPS上进行代理。GoProxy是GoAgent的后续项目https://github.com/phuslu/goproxy还有一个XX-NET：https://github.com/XX-net/XX-Net 有兴趣都可以去了解下。 TorTor（The Onion Router，洋葱路由器）是实现匿名通信的自由软件。Tor是第二代洋葱路由的一种实现，用户通过Tor可以在因特网上进行匿名交流。 The Tor network is a group of volunteer-operated servers that allows people to improve their privacy and security on the Internet. Tor’s users employ this network by connecting through a series of virtual tunnels rather than making a direct connection, thus allowing both organizations and individuals to share information over public networks without compromising their privacy. Along the same line, Tor is an effective censorship circumvention tool, allowing its users to reach otherwise blocked destinations or content. Tor can also be used as a building block for software developers to create new communication tools with built-in privacy features. 简单说和其他翻墙方式不同，简单可以理解为Tor有一群代理服务器，然后要访问远端站点，是通过随机的代理路径来完成的，数据经历了多个代理服务器的传递。它主要作用是隐藏访问者信息，而翻墙只是顺带的功能。 要访问远程站点，Client需要知道Tor nodes，这些nodes就是普通加入的用户，就好像P2P下载一样。获取nodes信息后，会随机选择一条路径访问。 因为这个原因，Tor的速度可能不会很好。 而关于Tor的漏洞和检测看这里：Tor真的十分安全么 其原理以及漏洞详解 目前有结合Tor+Shadowsocks前置代理使用的。 ReferenceVPN翻墙，不安全的加密，不要相信墙内公司GFW的工作原理（1） ————GFW是如何识别并封锁翻墙工具的关于翻墙和匿名与网络安全类科普文大集合为什么不应该用 SSL 翻墙科学上网的一些原理]]></content>
      <tags>
        <tag>GFW, VPN, 翻墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C#与Java对比]]></title>
    <url>%2F2017%2F05%2F06%2FC-vs-Java%2F</url>
    <content type="text"><![CDATA[垃圾回收机制JVM采用了和.NET框架类似的垃圾回收机制—–分代垃圾回收方法 C#与Java垃圾回收机制不同，我只知道一点： C#中存在大量不归CLR管的资源，也就是非托管资源，这部分资源是不能由GC来自动释放的； 正是由于这些原因，C#有IDisposable接口，IDisposable接口中定义了Dispose方法，这个方法用来供程序员显式调用以释放非托管资源。使用using语句可以简化资源管理。而java中全是托管资源，故不存在这样的问题。 C#五花八门的特性要多很多委托，属性，真正的泛型，索引器，类初始化器，分部类，操作符重载，struct，unsafe代码，IDisposable等 委托，这个可以算是C#之于Java的最大优势。虽然Java可以依靠接口，匿名内部类这些特性实现委托一样的功能，但却要麻烦许多，如果涉及到N个委托实例相加的情况，那么一个C#里面简单的”+”号，在Java里就只能用FilterChain，InterceptorStack这种概念了。 真正的泛型，这个又是一大C#的优势，同时伪泛型又是Java的一大败笔。但是Java年代比较长，为兼容性考虑不得不使用假的泛型实现。 索引器，有了这个很多容器类都可以直接用[]取元素，感觉还不错，比没有好，编译器的小把戏。类初始化器，典型的懒汉特性。每次用顶多能省下一两行代码，又是编译器的小把戏。分部类（partial class），纯粹为了vs.net的那一大堆图形化设计器老和人的代码冲突而搞出来得玩意，又是编译器的小把戏。 操作符重载，属于用到得不多，要用时却显得特别有用的东西。struct，在堆栈上的东西，释放内存那是超级的快，只不过需要用到这个的场合，大概都在使用C++编程。unsafe代码，纯粹增加语言复杂性的东西。就好像一个人搬家，看这个不舍得扔，那个也不舍得扔，搞到最后把瓶瓶罐罐都搬走了。 IDisposable，实现这个接口，配合using块，非常的强大，终于可以像C++那样掌握对象的销毁了。 C#没有完全抛弃指针（在unsafe状态下还可以操作指针），对于类的管理采用了名称空间（namespace）的概念，并且还使用了out、ref等关键字，便于从一个方法返回多个结果，在C#中不仅存在属性，还有索引器等比较方便的特性。 Java比C#多的特性匿名内部类：真是极端方便的一个东西，还和Java的好多设计模式有关系。 动态代理： Java里面要实现AOP，易如反掌；C#要实现AOP，相对较难，不得不借助Assamble命名空间下的那些动态IL生成工具或者使用拦截器。这就是动态代理的作用。 总结C#各项特性都完胜Java，然并卵，因为Java生态系统完胜C# 微软的c#设计者更注重一线开发人员的感受，为方便开发提高效率，他们愿意大费周章改善语言本身各方特性，不断加入语法糖，从泛型，nullable，隐式类型到lamada再到dynamic，awaitasyc等等都可看到其一直在围绕代码整洁，减少bug等实际的开发过程中问题来进行的改进，同时越来越智能的IDE也说明了这点。 而java设计者则不同，他们的关注点在于java应用系统本身，更好的降低耦合，保持OOP是其始终坚持的。]]></content>
      <tags>
        <tag>C#,Java</tag>
      </tags>
  </entry>
</search>
